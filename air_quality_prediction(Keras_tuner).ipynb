{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./ltfc/Real_Combine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>SLP</th>\n",
       "      <th>H</th>\n",
       "      <th>VV</th>\n",
       "      <th>V</th>\n",
       "      <th>VM</th>\n",
       "      <th>PM 2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>219.720833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>12.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1018.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>182.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.7</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1019.4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>154.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.6</td>\n",
       "      <td>15.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1018.7</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>20.6</td>\n",
       "      <td>223.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.4</td>\n",
       "      <td>20.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1017.3</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>200.645833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      T    TM   Tm     SLP     H   VV    V    VM      PM 2.5\n",
       "0   7.4   9.8  4.8  1017.6  93.0  0.5  4.3   9.4  219.720833\n",
       "1   7.8  12.7  4.4  1018.5  87.0  0.6  4.4  11.1  182.187500\n",
       "2   6.7  13.4  2.4  1019.4  82.0  0.6  4.8  11.1  154.037500\n",
       "3   8.6  15.5  3.3  1018.7  72.0  0.8  8.1  20.6  223.208333\n",
       "4  12.4  20.9  4.4  1017.3  61.0  1.3  8.7  22.2  200.645833"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.pop('PM 2.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.2, random_state= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperperameter:\n",
    "1. how many hidden layers model should have\n",
    "2. neuron\n",
    "3. leraning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    for i in range (hp.Int('num_layers',2,20)):\n",
    "        model.add(Dense(units = hp.Int('units_'+str(i), min_value=32, max_value=512, step=32), activation='relu'))\n",
    "    model.add(Dense(1, activation ='linear'))\n",
    "    model.compile(\n",
    "    optimizer=keras.optimizers.Adam(\n",
    "        hp.Choice('learning_rate',[1e-2,1e-3,1e-4])),                    #choice chooses between hethe given values\n",
    "    loss= 'mean_absolute_error',\n",
    "    metrics = ['mean_absolute_error'])\n",
    "    return model  #INT try with different values itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(build_model,\n",
    "                     objective ='val_mean_absolute_error',\n",
    "                     max_trials=5,\n",
    "                     executions_per_trial =3,\n",
    "                     directory ='project3',\n",
    "                     project_name = 'Air_Quality_Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 46s]\n",
      "val_mean_absolute_error: 39.874132792154946\n",
      "\n",
      "Best val_mean_absolute_error So Far: 39.37686538696289\n",
      "Total elapsed time: 00h 07m 15s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train,y_train, epochs=100, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in project1\\Air_Quality_Index\n",
      "Showing 10 best trials\n",
      "Objective(name='val_mean_absolute_error', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 8\n",
      "units_0: 128\n",
      "units_1: 128\n",
      "learning_rate: 0.01\n",
      "units_2: 32\n",
      "units_3: 32\n",
      "units_4: 32\n",
      "units_5: 32\n",
      "units_6: 32\n",
      "units_7: 32\n",
      "Score: 46.614322662353516\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 10\n",
      "units_0: 384\n",
      "units_1: 384\n",
      "learning_rate: 0.01\n",
      "units_2: 128\n",
      "units_3: 192\n",
      "units_4: 64\n",
      "units_5: 224\n",
      "units_6: 192\n",
      "units_7: 320\n",
      "units_8: 320\n",
      "units_9: 320\n",
      "units_10: 448\n",
      "units_11: 128\n",
      "units_12: 224\n",
      "units_13: 256\n",
      "units_14: 416\n",
      "units_15: 480\n",
      "Score: 47.26721064249674\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 288\n",
      "units_1: 288\n",
      "learning_rate: 0.001\n",
      "units_2: 96\n",
      "units_3: 224\n",
      "units_4: 64\n",
      "units_5: 320\n",
      "units_6: 480\n",
      "units_7: 96\n",
      "units_8: 448\n",
      "units_9: 96\n",
      "units_10: 64\n",
      "units_11: 32\n",
      "units_12: 288\n",
      "units_13: 64\n",
      "units_14: 128\n",
      "units_15: 64\n",
      "Score: 62.68621317545573\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 16\n",
      "units_0: 64\n",
      "units_1: 256\n",
      "learning_rate: 0.001\n",
      "units_2: 384\n",
      "units_3: 224\n",
      "units_4: 160\n",
      "units_5: 480\n",
      "units_6: 224\n",
      "units_7: 480\n",
      "units_8: 32\n",
      "units_9: 32\n",
      "units_10: 32\n",
      "units_11: 32\n",
      "units_12: 32\n",
      "units_13: 32\n",
      "units_14: 32\n",
      "units_15: 32\n",
      "Score: 66.15166727701823\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 16\n",
      "units_0: 448\n",
      "units_1: 96\n",
      "learning_rate: 0.01\n",
      "units_2: 224\n",
      "units_3: 384\n",
      "units_4: 160\n",
      "units_5: 288\n",
      "units_6: 384\n",
      "units_7: 448\n",
      "units_8: 288\n",
      "units_9: 416\n",
      "units_10: 96\n",
      "units_11: 96\n",
      "units_12: 352\n",
      "units_13: 480\n",
      "units_14: 288\n",
      "units_15: 256\n",
      "Score: 66.45282745361328\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(32, activation='relu'),\n",
    "      layers.Dense(32, activation='relu'),\n",
    "      layers.Dense(32, activation='relu'),\n",
    "      layers.Dense(32, activation='relu'),\n",
    "      layers.Dense(32, activation='relu'),\n",
    "      layers.Dense(32, activation='relu'),\n",
    "      layers.Dense(1, activation='linear')\n",
    "  ])\n",
    "\n",
    "  model.compile(loss= 'mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.01))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(np.array(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot3_model = build_and_compile_model(normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "88/88 - 1s - loss: 57.0748 - val_loss: 39.4044\n",
      "Epoch 2/2000\n",
      "88/88 - 0s - loss: 41.0780 - val_loss: 75.3397\n",
      "Epoch 3/2000\n",
      "88/88 - 0s - loss: 47.0113 - val_loss: 36.2762\n",
      "Epoch 4/2000\n",
      "88/88 - 0s - loss: 38.9756 - val_loss: 37.1899\n",
      "Epoch 5/2000\n",
      "88/88 - 0s - loss: 40.2360 - val_loss: 36.1489\n",
      "Epoch 6/2000\n",
      "88/88 - 0s - loss: 40.3351 - val_loss: 36.9918\n",
      "Epoch 7/2000\n",
      "88/88 - 0s - loss: 39.5361 - val_loss: 45.0187\n",
      "Epoch 8/2000\n",
      "88/88 - 0s - loss: 39.2966 - val_loss: 36.4444\n",
      "Epoch 9/2000\n",
      "88/88 - 0s - loss: 37.6879 - val_loss: 34.2522\n",
      "Epoch 10/2000\n",
      "88/88 - 0s - loss: 37.2105 - val_loss: 35.6137\n",
      "Epoch 11/2000\n",
      "88/88 - 0s - loss: 37.9288 - val_loss: 37.4688\n",
      "Epoch 12/2000\n",
      "88/88 - 0s - loss: 38.3680 - val_loss: 33.2740\n",
      "Epoch 13/2000\n",
      "88/88 - 0s - loss: 35.4881 - val_loss: 34.1345\n",
      "Epoch 14/2000\n",
      "88/88 - 0s - loss: 37.1514 - val_loss: 34.4810\n",
      "Epoch 15/2000\n",
      "88/88 - 0s - loss: 38.3104 - val_loss: 42.4100\n",
      "Epoch 16/2000\n",
      "88/88 - 0s - loss: 38.4832 - val_loss: 39.9388\n",
      "Epoch 17/2000\n",
      "88/88 - 0s - loss: 36.1415 - val_loss: 33.6464\n",
      "Epoch 18/2000\n",
      "88/88 - 0s - loss: 34.4953 - val_loss: 36.7213\n",
      "Epoch 19/2000\n",
      "88/88 - 0s - loss: 34.0559 - val_loss: 35.3946\n",
      "Epoch 20/2000\n",
      "88/88 - 0s - loss: 35.2857 - val_loss: 39.2168\n",
      "Epoch 21/2000\n",
      "88/88 - 0s - loss: 33.9202 - val_loss: 37.5617\n",
      "Epoch 22/2000\n",
      "88/88 - 0s - loss: 34.8729 - val_loss: 42.1724\n",
      "Epoch 23/2000\n",
      "88/88 - 0s - loss: 35.4827 - val_loss: 33.5610\n",
      "Epoch 24/2000\n",
      "88/88 - 0s - loss: 33.7059 - val_loss: 32.2637\n",
      "Epoch 25/2000\n",
      "88/88 - 0s - loss: 32.5274 - val_loss: 40.8247\n",
      "Epoch 26/2000\n",
      "88/88 - 0s - loss: 32.6157 - val_loss: 38.3035\n",
      "Epoch 27/2000\n",
      "88/88 - 0s - loss: 34.1205 - val_loss: 35.8688\n",
      "Epoch 28/2000\n",
      "88/88 - 0s - loss: 33.1501 - val_loss: 32.6100\n",
      "Epoch 29/2000\n",
      "88/88 - 0s - loss: 32.9104 - val_loss: 32.2814\n",
      "Epoch 30/2000\n",
      "88/88 - 0s - loss: 33.3647 - val_loss: 34.2157\n",
      "Epoch 31/2000\n",
      "88/88 - 0s - loss: 34.9499 - val_loss: 40.6539\n",
      "Epoch 32/2000\n",
      "88/88 - 0s - loss: 31.8035 - val_loss: 34.7298\n",
      "Epoch 33/2000\n",
      "88/88 - 0s - loss: 31.8121 - val_loss: 32.4382\n",
      "Epoch 34/2000\n",
      "88/88 - 0s - loss: 30.9308 - val_loss: 41.6863\n",
      "Epoch 35/2000\n",
      "88/88 - 0s - loss: 31.6744 - val_loss: 33.0153\n",
      "Epoch 36/2000\n",
      "88/88 - 0s - loss: 31.9826 - val_loss: 38.8258\n",
      "Epoch 37/2000\n",
      "88/88 - 0s - loss: 34.6042 - val_loss: 34.4552\n",
      "Epoch 38/2000\n",
      "88/88 - 0s - loss: 31.0545 - val_loss: 32.7360\n",
      "Epoch 39/2000\n",
      "88/88 - 0s - loss: 30.2651 - val_loss: 36.1673\n",
      "Epoch 40/2000\n",
      "88/88 - 0s - loss: 29.6222 - val_loss: 32.4882\n",
      "Epoch 41/2000\n",
      "88/88 - 0s - loss: 30.8091 - val_loss: 31.6582\n",
      "Epoch 42/2000\n",
      "88/88 - 0s - loss: 32.8833 - val_loss: 33.2816\n",
      "Epoch 43/2000\n",
      "88/88 - 0s - loss: 29.2386 - val_loss: 32.0213\n",
      "Epoch 44/2000\n",
      "88/88 - 0s - loss: 29.8165 - val_loss: 32.1186\n",
      "Epoch 45/2000\n",
      "88/88 - 0s - loss: 28.8229 - val_loss: 34.1151\n",
      "Epoch 46/2000\n",
      "88/88 - 0s - loss: 29.8081 - val_loss: 33.6204\n",
      "Epoch 47/2000\n",
      "88/88 - 0s - loss: 32.1482 - val_loss: 31.9377\n",
      "Epoch 48/2000\n",
      "88/88 - 0s - loss: 30.6733 - val_loss: 32.0095\n",
      "Epoch 49/2000\n",
      "88/88 - 0s - loss: 28.9574 - val_loss: 31.8591\n",
      "Epoch 50/2000\n",
      "88/88 - 0s - loss: 28.1661 - val_loss: 31.6894\n",
      "Epoch 51/2000\n",
      "88/88 - 0s - loss: 28.9189 - val_loss: 31.5786\n",
      "Epoch 52/2000\n",
      "88/88 - 0s - loss: 30.2247 - val_loss: 31.1775\n",
      "Epoch 53/2000\n",
      "88/88 - 0s - loss: 28.1503 - val_loss: 30.8983\n",
      "Epoch 54/2000\n",
      "88/88 - 0s - loss: 28.1016 - val_loss: 31.6615\n",
      "Epoch 55/2000\n",
      "88/88 - 0s - loss: 26.9032 - val_loss: 32.5235\n",
      "Epoch 56/2000\n",
      "88/88 - 0s - loss: 27.8474 - val_loss: 31.8081\n",
      "Epoch 57/2000\n",
      "88/88 - 0s - loss: 28.0284 - val_loss: 35.2499\n",
      "Epoch 58/2000\n",
      "88/88 - 0s - loss: 30.3708 - val_loss: 38.3374\n",
      "Epoch 59/2000\n",
      "88/88 - 0s - loss: 28.1077 - val_loss: 30.4309\n",
      "Epoch 60/2000\n",
      "88/88 - 0s - loss: 26.1813 - val_loss: 30.0432\n",
      "Epoch 61/2000\n",
      "88/88 - 0s - loss: 27.5235 - val_loss: 29.5065\n",
      "Epoch 62/2000\n",
      "88/88 - 0s - loss: 27.7280 - val_loss: 31.6374\n",
      "Epoch 63/2000\n",
      "88/88 - 0s - loss: 29.1133 - val_loss: 31.1322\n",
      "Epoch 64/2000\n",
      "88/88 - 0s - loss: 28.9633 - val_loss: 31.2332\n",
      "Epoch 65/2000\n",
      "88/88 - 0s - loss: 28.2326 - val_loss: 29.9730\n",
      "Epoch 66/2000\n",
      "88/88 - 0s - loss: 25.6125 - val_loss: 29.2885\n",
      "Epoch 67/2000\n",
      "88/88 - 0s - loss: 25.7628 - val_loss: 29.7747\n",
      "Epoch 68/2000\n",
      "88/88 - 0s - loss: 26.6804 - val_loss: 30.5115\n",
      "Epoch 69/2000\n",
      "88/88 - 0s - loss: 27.5899 - val_loss: 29.6065\n",
      "Epoch 70/2000\n",
      "88/88 - 0s - loss: 25.4158 - val_loss: 34.5611\n",
      "Epoch 71/2000\n",
      "88/88 - 0s - loss: 26.5465 - val_loss: 30.8717\n",
      "Epoch 72/2000\n",
      "88/88 - 0s - loss: 26.1444 - val_loss: 33.8373\n",
      "Epoch 73/2000\n",
      "88/88 - 0s - loss: 26.2807 - val_loss: 30.2492\n",
      "Epoch 74/2000\n",
      "88/88 - 0s - loss: 26.1571 - val_loss: 29.9187\n",
      "Epoch 75/2000\n",
      "88/88 - 0s - loss: 27.1090 - val_loss: 29.7246\n",
      "Epoch 76/2000\n",
      "88/88 - 0s - loss: 26.6050 - val_loss: 29.5464\n",
      "Epoch 77/2000\n",
      "88/88 - 0s - loss: 24.9780 - val_loss: 29.1222\n",
      "Epoch 78/2000\n",
      "88/88 - 0s - loss: 26.2512 - val_loss: 30.3484\n",
      "Epoch 79/2000\n",
      "88/88 - 0s - loss: 25.9261 - val_loss: 30.8702\n",
      "Epoch 80/2000\n",
      "88/88 - 0s - loss: 25.4173 - val_loss: 32.8320\n",
      "Epoch 81/2000\n",
      "88/88 - 0s - loss: 25.1705 - val_loss: 31.1053\n",
      "Epoch 82/2000\n",
      "88/88 - 0s - loss: 25.8181 - val_loss: 34.4276\n",
      "Epoch 83/2000\n",
      "88/88 - 0s - loss: 25.3170 - val_loss: 30.5290\n",
      "Epoch 84/2000\n",
      "88/88 - 0s - loss: 24.8215 - val_loss: 28.8086\n",
      "Epoch 85/2000\n",
      "88/88 - 0s - loss: 24.4836 - val_loss: 30.7715\n",
      "Epoch 86/2000\n",
      "88/88 - 0s - loss: 24.3323 - val_loss: 28.9992\n",
      "Epoch 87/2000\n",
      "88/88 - 0s - loss: 24.0052 - val_loss: 29.1524\n",
      "Epoch 88/2000\n",
      "88/88 - 0s - loss: 24.0672 - val_loss: 30.4448\n",
      "Epoch 89/2000\n",
      "88/88 - 0s - loss: 24.2842 - val_loss: 34.1562\n",
      "Epoch 90/2000\n",
      "88/88 - 0s - loss: 23.7578 - val_loss: 29.2266\n",
      "Epoch 91/2000\n",
      "88/88 - 0s - loss: 23.1218 - val_loss: 30.5647\n",
      "Epoch 92/2000\n",
      "88/88 - 0s - loss: 27.0036 - val_loss: 36.5891\n",
      "Epoch 93/2000\n",
      "88/88 - 0s - loss: 26.4000 - val_loss: 31.5922\n",
      "Epoch 94/2000\n",
      "88/88 - 0s - loss: 24.1228 - val_loss: 31.6209\n",
      "Epoch 95/2000\n",
      "88/88 - 0s - loss: 25.2834 - val_loss: 33.8947\n",
      "Epoch 96/2000\n",
      "88/88 - 0s - loss: 24.8114 - val_loss: 29.7233\n",
      "Epoch 97/2000\n",
      "88/88 - 0s - loss: 22.9031 - val_loss: 28.8809\n",
      "Epoch 98/2000\n",
      "88/88 - 0s - loss: 23.0426 - val_loss: 28.8628\n",
      "Epoch 99/2000\n",
      "88/88 - 0s - loss: 22.9903 - val_loss: 30.2526\n",
      "Epoch 100/2000\n",
      "88/88 - 0s - loss: 22.9576 - val_loss: 28.5894\n",
      "Epoch 101/2000\n",
      "88/88 - 0s - loss: 22.3723 - val_loss: 29.8276\n",
      "Epoch 102/2000\n",
      "88/88 - 0s - loss: 22.2047 - val_loss: 30.8722\n",
      "Epoch 103/2000\n",
      "88/88 - 0s - loss: 24.0229 - val_loss: 29.9511\n",
      "Epoch 104/2000\n",
      "88/88 - 0s - loss: 23.2266 - val_loss: 29.2457\n",
      "Epoch 105/2000\n",
      "88/88 - 0s - loss: 23.2488 - val_loss: 29.8085\n",
      "Epoch 106/2000\n",
      "88/88 - 0s - loss: 22.1617 - val_loss: 29.6487\n",
      "Epoch 107/2000\n",
      "88/88 - 0s - loss: 22.9512 - val_loss: 28.7571\n",
      "Epoch 108/2000\n",
      "88/88 - 0s - loss: 23.2001 - val_loss: 30.6330\n",
      "Epoch 109/2000\n",
      "88/88 - 0s - loss: 24.7832 - val_loss: 29.2961\n",
      "Epoch 110/2000\n",
      "88/88 - 0s - loss: 22.3071 - val_loss: 28.5846\n",
      "Epoch 111/2000\n",
      "88/88 - 0s - loss: 22.3934 - val_loss: 30.3398\n",
      "Epoch 112/2000\n",
      "88/88 - 0s - loss: 22.3238 - val_loss: 27.5546\n",
      "Epoch 113/2000\n",
      "88/88 - 0s - loss: 22.2893 - val_loss: 28.1712\n",
      "Epoch 114/2000\n",
      "88/88 - 0s - loss: 22.2817 - val_loss: 27.4350\n",
      "Epoch 115/2000\n",
      "88/88 - 0s - loss: 22.0558 - val_loss: 33.0196\n",
      "Epoch 116/2000\n",
      "88/88 - 0s - loss: 23.3972 - val_loss: 28.6837\n",
      "Epoch 117/2000\n",
      "88/88 - 0s - loss: 22.1453 - val_loss: 27.7593\n",
      "Epoch 118/2000\n",
      "88/88 - 0s - loss: 22.1001 - val_loss: 30.2256\n",
      "Epoch 119/2000\n",
      "88/88 - 0s - loss: 22.0551 - val_loss: 29.4041\n",
      "Epoch 120/2000\n",
      "88/88 - 0s - loss: 23.2039 - val_loss: 28.3611\n",
      "Epoch 121/2000\n",
      "88/88 - 0s - loss: 20.6229 - val_loss: 26.8368\n",
      "Epoch 122/2000\n",
      "88/88 - 0s - loss: 23.2087 - val_loss: 30.5944\n",
      "Epoch 123/2000\n",
      "88/88 - 0s - loss: 23.1230 - val_loss: 29.4075\n",
      "Epoch 124/2000\n",
      "88/88 - 0s - loss: 21.0194 - val_loss: 28.5538\n",
      "Epoch 125/2000\n",
      "88/88 - 0s - loss: 21.6132 - val_loss: 26.5331\n",
      "Epoch 126/2000\n",
      "88/88 - 0s - loss: 21.1931 - val_loss: 25.9709\n",
      "Epoch 127/2000\n",
      "88/88 - 0s - loss: 19.8963 - val_loss: 28.0841\n",
      "Epoch 128/2000\n",
      "88/88 - 0s - loss: 21.5308 - val_loss: 27.2275\n",
      "Epoch 129/2000\n",
      "88/88 - 0s - loss: 21.6175 - val_loss: 28.3443\n",
      "Epoch 130/2000\n",
      "88/88 - 0s - loss: 20.4876 - val_loss: 30.6564\n",
      "Epoch 131/2000\n",
      "88/88 - 0s - loss: 22.2126 - val_loss: 30.9063\n",
      "Epoch 132/2000\n",
      "88/88 - 0s - loss: 22.2771 - val_loss: 29.1140\n",
      "Epoch 133/2000\n",
      "88/88 - 0s - loss: 20.9947 - val_loss: 28.7857\n",
      "Epoch 134/2000\n",
      "88/88 - 0s - loss: 21.3333 - val_loss: 30.6464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/2000\n",
      "88/88 - 0s - loss: 20.0039 - val_loss: 29.1728\n",
      "Epoch 136/2000\n",
      "88/88 - 0s - loss: 23.9772 - val_loss: 30.3565\n",
      "Epoch 137/2000\n",
      "88/88 - 0s - loss: 20.8260 - val_loss: 27.9668\n",
      "Epoch 138/2000\n",
      "88/88 - 0s - loss: 20.2109 - val_loss: 28.0189\n",
      "Epoch 139/2000\n",
      "88/88 - 0s - loss: 19.8530 - val_loss: 27.6545\n",
      "Epoch 140/2000\n",
      "88/88 - 0s - loss: 20.4484 - val_loss: 27.3803\n",
      "Epoch 141/2000\n",
      "88/88 - 0s - loss: 21.3190 - val_loss: 29.8756\n",
      "Epoch 142/2000\n",
      "88/88 - 0s - loss: 21.2371 - val_loss: 28.0162\n",
      "Epoch 143/2000\n",
      "88/88 - 0s - loss: 20.5448 - val_loss: 28.9441\n",
      "Epoch 144/2000\n",
      "88/88 - 0s - loss: 20.5508 - val_loss: 28.6009\n",
      "Epoch 145/2000\n",
      "88/88 - 0s - loss: 22.1303 - val_loss: 28.6462\n",
      "Epoch 146/2000\n",
      "88/88 - 0s - loss: 20.1201 - val_loss: 27.0416\n",
      "Epoch 147/2000\n",
      "88/88 - 0s - loss: 19.1423 - val_loss: 26.0680\n",
      "Epoch 148/2000\n",
      "88/88 - 0s - loss: 19.2970 - val_loss: 29.3256\n",
      "Epoch 149/2000\n",
      "88/88 - 0s - loss: 20.7924 - val_loss: 29.5490\n",
      "Epoch 150/2000\n",
      "88/88 - 0s - loss: 21.4910 - val_loss: 26.8393\n",
      "Epoch 151/2000\n",
      "88/88 - 0s - loss: 20.4490 - val_loss: 25.6867\n",
      "Epoch 152/2000\n",
      "88/88 - 0s - loss: 19.6513 - val_loss: 25.5755\n",
      "Epoch 153/2000\n",
      "88/88 - 0s - loss: 18.8360 - val_loss: 28.3694\n",
      "Epoch 154/2000\n",
      "88/88 - 0s - loss: 20.3418 - val_loss: 26.5477\n",
      "Epoch 155/2000\n",
      "88/88 - 0s - loss: 18.5138 - val_loss: 27.0457\n",
      "Epoch 156/2000\n",
      "88/88 - 0s - loss: 18.7199 - val_loss: 26.4368\n",
      "Epoch 157/2000\n",
      "88/88 - 0s - loss: 19.5314 - val_loss: 26.8274\n",
      "Epoch 158/2000\n",
      "88/88 - 0s - loss: 19.5301 - val_loss: 25.7967\n",
      "Epoch 159/2000\n",
      "88/88 - 0s - loss: 20.0129 - val_loss: 28.0595\n",
      "Epoch 160/2000\n",
      "88/88 - 0s - loss: 19.7751 - val_loss: 28.0906\n",
      "Epoch 161/2000\n",
      "88/88 - 0s - loss: 19.6001 - val_loss: 29.0059\n",
      "Epoch 162/2000\n",
      "88/88 - 0s - loss: 19.8420 - val_loss: 25.6534\n",
      "Epoch 163/2000\n",
      "88/88 - 0s - loss: 19.7788 - val_loss: 25.7161\n",
      "Epoch 164/2000\n",
      "88/88 - 0s - loss: 18.1223 - val_loss: 25.5622\n",
      "Epoch 165/2000\n",
      "88/88 - 0s - loss: 18.3802 - val_loss: 24.3979\n",
      "Epoch 166/2000\n",
      "88/88 - 0s - loss: 18.9328 - val_loss: 25.6292\n",
      "Epoch 167/2000\n",
      "88/88 - 0s - loss: 19.0657 - val_loss: 24.5878\n",
      "Epoch 168/2000\n",
      "88/88 - 0s - loss: 18.8857 - val_loss: 25.5815\n",
      "Epoch 169/2000\n",
      "88/88 - 0s - loss: 18.6490 - val_loss: 25.7826\n",
      "Epoch 170/2000\n",
      "88/88 - 0s - loss: 19.7242 - val_loss: 26.8406\n",
      "Epoch 171/2000\n",
      "88/88 - 0s - loss: 18.2424 - val_loss: 25.7958\n",
      "Epoch 172/2000\n",
      "88/88 - 0s - loss: 18.1917 - val_loss: 25.2912\n",
      "Epoch 173/2000\n",
      "88/88 - 0s - loss: 19.8607 - val_loss: 25.6680\n",
      "Epoch 174/2000\n",
      "88/88 - 0s - loss: 19.7194 - val_loss: 25.8036\n",
      "Epoch 175/2000\n",
      "88/88 - 0s - loss: 18.4916 - val_loss: 26.1584\n",
      "Epoch 176/2000\n",
      "88/88 - 0s - loss: 18.4743 - val_loss: 25.9033\n",
      "Epoch 177/2000\n",
      "88/88 - 0s - loss: 19.4955 - val_loss: 25.2140\n",
      "Epoch 178/2000\n",
      "88/88 - 0s - loss: 19.7312 - val_loss: 24.9326\n",
      "Epoch 179/2000\n",
      "88/88 - 0s - loss: 18.4745 - val_loss: 25.9295\n",
      "Epoch 180/2000\n",
      "88/88 - 0s - loss: 19.6351 - val_loss: 24.8478\n",
      "Epoch 181/2000\n",
      "88/88 - 0s - loss: 19.9480 - val_loss: 25.7436\n",
      "Epoch 182/2000\n",
      "88/88 - 0s - loss: 19.1545 - val_loss: 25.5359\n",
      "Epoch 183/2000\n",
      "88/88 - 0s - loss: 18.7482 - val_loss: 26.6909\n",
      "Epoch 184/2000\n",
      "88/88 - 0s - loss: 18.5182 - val_loss: 26.7717\n",
      "Epoch 185/2000\n",
      "88/88 - 0s - loss: 17.4991 - val_loss: 25.2978\n",
      "Epoch 186/2000\n",
      "88/88 - 0s - loss: 17.9145 - val_loss: 25.8070\n",
      "Epoch 187/2000\n",
      "88/88 - 0s - loss: 17.0353 - val_loss: 27.3472\n",
      "Epoch 188/2000\n",
      "88/88 - 0s - loss: 18.5716 - val_loss: 26.8389\n",
      "Epoch 189/2000\n",
      "88/88 - 0s - loss: 18.5049 - val_loss: 25.1936\n",
      "Epoch 190/2000\n",
      "88/88 - 0s - loss: 17.3025 - val_loss: 27.3727\n",
      "Epoch 191/2000\n",
      "88/88 - 0s - loss: 17.7866 - val_loss: 24.9916\n",
      "Epoch 192/2000\n",
      "88/88 - 0s - loss: 19.4616 - val_loss: 28.3614\n",
      "Epoch 193/2000\n",
      "88/88 - 0s - loss: 17.9522 - val_loss: 24.3616\n",
      "Epoch 194/2000\n",
      "88/88 - 0s - loss: 16.8133 - val_loss: 26.0934\n",
      "Epoch 195/2000\n",
      "88/88 - 0s - loss: 17.0426 - val_loss: 24.5522\n",
      "Epoch 196/2000\n",
      "88/88 - 0s - loss: 17.3393 - val_loss: 24.3933\n",
      "Epoch 197/2000\n",
      "88/88 - 0s - loss: 17.1094 - val_loss: 24.5651\n",
      "Epoch 198/2000\n",
      "88/88 - 0s - loss: 16.1310 - val_loss: 26.8773\n",
      "Epoch 199/2000\n",
      "88/88 - 0s - loss: 18.2945 - val_loss: 28.7813\n",
      "Epoch 200/2000\n",
      "88/88 - 0s - loss: 18.6672 - val_loss: 24.8007\n",
      "Epoch 201/2000\n",
      "88/88 - 0s - loss: 18.1357 - val_loss: 24.2697\n",
      "Epoch 202/2000\n",
      "88/88 - 0s - loss: 18.1943 - val_loss: 24.1042\n",
      "Epoch 203/2000\n",
      "88/88 - 0s - loss: 18.0329 - val_loss: 28.2301\n",
      "Epoch 204/2000\n",
      "88/88 - 0s - loss: 17.4183 - val_loss: 23.5433\n",
      "Epoch 205/2000\n",
      "88/88 - 0s - loss: 16.3326 - val_loss: 25.5953\n",
      "Epoch 206/2000\n",
      "88/88 - 0s - loss: 17.7315 - val_loss: 24.2114\n",
      "Epoch 207/2000\n",
      "88/88 - 0s - loss: 20.6538 - val_loss: 25.5257\n",
      "Epoch 208/2000\n",
      "88/88 - 0s - loss: 19.5594 - val_loss: 25.2260\n",
      "Epoch 209/2000\n",
      "88/88 - 0s - loss: 17.2925 - val_loss: 24.0249\n",
      "Epoch 210/2000\n",
      "88/88 - 0s - loss: 18.0559 - val_loss: 24.9094\n",
      "Epoch 211/2000\n",
      "88/88 - 0s - loss: 17.5404 - val_loss: 25.8928\n",
      "Epoch 212/2000\n",
      "88/88 - 0s - loss: 17.5539 - val_loss: 24.1920\n",
      "Epoch 213/2000\n",
      "88/88 - 0s - loss: 16.8881 - val_loss: 24.7583\n",
      "Epoch 214/2000\n",
      "88/88 - 0s - loss: 16.3636 - val_loss: 27.5806\n",
      "Epoch 215/2000\n",
      "88/88 - 0s - loss: 17.8371 - val_loss: 25.4756\n",
      "Epoch 216/2000\n",
      "88/88 - 0s - loss: 16.9854 - val_loss: 25.2833\n",
      "Epoch 217/2000\n",
      "88/88 - 0s - loss: 17.3394 - val_loss: 27.5336\n",
      "Epoch 218/2000\n",
      "88/88 - 0s - loss: 18.0940 - val_loss: 24.1516\n",
      "Epoch 219/2000\n",
      "88/88 - 0s - loss: 17.6847 - val_loss: 26.9444\n",
      "Epoch 220/2000\n",
      "88/88 - 0s - loss: 18.3433 - val_loss: 27.1302\n",
      "Epoch 221/2000\n",
      "88/88 - 0s - loss: 16.3780 - val_loss: 25.2211\n",
      "Epoch 222/2000\n",
      "88/88 - 0s - loss: 16.2081 - val_loss: 24.1942\n",
      "Epoch 223/2000\n",
      "88/88 - 0s - loss: 16.3012 - val_loss: 24.0004\n",
      "Epoch 224/2000\n",
      "88/88 - 0s - loss: 16.5447 - val_loss: 25.7009\n",
      "Epoch 225/2000\n",
      "88/88 - 0s - loss: 17.0574 - val_loss: 23.9887\n",
      "Epoch 226/2000\n",
      "88/88 - 0s - loss: 18.3284 - val_loss: 23.5879\n",
      "Epoch 227/2000\n",
      "88/88 - 0s - loss: 17.6336 - val_loss: 23.4726\n",
      "Epoch 228/2000\n",
      "88/88 - 0s - loss: 17.1719 - val_loss: 23.1365\n",
      "Epoch 229/2000\n",
      "88/88 - 0s - loss: 16.4658 - val_loss: 25.7602\n",
      "Epoch 230/2000\n",
      "88/88 - 0s - loss: 19.2049 - val_loss: 26.6838\n",
      "Epoch 231/2000\n",
      "88/88 - 0s - loss: 17.4690 - val_loss: 24.7531\n",
      "Epoch 232/2000\n",
      "88/88 - 0s - loss: 17.0033 - val_loss: 25.4096\n",
      "Epoch 233/2000\n",
      "88/88 - 0s - loss: 16.9583 - val_loss: 25.7664\n",
      "Epoch 234/2000\n",
      "88/88 - 0s - loss: 19.2162 - val_loss: 24.3139\n",
      "Epoch 235/2000\n",
      "88/88 - 0s - loss: 17.0887 - val_loss: 24.0015\n",
      "Epoch 236/2000\n",
      "88/88 - 0s - loss: 16.7495 - val_loss: 24.2677\n",
      "Epoch 237/2000\n",
      "88/88 - 0s - loss: 16.7590 - val_loss: 24.2652\n",
      "Epoch 238/2000\n",
      "88/88 - 0s - loss: 16.1066 - val_loss: 24.1821\n",
      "Epoch 239/2000\n",
      "88/88 - 0s - loss: 16.3650 - val_loss: 24.1702\n",
      "Epoch 240/2000\n",
      "88/88 - 0s - loss: 16.8255 - val_loss: 24.1135\n",
      "Epoch 241/2000\n",
      "88/88 - 0s - loss: 17.7030 - val_loss: 23.9257\n",
      "Epoch 242/2000\n",
      "88/88 - 0s - loss: 19.3651 - val_loss: 23.4748\n",
      "Epoch 243/2000\n",
      "88/88 - 0s - loss: 18.4965 - val_loss: 25.2322\n",
      "Epoch 244/2000\n",
      "88/88 - 0s - loss: 18.3572 - val_loss: 24.5860\n",
      "Epoch 245/2000\n",
      "88/88 - 0s - loss: 17.1852 - val_loss: 24.5065\n",
      "Epoch 246/2000\n",
      "88/88 - 0s - loss: 16.8263 - val_loss: 25.5100\n",
      "Epoch 247/2000\n",
      "88/88 - 0s - loss: 16.8687 - val_loss: 24.2246\n",
      "Epoch 248/2000\n",
      "88/88 - 0s - loss: 15.2681 - val_loss: 26.5705\n",
      "Epoch 249/2000\n",
      "88/88 - 0s - loss: 17.4038 - val_loss: 28.4764\n",
      "Epoch 250/2000\n",
      "88/88 - 0s - loss: 17.8940 - val_loss: 24.8468\n",
      "Epoch 251/2000\n",
      "88/88 - 0s - loss: 16.4764 - val_loss: 23.8568\n",
      "Epoch 252/2000\n",
      "88/88 - 0s - loss: 15.6643 - val_loss: 23.5194\n",
      "Epoch 253/2000\n",
      "88/88 - 0s - loss: 16.5098 - val_loss: 23.8203\n",
      "Epoch 254/2000\n",
      "88/88 - 0s - loss: 15.8063 - val_loss: 22.3690\n",
      "Epoch 255/2000\n",
      "88/88 - 0s - loss: 14.8843 - val_loss: 23.4593\n",
      "Epoch 256/2000\n",
      "88/88 - 0s - loss: 15.8125 - val_loss: 22.5936\n",
      "Epoch 257/2000\n",
      "88/88 - 0s - loss: 16.5185 - val_loss: 26.6793\n",
      "Epoch 258/2000\n",
      "88/88 - 0s - loss: 16.9038 - val_loss: 24.7216\n",
      "Epoch 259/2000\n",
      "88/88 - 0s - loss: 16.0519 - val_loss: 23.1583\n",
      "Epoch 260/2000\n",
      "88/88 - 0s - loss: 15.0509 - val_loss: 22.7968\n",
      "Epoch 261/2000\n",
      "88/88 - 0s - loss: 15.4010 - val_loss: 22.2756\n",
      "Epoch 262/2000\n",
      "88/88 - 0s - loss: 16.2098 - val_loss: 26.7189\n",
      "Epoch 263/2000\n",
      "88/88 - 0s - loss: 16.8797 - val_loss: 22.3741\n",
      "Epoch 264/2000\n",
      "88/88 - 0s - loss: 14.9383 - val_loss: 23.2104\n",
      "Epoch 265/2000\n",
      "88/88 - 0s - loss: 14.9257 - val_loss: 23.8542\n",
      "Epoch 266/2000\n",
      "88/88 - 0s - loss: 15.4724 - val_loss: 24.7238\n",
      "Epoch 267/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 - 0s - loss: 15.6584 - val_loss: 24.5892\n",
      "Epoch 268/2000\n",
      "88/88 - 0s - loss: 16.6594 - val_loss: 27.2847\n",
      "Epoch 269/2000\n",
      "88/88 - 0s - loss: 17.4602 - val_loss: 26.0300\n",
      "Epoch 270/2000\n",
      "88/88 - 0s - loss: 16.9695 - val_loss: 23.4663\n",
      "Epoch 271/2000\n",
      "88/88 - 0s - loss: 17.0149 - val_loss: 27.2515\n",
      "Epoch 272/2000\n",
      "88/88 - 0s - loss: 16.0696 - val_loss: 24.1203\n",
      "Epoch 273/2000\n",
      "88/88 - 0s - loss: 15.9222 - val_loss: 22.0385\n",
      "Epoch 274/2000\n",
      "88/88 - 0s - loss: 16.2526 - val_loss: 24.8044\n",
      "Epoch 275/2000\n",
      "88/88 - 0s - loss: 16.7414 - val_loss: 24.3599\n",
      "Epoch 276/2000\n",
      "88/88 - 0s - loss: 16.7360 - val_loss: 24.8956\n",
      "Epoch 277/2000\n",
      "88/88 - 0s - loss: 17.3591 - val_loss: 22.2983\n",
      "Epoch 278/2000\n",
      "88/88 - 0s - loss: 15.3271 - val_loss: 23.6285\n",
      "Epoch 279/2000\n",
      "88/88 - 0s - loss: 15.3231 - val_loss: 22.7687\n",
      "Epoch 280/2000\n",
      "88/88 - 0s - loss: 15.5865 - val_loss: 23.9898\n",
      "Epoch 281/2000\n",
      "88/88 - 0s - loss: 14.4031 - val_loss: 22.7900\n",
      "Epoch 282/2000\n",
      "88/88 - 0s - loss: 16.0258 - val_loss: 22.6764\n",
      "Epoch 283/2000\n",
      "88/88 - 0s - loss: 15.5333 - val_loss: 25.0435\n",
      "Epoch 284/2000\n",
      "88/88 - 0s - loss: 14.6436 - val_loss: 22.3201\n",
      "Epoch 285/2000\n",
      "88/88 - 0s - loss: 15.3665 - val_loss: 23.4006\n",
      "Epoch 286/2000\n",
      "88/88 - 0s - loss: 15.7356 - val_loss: 22.5218\n",
      "Epoch 287/2000\n",
      "88/88 - 0s - loss: 15.0519 - val_loss: 23.4613\n",
      "Epoch 288/2000\n",
      "88/88 - 0s - loss: 14.4493 - val_loss: 21.9017\n",
      "Epoch 289/2000\n",
      "88/88 - 0s - loss: 16.4506 - val_loss: 24.3020\n",
      "Epoch 290/2000\n",
      "88/88 - 0s - loss: 16.7590 - val_loss: 24.8651\n",
      "Epoch 291/2000\n",
      "88/88 - 0s - loss: 15.3972 - val_loss: 24.1687\n",
      "Epoch 292/2000\n",
      "88/88 - 0s - loss: 15.1210 - val_loss: 21.2400\n",
      "Epoch 293/2000\n",
      "88/88 - 0s - loss: 14.5231 - val_loss: 22.1566\n",
      "Epoch 294/2000\n",
      "88/88 - 0s - loss: 14.4295 - val_loss: 24.6976\n",
      "Epoch 295/2000\n",
      "88/88 - 0s - loss: 18.5703 - val_loss: 25.2110\n",
      "Epoch 296/2000\n",
      "88/88 - 0s - loss: 16.8782 - val_loss: 25.1051\n",
      "Epoch 297/2000\n",
      "88/88 - 0s - loss: 16.0318 - val_loss: 22.8357\n",
      "Epoch 298/2000\n",
      "88/88 - 0s - loss: 15.1089 - val_loss: 23.2004\n",
      "Epoch 299/2000\n",
      "88/88 - 0s - loss: 14.9168 - val_loss: 24.6698\n",
      "Epoch 300/2000\n",
      "88/88 - 0s - loss: 15.0478 - val_loss: 23.1657\n",
      "Epoch 301/2000\n",
      "88/88 - 0s - loss: 14.0247 - val_loss: 23.5942\n",
      "Epoch 302/2000\n",
      "88/88 - 0s - loss: 14.3617 - val_loss: 25.6455\n",
      "Epoch 303/2000\n",
      "88/88 - 0s - loss: 15.1359 - val_loss: 23.1538\n",
      "Epoch 304/2000\n",
      "88/88 - 0s - loss: 16.4427 - val_loss: 24.8779\n",
      "Epoch 305/2000\n",
      "88/88 - 0s - loss: 15.7765 - val_loss: 22.4903\n",
      "Epoch 306/2000\n",
      "88/88 - 0s - loss: 14.0580 - val_loss: 22.5038\n",
      "Epoch 307/2000\n",
      "88/88 - 0s - loss: 14.7070 - val_loss: 24.0885\n",
      "Epoch 308/2000\n",
      "88/88 - 0s - loss: 14.9784 - val_loss: 24.6447\n",
      "Epoch 309/2000\n",
      "88/88 - 0s - loss: 14.6915 - val_loss: 23.4535\n",
      "Epoch 310/2000\n",
      "88/88 - 0s - loss: 14.8409 - val_loss: 26.2266\n",
      "Epoch 311/2000\n",
      "88/88 - 0s - loss: 14.9023 - val_loss: 21.6486\n",
      "Epoch 312/2000\n",
      "88/88 - 0s - loss: 13.9905 - val_loss: 22.9084\n",
      "Epoch 313/2000\n",
      "88/88 - 0s - loss: 17.3830 - val_loss: 24.1790\n",
      "Epoch 314/2000\n",
      "88/88 - 0s - loss: 16.7068 - val_loss: 23.2777\n",
      "Epoch 315/2000\n",
      "88/88 - 0s - loss: 15.8435 - val_loss: 22.8022\n",
      "Epoch 316/2000\n",
      "88/88 - 0s - loss: 13.3695 - val_loss: 23.0377\n",
      "Epoch 317/2000\n",
      "88/88 - 0s - loss: 13.8335 - val_loss: 22.9648\n",
      "Epoch 318/2000\n",
      "88/88 - 0s - loss: 13.9947 - val_loss: 21.3335\n",
      "Epoch 319/2000\n",
      "88/88 - 0s - loss: 13.1709 - val_loss: 23.4530\n",
      "Epoch 320/2000\n",
      "88/88 - 0s - loss: 13.8982 - val_loss: 21.8503\n",
      "Epoch 321/2000\n",
      "88/88 - 0s - loss: 13.4188 - val_loss: 23.1595\n",
      "Epoch 322/2000\n",
      "88/88 - 0s - loss: 15.0641 - val_loss: 24.8417\n",
      "Epoch 323/2000\n",
      "88/88 - 0s - loss: 14.8735 - val_loss: 23.0561\n",
      "Epoch 324/2000\n",
      "88/88 - 0s - loss: 15.7371 - val_loss: 24.5689\n",
      "Epoch 325/2000\n",
      "88/88 - 0s - loss: 15.1102 - val_loss: 24.0500\n",
      "Epoch 326/2000\n",
      "88/88 - 0s - loss: 14.8279 - val_loss: 22.5523\n",
      "Epoch 327/2000\n",
      "88/88 - 0s - loss: 14.0686 - val_loss: 24.2749\n",
      "Epoch 328/2000\n",
      "88/88 - 0s - loss: 14.5377 - val_loss: 23.2510\n",
      "Epoch 329/2000\n",
      "88/88 - 0s - loss: 14.3502 - val_loss: 23.0233\n",
      "Epoch 330/2000\n",
      "88/88 - 0s - loss: 15.9096 - val_loss: 22.0401\n",
      "Epoch 331/2000\n",
      "88/88 - 0s - loss: 14.4350 - val_loss: 21.8559\n",
      "Epoch 332/2000\n",
      "88/88 - 0s - loss: 13.4594 - val_loss: 23.7435\n",
      "Epoch 333/2000\n",
      "88/88 - 0s - loss: 14.4458 - val_loss: 25.0011\n",
      "Epoch 334/2000\n",
      "88/88 - 0s - loss: 14.3888 - val_loss: 21.7455\n",
      "Epoch 335/2000\n",
      "88/88 - 0s - loss: 13.0374 - val_loss: 21.9319\n",
      "Epoch 336/2000\n",
      "88/88 - 0s - loss: 13.0325 - val_loss: 21.7124\n",
      "Epoch 337/2000\n",
      "88/88 - 0s - loss: 13.6281 - val_loss: 24.7381\n",
      "Epoch 338/2000\n",
      "88/88 - 0s - loss: 13.3138 - val_loss: 22.8555\n",
      "Epoch 339/2000\n",
      "88/88 - 0s - loss: 13.4205 - val_loss: 22.6679\n",
      "Epoch 340/2000\n",
      "88/88 - 0s - loss: 14.4011 - val_loss: 25.5283\n",
      "Epoch 341/2000\n",
      "88/88 - 0s - loss: 15.4591 - val_loss: 23.8733\n",
      "Epoch 342/2000\n",
      "88/88 - 0s - loss: 13.6379 - val_loss: 25.0033\n",
      "Epoch 343/2000\n",
      "88/88 - 0s - loss: 13.7536 - val_loss: 22.5679\n",
      "Epoch 344/2000\n",
      "88/88 - 0s - loss: 14.4590 - val_loss: 23.4296\n",
      "Epoch 345/2000\n",
      "88/88 - 0s - loss: 12.9182 - val_loss: 22.2605\n",
      "Epoch 346/2000\n",
      "88/88 - 0s - loss: 12.4975 - val_loss: 22.1836\n",
      "Epoch 347/2000\n",
      "88/88 - 0s - loss: 14.5494 - val_loss: 31.7356\n",
      "Epoch 348/2000\n",
      "88/88 - 0s - loss: 13.9679 - val_loss: 23.6564\n",
      "Epoch 349/2000\n",
      "88/88 - 0s - loss: 13.8873 - val_loss: 22.3543\n",
      "Epoch 350/2000\n",
      "88/88 - 0s - loss: 12.8372 - val_loss: 22.7646\n",
      "Epoch 351/2000\n",
      "88/88 - 0s - loss: 13.9493 - val_loss: 21.9113\n",
      "Epoch 352/2000\n",
      "88/88 - 0s - loss: 14.2675 - val_loss: 22.0238\n",
      "Epoch 353/2000\n",
      "88/88 - 0s - loss: 13.1550 - val_loss: 23.8731\n",
      "Epoch 354/2000\n",
      "88/88 - 0s - loss: 14.1962 - val_loss: 23.8436\n",
      "Epoch 355/2000\n",
      "88/88 - 0s - loss: 14.0572 - val_loss: 22.9397\n",
      "Epoch 356/2000\n",
      "88/88 - 0s - loss: 12.6773 - val_loss: 22.0819\n",
      "Epoch 357/2000\n",
      "88/88 - 0s - loss: 13.3597 - val_loss: 22.1608\n",
      "Epoch 358/2000\n",
      "88/88 - 0s - loss: 14.2416 - val_loss: 25.9247\n",
      "Epoch 359/2000\n",
      "88/88 - 0s - loss: 13.4310 - val_loss: 23.0013\n",
      "Epoch 360/2000\n",
      "88/88 - 0s - loss: 14.5271 - val_loss: 24.8943\n",
      "Epoch 361/2000\n",
      "88/88 - 0s - loss: 15.0833 - val_loss: 25.3660\n",
      "Epoch 362/2000\n",
      "88/88 - 0s - loss: 14.9739 - val_loss: 24.6370\n",
      "Epoch 363/2000\n",
      "88/88 - 0s - loss: 16.3710 - val_loss: 27.2118\n",
      "Epoch 364/2000\n",
      "88/88 - 0s - loss: 15.1457 - val_loss: 27.2850\n",
      "Epoch 365/2000\n",
      "88/88 - 0s - loss: 17.1483 - val_loss: 23.7342\n",
      "Epoch 366/2000\n",
      "88/88 - 0s - loss: 13.6207 - val_loss: 24.0654\n",
      "Epoch 367/2000\n",
      "88/88 - 0s - loss: 14.2537 - val_loss: 22.8336\n",
      "Epoch 368/2000\n",
      "88/88 - 0s - loss: 12.3449 - val_loss: 21.8251\n",
      "Epoch 369/2000\n",
      "88/88 - 0s - loss: 12.5662 - val_loss: 23.1449\n",
      "Epoch 370/2000\n",
      "88/88 - 0s - loss: 13.4643 - val_loss: 23.4079\n",
      "Epoch 371/2000\n",
      "88/88 - 0s - loss: 12.8738 - val_loss: 23.2553\n",
      "Epoch 372/2000\n",
      "88/88 - 0s - loss: 14.1458 - val_loss: 22.2344\n",
      "Epoch 373/2000\n",
      "88/88 - 0s - loss: 12.9487 - val_loss: 22.2536\n",
      "Epoch 374/2000\n",
      "88/88 - 0s - loss: 12.6587 - val_loss: 22.3812\n",
      "Epoch 375/2000\n",
      "88/88 - 0s - loss: 12.8129 - val_loss: 23.4165\n",
      "Epoch 376/2000\n",
      "88/88 - 0s - loss: 12.9345 - val_loss: 22.2049\n",
      "Epoch 377/2000\n",
      "88/88 - 0s - loss: 12.9473 - val_loss: 21.7156\n",
      "Epoch 378/2000\n",
      "88/88 - 0s - loss: 12.3918 - val_loss: 24.8640\n",
      "Epoch 379/2000\n",
      "88/88 - 0s - loss: 13.5720 - val_loss: 24.4673\n",
      "Epoch 380/2000\n",
      "88/88 - 0s - loss: 13.1310 - val_loss: 23.4737\n",
      "Epoch 381/2000\n",
      "88/88 - 0s - loss: 14.3611 - val_loss: 22.6482\n",
      "Epoch 382/2000\n",
      "88/88 - 0s - loss: 15.6541 - val_loss: 25.6736\n",
      "Epoch 383/2000\n",
      "88/88 - 0s - loss: 13.8095 - val_loss: 24.5951\n",
      "Epoch 384/2000\n",
      "88/88 - 0s - loss: 15.5327 - val_loss: 22.6680\n",
      "Epoch 385/2000\n",
      "88/88 - 0s - loss: 16.1282 - val_loss: 24.2312\n",
      "Epoch 386/2000\n",
      "88/88 - 0s - loss: 15.5565 - val_loss: 28.6849\n",
      "Epoch 387/2000\n",
      "88/88 - 0s - loss: 15.5156 - val_loss: 21.3877\n",
      "Epoch 388/2000\n",
      "88/88 - 0s - loss: 14.9905 - val_loss: 24.5944\n",
      "Epoch 389/2000\n",
      "88/88 - 0s - loss: 15.7182 - val_loss: 24.7960\n",
      "Epoch 390/2000\n",
      "88/88 - 0s - loss: 14.7566 - val_loss: 23.2297\n",
      "Epoch 391/2000\n",
      "88/88 - 0s - loss: 12.7030 - val_loss: 23.3072\n",
      "Epoch 392/2000\n",
      "88/88 - 0s - loss: 13.7463 - val_loss: 25.1339\n",
      "Epoch 393/2000\n",
      "88/88 - 0s - loss: 13.9229 - val_loss: 22.6354\n",
      "Epoch 394/2000\n",
      "88/88 - 0s - loss: 14.7142 - val_loss: 28.2963\n",
      "Epoch 395/2000\n",
      "88/88 - 0s - loss: 16.6529 - val_loss: 24.0389\n",
      "Epoch 396/2000\n",
      "88/88 - 0s - loss: 14.9056 - val_loss: 23.9058\n",
      "Epoch 397/2000\n",
      "88/88 - 0s - loss: 14.6498 - val_loss: 25.0048\n",
      "Epoch 398/2000\n",
      "88/88 - 0s - loss: 16.3753 - val_loss: 23.1474\n",
      "Epoch 399/2000\n",
      "88/88 - 0s - loss: 14.9597 - val_loss: 24.1195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/2000\n",
      "88/88 - 0s - loss: 17.0831 - val_loss: 24.6332\n",
      "Epoch 401/2000\n",
      "88/88 - 0s - loss: 15.4350 - val_loss: 23.4245\n",
      "Epoch 402/2000\n",
      "88/88 - 0s - loss: 14.5101 - val_loss: 22.3624\n",
      "Epoch 403/2000\n",
      "88/88 - 0s - loss: 18.8160 - val_loss: 26.2459\n",
      "Epoch 404/2000\n",
      "88/88 - 0s - loss: 17.0400 - val_loss: 24.1255\n",
      "Epoch 405/2000\n",
      "88/88 - 0s - loss: 15.2039 - val_loss: 23.8860\n",
      "Epoch 406/2000\n",
      "88/88 - 0s - loss: 16.3697 - val_loss: 24.3076\n",
      "Epoch 407/2000\n",
      "88/88 - 0s - loss: 15.1393 - val_loss: 25.4759\n",
      "Epoch 408/2000\n",
      "88/88 - 0s - loss: 15.6333 - val_loss: 23.6864\n",
      "Epoch 409/2000\n",
      "88/88 - 0s - loss: 15.2126 - val_loss: 22.6494\n",
      "Epoch 410/2000\n",
      "88/88 - 0s - loss: 14.2712 - val_loss: 24.6984\n",
      "Epoch 411/2000\n",
      "88/88 - 0s - loss: 14.4748 - val_loss: 21.7625\n",
      "Epoch 412/2000\n",
      "88/88 - 0s - loss: 13.1963 - val_loss: 22.5988\n",
      "Epoch 413/2000\n",
      "88/88 - 0s - loss: 13.4779 - val_loss: 22.8354\n",
      "Epoch 414/2000\n",
      "88/88 - 0s - loss: 15.2566 - val_loss: 21.9645\n",
      "Epoch 415/2000\n",
      "88/88 - 0s - loss: 13.1432 - val_loss: 23.0727\n",
      "Epoch 416/2000\n",
      "88/88 - 0s - loss: 12.8711 - val_loss: 21.8825\n",
      "Epoch 417/2000\n",
      "88/88 - 0s - loss: 15.3027 - val_loss: 26.8840\n",
      "Epoch 418/2000\n",
      "88/88 - 0s - loss: 15.8721 - val_loss: 22.7770\n",
      "Epoch 419/2000\n",
      "88/88 - 0s - loss: 14.4166 - val_loss: 22.1122\n",
      "Epoch 420/2000\n",
      "88/88 - 0s - loss: 13.1610 - val_loss: 21.3259\n",
      "Epoch 421/2000\n",
      "88/88 - 0s - loss: 12.9950 - val_loss: 21.7530\n",
      "Epoch 422/2000\n",
      "88/88 - 0s - loss: 14.9889 - val_loss: 21.5287\n",
      "Epoch 423/2000\n",
      "88/88 - 0s - loss: 13.7400 - val_loss: 22.6122\n",
      "Epoch 424/2000\n",
      "88/88 - 0s - loss: 13.5297 - val_loss: 21.6745\n",
      "Epoch 425/2000\n",
      "88/88 - 0s - loss: 14.2502 - val_loss: 22.5213\n",
      "Epoch 426/2000\n",
      "88/88 - 0s - loss: 15.0545 - val_loss: 23.4377\n",
      "Epoch 427/2000\n",
      "88/88 - 0s - loss: 17.6378 - val_loss: 22.9923\n",
      "Epoch 428/2000\n",
      "88/88 - 0s - loss: 16.1858 - val_loss: 23.2397\n",
      "Epoch 429/2000\n",
      "88/88 - 0s - loss: 14.8876 - val_loss: 22.5246\n",
      "Epoch 430/2000\n",
      "88/88 - 0s - loss: 15.1870 - val_loss: 23.1792\n",
      "Epoch 431/2000\n",
      "88/88 - 0s - loss: 12.9078 - val_loss: 22.7949\n",
      "Epoch 432/2000\n",
      "88/88 - 0s - loss: 13.3000 - val_loss: 22.1702\n",
      "Epoch 433/2000\n",
      "88/88 - 0s - loss: 14.6323 - val_loss: 23.4080\n",
      "Epoch 434/2000\n",
      "88/88 - 0s - loss: 13.1672 - val_loss: 21.3913\n",
      "Epoch 435/2000\n",
      "88/88 - 0s - loss: 14.7995 - val_loss: 21.6723\n",
      "Epoch 436/2000\n",
      "88/88 - 0s - loss: 13.8025 - val_loss: 21.3769\n",
      "Epoch 437/2000\n",
      "88/88 - 0s - loss: 12.7375 - val_loss: 21.3375\n",
      "Epoch 438/2000\n",
      "88/88 - 0s - loss: 12.7337 - val_loss: 22.6212\n",
      "Epoch 439/2000\n",
      "88/88 - 0s - loss: 13.4541 - val_loss: 22.5920\n",
      "Epoch 440/2000\n",
      "88/88 - 0s - loss: 13.8206 - val_loss: 22.7957\n",
      "Epoch 441/2000\n",
      "88/88 - 0s - loss: 15.3410 - val_loss: 24.2484\n",
      "Epoch 442/2000\n",
      "88/88 - 0s - loss: 13.8741 - val_loss: 22.4666\n",
      "Epoch 443/2000\n",
      "88/88 - 0s - loss: 14.8784 - val_loss: 24.0152\n",
      "Epoch 444/2000\n",
      "88/88 - 0s - loss: 13.9364 - val_loss: 22.9842\n",
      "Epoch 445/2000\n",
      "88/88 - 0s - loss: 13.0832 - val_loss: 25.8946\n",
      "Epoch 446/2000\n",
      "88/88 - 0s - loss: 13.4334 - val_loss: 22.4977\n",
      "Epoch 447/2000\n",
      "88/88 - 0s - loss: 12.8933 - val_loss: 23.9632\n",
      "Epoch 448/2000\n",
      "88/88 - 0s - loss: 13.6566 - val_loss: 21.0514\n",
      "Epoch 449/2000\n",
      "88/88 - 0s - loss: 14.4620 - val_loss: 21.2763\n",
      "Epoch 450/2000\n",
      "88/88 - 0s - loss: 13.5493 - val_loss: 21.2104\n",
      "Epoch 451/2000\n",
      "88/88 - 0s - loss: 12.7186 - val_loss: 23.6244\n",
      "Epoch 452/2000\n",
      "88/88 - 0s - loss: 13.7777 - val_loss: 22.9529\n",
      "Epoch 453/2000\n",
      "88/88 - 0s - loss: 12.7464 - val_loss: 22.1846\n",
      "Epoch 454/2000\n",
      "88/88 - 0s - loss: 16.6662 - val_loss: 26.3310\n",
      "Epoch 455/2000\n",
      "88/88 - 0s - loss: 17.6843 - val_loss: 22.8652\n",
      "Epoch 456/2000\n",
      "88/88 - 0s - loss: 14.0266 - val_loss: 22.2129\n",
      "Epoch 457/2000\n",
      "88/88 - 0s - loss: 14.0754 - val_loss: 21.2561\n",
      "Epoch 458/2000\n",
      "88/88 - 0s - loss: 13.4369 - val_loss: 22.0968\n",
      "Epoch 459/2000\n",
      "88/88 - 0s - loss: 13.3132 - val_loss: 20.8172\n",
      "Epoch 460/2000\n",
      "88/88 - 0s - loss: 12.4011 - val_loss: 21.8189\n",
      "Epoch 461/2000\n",
      "88/88 - 0s - loss: 13.2236 - val_loss: 21.5382\n",
      "Epoch 462/2000\n",
      "88/88 - 0s - loss: 11.3942 - val_loss: 20.4313\n",
      "Epoch 463/2000\n",
      "88/88 - 0s - loss: 12.3159 - val_loss: 20.3445\n",
      "Epoch 464/2000\n",
      "88/88 - 0s - loss: 13.6502 - val_loss: 21.1121\n",
      "Epoch 465/2000\n",
      "88/88 - 0s - loss: 12.6656 - val_loss: 20.4676\n",
      "Epoch 466/2000\n",
      "88/88 - 0s - loss: 12.7255 - val_loss: 21.8110\n",
      "Epoch 467/2000\n",
      "88/88 - 0s - loss: 13.9421 - val_loss: 21.7138\n",
      "Epoch 468/2000\n",
      "88/88 - 0s - loss: 12.3134 - val_loss: 23.8198\n",
      "Epoch 469/2000\n",
      "88/88 - 0s - loss: 12.6994 - val_loss: 22.0269\n",
      "Epoch 470/2000\n",
      "88/88 - 0s - loss: 13.0336 - val_loss: 21.8658\n",
      "Epoch 471/2000\n",
      "88/88 - 0s - loss: 12.8766 - val_loss: 22.3507\n",
      "Epoch 472/2000\n",
      "88/88 - 0s - loss: 17.7566 - val_loss: 23.6824\n",
      "Epoch 473/2000\n",
      "88/88 - 0s - loss: 15.5614 - val_loss: 23.0988\n",
      "Epoch 474/2000\n",
      "88/88 - 0s - loss: 15.3281 - val_loss: 25.9520\n",
      "Epoch 475/2000\n",
      "88/88 - 0s - loss: 16.3318 - val_loss: 20.9218\n",
      "Epoch 476/2000\n",
      "88/88 - 0s - loss: 13.9132 - val_loss: 21.9281\n",
      "Epoch 477/2000\n",
      "88/88 - 0s - loss: 13.6181 - val_loss: 21.2742\n",
      "Epoch 478/2000\n",
      "88/88 - 0s - loss: 12.9318 - val_loss: 20.2420\n",
      "Epoch 479/2000\n",
      "88/88 - 0s - loss: 12.9907 - val_loss: 21.8045\n",
      "Epoch 480/2000\n",
      "88/88 - 0s - loss: 13.7104 - val_loss: 21.3353\n",
      "Epoch 481/2000\n",
      "88/88 - 0s - loss: 13.1833 - val_loss: 19.6209\n",
      "Epoch 482/2000\n",
      "88/88 - 0s - loss: 12.7893 - val_loss: 20.0088\n",
      "Epoch 483/2000\n",
      "88/88 - 0s - loss: 16.3677 - val_loss: 23.1062\n",
      "Epoch 484/2000\n",
      "88/88 - 0s - loss: 13.7720 - val_loss: 23.5009\n",
      "Epoch 485/2000\n",
      "88/88 - 0s - loss: 12.9351 - val_loss: 21.4205\n",
      "Epoch 486/2000\n",
      "88/88 - 0s - loss: 12.1183 - val_loss: 20.9323\n",
      "Epoch 487/2000\n",
      "88/88 - 0s - loss: 18.4401 - val_loss: 23.2436\n",
      "Epoch 488/2000\n",
      "88/88 - 0s - loss: 17.3164 - val_loss: 29.4808\n",
      "Epoch 489/2000\n",
      "88/88 - 0s - loss: 17.0011 - val_loss: 23.9610\n",
      "Epoch 490/2000\n",
      "88/88 - 0s - loss: 14.8375 - val_loss: 23.0469\n",
      "Epoch 491/2000\n",
      "88/88 - 0s - loss: 14.4863 - val_loss: 22.1419\n",
      "Epoch 492/2000\n",
      "88/88 - 0s - loss: 13.4357 - val_loss: 23.0876\n",
      "Epoch 493/2000\n",
      "88/88 - 0s - loss: 16.2816 - val_loss: 22.7885\n",
      "Epoch 494/2000\n",
      "88/88 - 0s - loss: 12.9571 - val_loss: 22.8747\n",
      "Epoch 495/2000\n",
      "88/88 - 0s - loss: 12.0483 - val_loss: 24.2995\n",
      "Epoch 496/2000\n",
      "88/88 - 0s - loss: 12.3596 - val_loss: 22.3153\n",
      "Epoch 497/2000\n",
      "88/88 - 0s - loss: 11.9743 - val_loss: 23.9251\n",
      "Epoch 498/2000\n",
      "88/88 - 0s - loss: 12.5547 - val_loss: 23.3938\n",
      "Epoch 499/2000\n",
      "88/88 - 0s - loss: 13.3613 - val_loss: 21.3930\n",
      "Epoch 500/2000\n",
      "88/88 - 0s - loss: 12.4941 - val_loss: 23.2283\n",
      "Epoch 501/2000\n",
      "88/88 - 0s - loss: 12.1347 - val_loss: 22.3618\n",
      "Epoch 502/2000\n",
      "88/88 - 0s - loss: 12.4959 - val_loss: 23.7649\n",
      "Epoch 503/2000\n",
      "88/88 - 0s - loss: 14.5904 - val_loss: 22.4552\n",
      "Epoch 504/2000\n",
      "88/88 - 0s - loss: 13.2545 - val_loss: 21.3689\n",
      "Epoch 505/2000\n",
      "88/88 - 0s - loss: 15.1439 - val_loss: 23.4560\n",
      "Epoch 506/2000\n",
      "88/88 - 0s - loss: 13.4468 - val_loss: 22.6408\n",
      "Epoch 507/2000\n",
      "88/88 - 0s - loss: 12.5576 - val_loss: 22.9936\n",
      "Epoch 508/2000\n",
      "88/88 - 0s - loss: 14.2282 - val_loss: 22.3300\n",
      "Epoch 509/2000\n",
      "88/88 - 0s - loss: 13.3959 - val_loss: 22.0243\n",
      "Epoch 510/2000\n",
      "88/88 - 0s - loss: 11.6534 - val_loss: 23.7431\n",
      "Epoch 511/2000\n",
      "88/88 - 0s - loss: 12.9295 - val_loss: 22.0719\n",
      "Epoch 512/2000\n",
      "88/88 - 0s - loss: 12.3607 - val_loss: 22.0305\n",
      "Epoch 513/2000\n",
      "88/88 - 0s - loss: 12.8722 - val_loss: 25.6328\n",
      "Epoch 514/2000\n",
      "88/88 - 0s - loss: 11.9790 - val_loss: 21.8901\n",
      "Epoch 515/2000\n",
      "88/88 - 0s - loss: 12.6428 - val_loss: 20.4217\n",
      "Epoch 516/2000\n",
      "88/88 - 0s - loss: 12.5874 - val_loss: 20.8399\n",
      "Epoch 517/2000\n",
      "88/88 - 0s - loss: 12.3869 - val_loss: 22.9690\n",
      "Epoch 518/2000\n",
      "88/88 - 0s - loss: 13.0065 - val_loss: 23.2793\n",
      "Epoch 519/2000\n",
      "88/88 - 0s - loss: 11.6369 - val_loss: 22.6900\n",
      "Epoch 520/2000\n",
      "88/88 - 0s - loss: 13.8890 - val_loss: 22.5051\n",
      "Epoch 521/2000\n",
      "88/88 - 0s - loss: 15.2647 - val_loss: 23.8879\n",
      "Epoch 522/2000\n",
      "88/88 - 0s - loss: 14.3334 - val_loss: 21.5576\n",
      "Epoch 523/2000\n",
      "88/88 - 0s - loss: 12.6650 - val_loss: 22.2278\n",
      "Epoch 524/2000\n",
      "88/88 - 0s - loss: 12.3219 - val_loss: 21.7723\n",
      "Epoch 525/2000\n",
      "88/88 - 0s - loss: 15.0638 - val_loss: 22.7363\n",
      "Epoch 526/2000\n",
      "88/88 - 0s - loss: 16.6410 - val_loss: 24.1384\n",
      "Epoch 527/2000\n",
      "88/88 - 0s - loss: 14.9254 - val_loss: 22.7747\n",
      "Epoch 528/2000\n",
      "88/88 - 0s - loss: 14.5927 - val_loss: 25.5442\n",
      "Epoch 529/2000\n",
      "88/88 - 0s - loss: 14.1307 - val_loss: 22.9614\n",
      "Epoch 530/2000\n",
      "88/88 - 0s - loss: 13.2124 - val_loss: 20.8329\n",
      "Epoch 531/2000\n",
      "88/88 - 0s - loss: 12.6738 - val_loss: 21.4573\n",
      "Epoch 532/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 - 0s - loss: 12.8506 - val_loss: 23.3402\n",
      "Epoch 533/2000\n",
      "88/88 - 0s - loss: 15.0502 - val_loss: 25.8222\n",
      "Epoch 534/2000\n",
      "88/88 - 0s - loss: 14.0206 - val_loss: 23.5545\n",
      "Epoch 535/2000\n",
      "88/88 - 0s - loss: 12.7257 - val_loss: 24.1258\n",
      "Epoch 536/2000\n",
      "88/88 - 0s - loss: 13.1102 - val_loss: 23.2450\n",
      "Epoch 537/2000\n",
      "88/88 - 0s - loss: 13.1382 - val_loss: 26.6036\n",
      "Epoch 538/2000\n",
      "88/88 - 0s - loss: 12.4331 - val_loss: 21.6030\n",
      "Epoch 539/2000\n",
      "88/88 - 0s - loss: 12.0009 - val_loss: 22.8237\n",
      "Epoch 540/2000\n",
      "88/88 - 0s - loss: 11.8077 - val_loss: 21.2678\n",
      "Epoch 541/2000\n",
      "88/88 - 0s - loss: 12.2880 - val_loss: 23.0085\n",
      "Epoch 542/2000\n",
      "88/88 - 0s - loss: 12.2907 - val_loss: 21.3142\n",
      "Epoch 543/2000\n",
      "88/88 - 0s - loss: 12.5548 - val_loss: 23.9836\n",
      "Epoch 544/2000\n",
      "88/88 - 0s - loss: 12.8733 - val_loss: 23.4766\n",
      "Epoch 545/2000\n",
      "88/88 - 0s - loss: 12.6266 - val_loss: 23.7548\n",
      "Epoch 546/2000\n",
      "88/88 - 0s - loss: 12.7207 - val_loss: 22.1881\n",
      "Epoch 547/2000\n",
      "88/88 - 0s - loss: 12.4333 - val_loss: 21.7617\n",
      "Epoch 548/2000\n",
      "88/88 - 0s - loss: 12.3604 - val_loss: 22.3099\n",
      "Epoch 549/2000\n",
      "88/88 - 0s - loss: 13.3302 - val_loss: 23.5772\n",
      "Epoch 550/2000\n",
      "88/88 - 0s - loss: 11.2104 - val_loss: 24.0545\n",
      "Epoch 551/2000\n",
      "88/88 - 0s - loss: 11.5075 - val_loss: 21.0523\n",
      "Epoch 552/2000\n",
      "88/88 - 0s - loss: 10.9967 - val_loss: 20.8860\n",
      "Epoch 553/2000\n",
      "88/88 - 0s - loss: 11.6518 - val_loss: 21.2612\n",
      "Epoch 554/2000\n",
      "88/88 - 0s - loss: 11.2828 - val_loss: 23.6475\n",
      "Epoch 555/2000\n",
      "88/88 - 0s - loss: 11.5208 - val_loss: 23.2639\n",
      "Epoch 556/2000\n",
      "88/88 - 0s - loss: 12.2002 - val_loss: 20.8442\n",
      "Epoch 557/2000\n",
      "88/88 - 0s - loss: 10.7309 - val_loss: 20.9576\n",
      "Epoch 558/2000\n",
      "88/88 - 0s - loss: 12.3730 - val_loss: 22.7928\n",
      "Epoch 559/2000\n",
      "88/88 - 0s - loss: 13.1103 - val_loss: 21.6271\n",
      "Epoch 560/2000\n",
      "88/88 - 0s - loss: 11.1528 - val_loss: 20.9268\n",
      "Epoch 561/2000\n",
      "88/88 - 0s - loss: 10.5646 - val_loss: 21.0051\n",
      "Epoch 562/2000\n",
      "88/88 - 0s - loss: 10.5496 - val_loss: 21.1374\n",
      "Epoch 563/2000\n",
      "88/88 - 0s - loss: 11.9258 - val_loss: 21.9345\n",
      "Epoch 564/2000\n",
      "88/88 - 0s - loss: 11.9828 - val_loss: 23.3450\n",
      "Epoch 565/2000\n",
      "88/88 - 0s - loss: 13.3475 - val_loss: 23.8333\n",
      "Epoch 566/2000\n",
      "88/88 - 0s - loss: 12.0451 - val_loss: 19.7521\n",
      "Epoch 567/2000\n",
      "88/88 - 0s - loss: 12.3967 - val_loss: 21.1345\n",
      "Epoch 568/2000\n",
      "88/88 - 0s - loss: 11.5716 - val_loss: 22.1882\n",
      "Epoch 569/2000\n",
      "88/88 - 0s - loss: 12.0948 - val_loss: 21.9532\n",
      "Epoch 570/2000\n",
      "88/88 - 0s - loss: 10.6917 - val_loss: 25.0877\n",
      "Epoch 571/2000\n",
      "88/88 - 0s - loss: 11.4405 - val_loss: 22.8836\n",
      "Epoch 572/2000\n",
      "88/88 - 0s - loss: 11.8072 - val_loss: 21.4563\n",
      "Epoch 573/2000\n",
      "88/88 - 0s - loss: 11.7546 - val_loss: 24.4804\n",
      "Epoch 574/2000\n",
      "88/88 - 0s - loss: 13.0020 - val_loss: 21.7814\n",
      "Epoch 575/2000\n",
      "88/88 - 0s - loss: 12.1350 - val_loss: 23.5108\n",
      "Epoch 576/2000\n",
      "88/88 - 0s - loss: 11.6503 - val_loss: 21.0791\n",
      "Epoch 577/2000\n",
      "88/88 - 0s - loss: 12.5408 - val_loss: 20.7796\n",
      "Epoch 578/2000\n",
      "88/88 - 0s - loss: 13.3883 - val_loss: 22.6204\n",
      "Epoch 579/2000\n",
      "88/88 - 0s - loss: 14.3093 - val_loss: 22.4376\n",
      "Epoch 580/2000\n",
      "88/88 - 0s - loss: 11.4219 - val_loss: 23.2815\n",
      "Epoch 581/2000\n",
      "88/88 - 0s - loss: 12.1955 - val_loss: 22.9176\n",
      "Epoch 582/2000\n",
      "88/88 - 0s - loss: 12.8537 - val_loss: 21.4920\n",
      "Epoch 583/2000\n",
      "88/88 - 0s - loss: 11.1304 - val_loss: 20.3470\n",
      "Epoch 584/2000\n",
      "88/88 - 0s - loss: 11.8068 - val_loss: 20.7856\n",
      "Epoch 585/2000\n",
      "88/88 - 0s - loss: 11.8090 - val_loss: 20.8537\n",
      "Epoch 586/2000\n",
      "88/88 - 0s - loss: 12.6183 - val_loss: 27.1901\n",
      "Epoch 587/2000\n",
      "88/88 - 0s - loss: 13.9506 - val_loss: 23.0819\n",
      "Epoch 588/2000\n",
      "88/88 - 0s - loss: 12.1521 - val_loss: 21.3129\n",
      "Epoch 589/2000\n",
      "88/88 - 0s - loss: 11.3346 - val_loss: 24.7450\n",
      "Epoch 590/2000\n",
      "88/88 - 0s - loss: 11.0997 - val_loss: 22.2526\n",
      "Epoch 591/2000\n",
      "88/88 - 0s - loss: 12.9061 - val_loss: 21.5821\n",
      "Epoch 592/2000\n",
      "88/88 - 0s - loss: 11.0801 - val_loss: 22.1824\n",
      "Epoch 593/2000\n",
      "88/88 - 0s - loss: 12.5566 - val_loss: 21.5836\n",
      "Epoch 594/2000\n",
      "88/88 - 0s - loss: 11.2985 - val_loss: 21.1170\n",
      "Epoch 595/2000\n",
      "88/88 - 0s - loss: 11.7349 - val_loss: 20.8477\n",
      "Epoch 596/2000\n",
      "88/88 - 0s - loss: 10.7628 - val_loss: 22.2335\n",
      "Epoch 597/2000\n",
      "88/88 - 0s - loss: 11.4879 - val_loss: 20.6822\n",
      "Epoch 598/2000\n",
      "88/88 - 0s - loss: 12.1565 - val_loss: 21.8327\n",
      "Epoch 599/2000\n",
      "88/88 - 0s - loss: 12.7148 - val_loss: 26.4581\n",
      "Epoch 600/2000\n",
      "88/88 - 0s - loss: 13.1815 - val_loss: 22.4017\n",
      "Epoch 601/2000\n",
      "88/88 - 0s - loss: 11.9108 - val_loss: 21.2813\n",
      "Epoch 602/2000\n",
      "88/88 - 0s - loss: 12.0029 - val_loss: 20.6461\n",
      "Epoch 603/2000\n",
      "88/88 - 0s - loss: 16.0278 - val_loss: 24.7150\n",
      "Epoch 604/2000\n",
      "88/88 - 0s - loss: 15.5980 - val_loss: 24.1779\n",
      "Epoch 605/2000\n",
      "88/88 - 0s - loss: 13.8439 - val_loss: 22.2065\n",
      "Epoch 606/2000\n",
      "88/88 - 0s - loss: 12.5664 - val_loss: 22.3869\n",
      "Epoch 607/2000\n",
      "88/88 - 0s - loss: 11.1293 - val_loss: 21.6169\n",
      "Epoch 608/2000\n",
      "88/88 - 0s - loss: 11.1061 - val_loss: 21.1774\n",
      "Epoch 609/2000\n",
      "88/88 - 0s - loss: 11.0145 - val_loss: 22.7606\n",
      "Epoch 610/2000\n",
      "88/88 - 0s - loss: 11.6110 - val_loss: 20.9792\n",
      "Epoch 611/2000\n",
      "88/88 - 0s - loss: 10.1059 - val_loss: 20.8866\n",
      "Epoch 612/2000\n",
      "88/88 - 0s - loss: 11.2476 - val_loss: 22.8275\n",
      "Epoch 613/2000\n",
      "88/88 - 0s - loss: 11.4529 - val_loss: 21.9173\n",
      "Epoch 614/2000\n",
      "88/88 - 0s - loss: 11.4870 - val_loss: 23.8320\n",
      "Epoch 615/2000\n",
      "88/88 - 0s - loss: 12.0175 - val_loss: 22.5466\n",
      "Epoch 616/2000\n",
      "88/88 - 0s - loss: 13.7892 - val_loss: 23.2931\n",
      "Epoch 617/2000\n",
      "88/88 - 0s - loss: 13.2948 - val_loss: 21.9742\n",
      "Epoch 618/2000\n",
      "88/88 - 0s - loss: 12.5511 - val_loss: 23.1125\n",
      "Epoch 619/2000\n",
      "88/88 - 0s - loss: 12.2695 - val_loss: 23.1522\n",
      "Epoch 620/2000\n",
      "88/88 - 0s - loss: 13.8406 - val_loss: 23.2320\n",
      "Epoch 621/2000\n",
      "88/88 - 0s - loss: 15.0490 - val_loss: 22.2146\n",
      "Epoch 622/2000\n",
      "88/88 - 0s - loss: 13.2195 - val_loss: 25.1195\n",
      "Epoch 623/2000\n",
      "88/88 - 0s - loss: 13.2197 - val_loss: 22.6388\n",
      "Epoch 624/2000\n",
      "88/88 - 0s - loss: 13.1581 - val_loss: 22.9062\n",
      "Epoch 625/2000\n",
      "88/88 - 0s - loss: 12.9353 - val_loss: 22.1786\n",
      "Epoch 626/2000\n",
      "88/88 - 0s - loss: 17.4397 - val_loss: 25.9131\n",
      "Epoch 627/2000\n",
      "88/88 - 0s - loss: 17.3713 - val_loss: 23.0219\n",
      "Epoch 628/2000\n",
      "88/88 - 0s - loss: 16.7421 - val_loss: 25.4945\n",
      "Epoch 629/2000\n",
      "88/88 - 0s - loss: 15.5804 - val_loss: 26.3951\n",
      "Epoch 630/2000\n",
      "88/88 - 0s - loss: 15.2138 - val_loss: 24.7769\n",
      "Epoch 631/2000\n",
      "88/88 - 0s - loss: 16.8801 - val_loss: 23.7539\n",
      "Epoch 632/2000\n",
      "88/88 - 0s - loss: 13.6441 - val_loss: 22.5520\n",
      "Epoch 633/2000\n",
      "88/88 - 0s - loss: 12.5380 - val_loss: 24.9225\n",
      "Epoch 634/2000\n",
      "88/88 - 0s - loss: 12.7419 - val_loss: 21.7717\n",
      "Epoch 635/2000\n",
      "88/88 - 0s - loss: 11.8416 - val_loss: 22.9297\n",
      "Epoch 636/2000\n",
      "88/88 - 0s - loss: 11.8998 - val_loss: 22.5494\n",
      "Epoch 637/2000\n",
      "88/88 - 0s - loss: 12.5955 - val_loss: 25.5215\n",
      "Epoch 638/2000\n",
      "88/88 - 0s - loss: 13.1836 - val_loss: 22.6453\n",
      "Epoch 639/2000\n",
      "88/88 - 0s - loss: 10.7089 - val_loss: 22.3717\n",
      "Epoch 640/2000\n",
      "88/88 - 0s - loss: 11.5787 - val_loss: 23.4535\n",
      "Epoch 641/2000\n",
      "88/88 - 0s - loss: 11.4630 - val_loss: 24.6022\n",
      "Epoch 642/2000\n",
      "88/88 - 0s - loss: 11.3456 - val_loss: 21.6264\n",
      "Epoch 643/2000\n",
      "88/88 - 0s - loss: 10.6231 - val_loss: 22.0242\n",
      "Epoch 644/2000\n",
      "88/88 - 0s - loss: 10.8676 - val_loss: 23.3969\n",
      "Epoch 645/2000\n",
      "88/88 - 0s - loss: 11.3719 - val_loss: 21.5107\n",
      "Epoch 646/2000\n",
      "88/88 - 0s - loss: 11.1150 - val_loss: 22.4500\n",
      "Epoch 647/2000\n",
      "88/88 - 0s - loss: 11.4097 - val_loss: 21.3253\n",
      "Epoch 648/2000\n",
      "88/88 - 0s - loss: 11.0912 - val_loss: 21.3918\n",
      "Epoch 649/2000\n",
      "88/88 - 0s - loss: 10.7743 - val_loss: 21.8233\n",
      "Epoch 650/2000\n",
      "88/88 - 0s - loss: 10.3429 - val_loss: 20.8691\n",
      "Epoch 651/2000\n",
      "88/88 - 0s - loss: 10.4456 - val_loss: 21.0687\n",
      "Epoch 652/2000\n",
      "88/88 - 0s - loss: 10.4319 - val_loss: 21.3601\n",
      "Epoch 653/2000\n",
      "88/88 - 0s - loss: 10.1927 - val_loss: 23.8888\n",
      "Epoch 654/2000\n",
      "88/88 - 0s - loss: 12.9869 - val_loss: 22.5571\n",
      "Epoch 655/2000\n",
      "88/88 - 0s - loss: 13.3144 - val_loss: 22.9689\n",
      "Epoch 656/2000\n",
      "88/88 - 0s - loss: 11.4468 - val_loss: 21.7197\n",
      "Epoch 657/2000\n",
      "88/88 - 1s - loss: 10.7211 - val_loss: 22.0283\n",
      "Epoch 658/2000\n",
      "88/88 - 0s - loss: 11.5633 - val_loss: 21.5105\n",
      "Epoch 659/2000\n",
      "88/88 - 0s - loss: 11.4364 - val_loss: 29.6647\n",
      "Epoch 660/2000\n",
      "88/88 - 0s - loss: 12.2728 - val_loss: 22.0226\n",
      "Epoch 661/2000\n",
      "88/88 - 0s - loss: 15.1757 - val_loss: 22.5693\n",
      "Epoch 662/2000\n",
      "88/88 - 0s - loss: 12.5907 - val_loss: 21.8958\n",
      "Epoch 663/2000\n",
      "88/88 - 0s - loss: 11.3088 - val_loss: 20.9743\n",
      "Epoch 664/2000\n",
      "88/88 - 0s - loss: 10.3485 - val_loss: 20.8468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 665/2000\n",
      "88/88 - 0s - loss: 10.6863 - val_loss: 21.6621\n",
      "Epoch 666/2000\n",
      "88/88 - 0s - loss: 11.0250 - val_loss: 22.6044\n",
      "Epoch 667/2000\n",
      "88/88 - 0s - loss: 11.6398 - val_loss: 23.5096\n",
      "Epoch 668/2000\n",
      "88/88 - 0s - loss: 11.7260 - val_loss: 22.6128\n",
      "Epoch 669/2000\n",
      "88/88 - 0s - loss: 11.6666 - val_loss: 22.9972\n",
      "Epoch 670/2000\n",
      "88/88 - 0s - loss: 11.6391 - val_loss: 22.4225\n",
      "Epoch 671/2000\n",
      "88/88 - 0s - loss: 10.8964 - val_loss: 20.6489\n",
      "Epoch 672/2000\n",
      "88/88 - 0s - loss: 11.6848 - val_loss: 20.6785\n",
      "Epoch 673/2000\n",
      "88/88 - 0s - loss: 13.0905 - val_loss: 21.5193\n",
      "Epoch 674/2000\n",
      "88/88 - 0s - loss: 12.1534 - val_loss: 22.4701\n",
      "Epoch 675/2000\n",
      "88/88 - 0s - loss: 11.0865 - val_loss: 21.7900\n",
      "Epoch 676/2000\n",
      "88/88 - 0s - loss: 11.8774 - val_loss: 22.1776\n",
      "Epoch 677/2000\n",
      "88/88 - 0s - loss: 12.0948 - val_loss: 20.6719\n",
      "Epoch 678/2000\n",
      "88/88 - 0s - loss: 11.8966 - val_loss: 23.3754\n",
      "Epoch 679/2000\n",
      "88/88 - 0s - loss: 13.0759 - val_loss: 21.3295\n",
      "Epoch 680/2000\n",
      "88/88 - 0s - loss: 11.7973 - val_loss: 23.2327\n",
      "Epoch 681/2000\n",
      "88/88 - 0s - loss: 11.2150 - val_loss: 21.0892\n",
      "Epoch 682/2000\n",
      "88/88 - 0s - loss: 17.9918 - val_loss: 23.4253\n",
      "Epoch 683/2000\n",
      "88/88 - 0s - loss: 17.2115 - val_loss: 22.5933\n",
      "Epoch 684/2000\n",
      "88/88 - 0s - loss: 14.8903 - val_loss: 24.4529\n",
      "Epoch 685/2000\n",
      "88/88 - 0s - loss: 14.6344 - val_loss: 23.9758\n",
      "Epoch 686/2000\n",
      "88/88 - 0s - loss: 13.2444 - val_loss: 22.6529\n",
      "Epoch 687/2000\n",
      "88/88 - 0s - loss: 13.8173 - val_loss: 22.5905\n",
      "Epoch 688/2000\n",
      "88/88 - 0s - loss: 13.0504 - val_loss: 23.3121\n",
      "Epoch 689/2000\n",
      "88/88 - 0s - loss: 12.2628 - val_loss: 23.2549\n",
      "Epoch 690/2000\n",
      "88/88 - 0s - loss: 13.0063 - val_loss: 22.2251\n",
      "Epoch 691/2000\n",
      "88/88 - 0s - loss: 12.3532 - val_loss: 22.2557\n",
      "Epoch 692/2000\n",
      "88/88 - 0s - loss: 11.4421 - val_loss: 21.3917\n",
      "Epoch 693/2000\n",
      "88/88 - 0s - loss: 12.9677 - val_loss: 21.0251\n",
      "Epoch 694/2000\n",
      "88/88 - 0s - loss: 10.7667 - val_loss: 23.7916\n",
      "Epoch 695/2000\n",
      "88/88 - 0s - loss: 18.3400 - val_loss: 25.2796\n",
      "Epoch 696/2000\n",
      "88/88 - 0s - loss: 13.7344 - val_loss: 22.9084\n",
      "Epoch 697/2000\n",
      "88/88 - 0s - loss: 13.7731 - val_loss: 23.6337\n",
      "Epoch 698/2000\n",
      "88/88 - 0s - loss: 12.4969 - val_loss: 22.1237\n",
      "Epoch 699/2000\n",
      "88/88 - 0s - loss: 13.1974 - val_loss: 21.3454\n",
      "Epoch 700/2000\n",
      "88/88 - 0s - loss: 11.4234 - val_loss: 22.7868\n",
      "Epoch 701/2000\n",
      "88/88 - 0s - loss: 11.4913 - val_loss: 21.5369\n",
      "Epoch 702/2000\n",
      "88/88 - 0s - loss: 10.9309 - val_loss: 21.7518\n",
      "Epoch 703/2000\n",
      "88/88 - 0s - loss: 10.8721 - val_loss: 22.2179\n",
      "Epoch 704/2000\n",
      "88/88 - 0s - loss: 12.8183 - val_loss: 22.4728\n",
      "Epoch 705/2000\n",
      "88/88 - 0s - loss: 12.9219 - val_loss: 22.8131\n",
      "Epoch 706/2000\n",
      "88/88 - 0s - loss: 11.8890 - val_loss: 24.2912\n",
      "Epoch 707/2000\n",
      "88/88 - 0s - loss: 11.9779 - val_loss: 21.2309\n",
      "Epoch 708/2000\n",
      "88/88 - 0s - loss: 11.5279 - val_loss: 21.2999\n",
      "Epoch 709/2000\n",
      "88/88 - 0s - loss: 11.3727 - val_loss: 21.4319\n",
      "Epoch 710/2000\n",
      "88/88 - 0s - loss: 10.7876 - val_loss: 23.0896\n",
      "Epoch 711/2000\n",
      "88/88 - 0s - loss: 12.8665 - val_loss: 22.9523\n",
      "Epoch 712/2000\n",
      "88/88 - 0s - loss: 12.2003 - val_loss: 24.9276\n",
      "Epoch 713/2000\n",
      "88/88 - 0s - loss: 11.2948 - val_loss: 26.2035\n",
      "Epoch 714/2000\n",
      "88/88 - 0s - loss: 15.2638 - val_loss: 23.3613\n",
      "Epoch 715/2000\n",
      "88/88 - 0s - loss: 14.2039 - val_loss: 23.3651\n",
      "Epoch 716/2000\n",
      "88/88 - 0s - loss: 13.6458 - val_loss: 22.5555\n",
      "Epoch 717/2000\n",
      "88/88 - 0s - loss: 12.4709 - val_loss: 22.3860\n",
      "Epoch 718/2000\n",
      "88/88 - 0s - loss: 11.8193 - val_loss: 23.3815\n",
      "Epoch 719/2000\n",
      "88/88 - 0s - loss: 12.5194 - val_loss: 20.7452\n",
      "Epoch 720/2000\n",
      "88/88 - 0s - loss: 12.2330 - val_loss: 21.4291\n",
      "Epoch 721/2000\n",
      "88/88 - 0s - loss: 14.3334 - val_loss: 22.4595\n",
      "Epoch 722/2000\n",
      "88/88 - 0s - loss: 13.1287 - val_loss: 20.4920\n",
      "Epoch 723/2000\n",
      "88/88 - 0s - loss: 12.0100 - val_loss: 20.7637\n",
      "Epoch 724/2000\n",
      "88/88 - 0s - loss: 13.3792 - val_loss: 21.5376\n",
      "Epoch 725/2000\n",
      "88/88 - 0s - loss: 12.4810 - val_loss: 22.7674\n",
      "Epoch 726/2000\n",
      "88/88 - 0s - loss: 13.1790 - val_loss: 26.5403\n",
      "Epoch 727/2000\n",
      "88/88 - 0s - loss: 14.1245 - val_loss: 22.5146\n",
      "Epoch 728/2000\n",
      "88/88 - 0s - loss: 11.8246 - val_loss: 21.4804\n",
      "Epoch 729/2000\n",
      "88/88 - 0s - loss: 12.2104 - val_loss: 22.6534\n",
      "Epoch 730/2000\n",
      "88/88 - 0s - loss: 13.5970 - val_loss: 26.7345\n",
      "Epoch 731/2000\n",
      "88/88 - 0s - loss: 15.2147 - val_loss: 21.7135\n",
      "Epoch 732/2000\n",
      "88/88 - 0s - loss: 13.6287 - val_loss: 24.4546\n",
      "Epoch 733/2000\n",
      "88/88 - 0s - loss: 12.9973 - val_loss: 21.4010\n",
      "Epoch 734/2000\n",
      "88/88 - 0s - loss: 12.2402 - val_loss: 21.1615\n",
      "Epoch 735/2000\n",
      "88/88 - 0s - loss: 11.0704 - val_loss: 21.0882\n",
      "Epoch 736/2000\n",
      "88/88 - 0s - loss: 10.9593 - val_loss: 21.6867\n",
      "Epoch 737/2000\n",
      "88/88 - 0s - loss: 10.7785 - val_loss: 22.9715\n",
      "Epoch 738/2000\n",
      "88/88 - 0s - loss: 11.2673 - val_loss: 23.3557\n",
      "Epoch 739/2000\n",
      "88/88 - 0s - loss: 10.5166 - val_loss: 20.8821\n",
      "Epoch 740/2000\n",
      "88/88 - 0s - loss: 10.2745 - val_loss: 21.1805\n",
      "Epoch 741/2000\n",
      "88/88 - 0s - loss: 11.4260 - val_loss: 20.8420\n",
      "Epoch 742/2000\n",
      "88/88 - 0s - loss: 10.1803 - val_loss: 20.3022\n",
      "Epoch 743/2000\n",
      "88/88 - 0s - loss: 10.9818 - val_loss: 20.2917\n",
      "Epoch 744/2000\n",
      "88/88 - 0s - loss: 10.5804 - val_loss: 21.4473\n",
      "Epoch 745/2000\n",
      "88/88 - 0s - loss: 12.4060 - val_loss: 22.8658\n",
      "Epoch 746/2000\n",
      "88/88 - 0s - loss: 13.9071 - val_loss: 22.2549\n",
      "Epoch 747/2000\n",
      "88/88 - 0s - loss: 12.3222 - val_loss: 21.8499\n",
      "Epoch 748/2000\n",
      "88/88 - 0s - loss: 14.6479 - val_loss: 24.7153\n",
      "Epoch 749/2000\n",
      "88/88 - 0s - loss: 13.8453 - val_loss: 28.2078\n",
      "Epoch 750/2000\n",
      "88/88 - 0s - loss: 12.7590 - val_loss: 21.1357\n",
      "Epoch 751/2000\n",
      "88/88 - 0s - loss: 12.1889 - val_loss: 21.0053\n",
      "Epoch 752/2000\n",
      "88/88 - 0s - loss: 15.2186 - val_loss: 27.8713\n",
      "Epoch 753/2000\n",
      "88/88 - 0s - loss: 13.7690 - val_loss: 23.5697\n",
      "Epoch 754/2000\n",
      "88/88 - 0s - loss: 14.1355 - val_loss: 21.7347\n",
      "Epoch 755/2000\n",
      "88/88 - 0s - loss: 13.4822 - val_loss: 22.6799\n",
      "Epoch 756/2000\n",
      "88/88 - 0s - loss: 13.8351 - val_loss: 22.3447\n",
      "Epoch 757/2000\n",
      "88/88 - 0s - loss: 12.9469 - val_loss: 21.9603\n",
      "Epoch 758/2000\n",
      "88/88 - 0s - loss: 12.8246 - val_loss: 21.5403\n",
      "Epoch 759/2000\n",
      "88/88 - 0s - loss: 12.7279 - val_loss: 23.0223\n",
      "Epoch 760/2000\n",
      "88/88 - 0s - loss: 12.5531 - val_loss: 23.4279\n",
      "Epoch 761/2000\n",
      "88/88 - 0s - loss: 13.5054 - val_loss: 22.2719\n",
      "Epoch 762/2000\n",
      "88/88 - 0s - loss: 13.4883 - val_loss: 23.8763\n",
      "Epoch 763/2000\n",
      "88/88 - 0s - loss: 13.5464 - val_loss: 22.0919\n",
      "Epoch 764/2000\n",
      "88/88 - 0s - loss: 12.3727 - val_loss: 23.0677\n",
      "Epoch 765/2000\n",
      "88/88 - 0s - loss: 12.2415 - val_loss: 21.3737\n",
      "Epoch 766/2000\n",
      "88/88 - 0s - loss: 12.3227 - val_loss: 22.1000\n",
      "Epoch 767/2000\n",
      "88/88 - 0s - loss: 13.9688 - val_loss: 21.7249\n",
      "Epoch 768/2000\n",
      "88/88 - 0s - loss: 11.5819 - val_loss: 23.6131\n",
      "Epoch 769/2000\n",
      "88/88 - 0s - loss: 15.2039 - val_loss: 23.9385\n",
      "Epoch 770/2000\n",
      "88/88 - 0s - loss: 15.3458 - val_loss: 22.5157\n",
      "Epoch 771/2000\n",
      "88/88 - 0s - loss: 14.0516 - val_loss: 23.2927\n",
      "Epoch 772/2000\n",
      "88/88 - 0s - loss: 11.9502 - val_loss: 20.9020\n",
      "Epoch 773/2000\n",
      "88/88 - 0s - loss: 11.5441 - val_loss: 23.2308\n",
      "Epoch 774/2000\n",
      "88/88 - 0s - loss: 13.9725 - val_loss: 23.0964\n",
      "Epoch 775/2000\n",
      "88/88 - 0s - loss: 11.7760 - val_loss: 21.9082\n",
      "Epoch 776/2000\n",
      "88/88 - 0s - loss: 12.4417 - val_loss: 23.2098\n",
      "Epoch 777/2000\n",
      "88/88 - 0s - loss: 12.0274 - val_loss: 21.7101\n",
      "Epoch 778/2000\n",
      "88/88 - 0s - loss: 11.5785 - val_loss: 22.2463\n",
      "Epoch 779/2000\n",
      "88/88 - 0s - loss: 11.3892 - val_loss: 21.6974\n",
      "Epoch 780/2000\n",
      "88/88 - 0s - loss: 10.9822 - val_loss: 21.5275\n",
      "Epoch 781/2000\n",
      "88/88 - 0s - loss: 11.9263 - val_loss: 22.7902\n",
      "Epoch 782/2000\n",
      "88/88 - 0s - loss: 11.1806 - val_loss: 21.5730\n",
      "Epoch 783/2000\n",
      "88/88 - 0s - loss: 11.0844 - val_loss: 25.7558\n",
      "Epoch 784/2000\n",
      "88/88 - 0s - loss: 13.9576 - val_loss: 24.3895\n",
      "Epoch 785/2000\n",
      "88/88 - 0s - loss: 13.3733 - val_loss: 23.2022\n",
      "Epoch 786/2000\n",
      "88/88 - 0s - loss: 12.8372 - val_loss: 21.6089\n",
      "Epoch 787/2000\n",
      "88/88 - 0s - loss: 11.2449 - val_loss: 20.8623\n",
      "Epoch 788/2000\n",
      "88/88 - 0s - loss: 10.7741 - val_loss: 21.5805\n",
      "Epoch 789/2000\n",
      "88/88 - 0s - loss: 12.5998 - val_loss: 22.7622\n",
      "Epoch 790/2000\n",
      "88/88 - 0s - loss: 14.3230 - val_loss: 22.9913\n",
      "Epoch 791/2000\n",
      "88/88 - 0s - loss: 13.6147 - val_loss: 24.2591\n",
      "Epoch 792/2000\n",
      "88/88 - 2s - loss: 12.4641 - val_loss: 22.8437\n",
      "Epoch 793/2000\n",
      "88/88 - 0s - loss: 12.1717 - val_loss: 23.2246\n",
      "Epoch 794/2000\n",
      "88/88 - 0s - loss: 14.3571 - val_loss: 23.0037\n",
      "Epoch 795/2000\n",
      "88/88 - 0s - loss: 13.6862 - val_loss: 22.0837\n",
      "Epoch 796/2000\n",
      "88/88 - 0s - loss: 14.1101 - val_loss: 22.8223\n",
      "Epoch 797/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 - 0s - loss: 13.5466 - val_loss: 23.1230\n",
      "Epoch 798/2000\n",
      "88/88 - 0s - loss: 12.9675 - val_loss: 24.5267\n",
      "Epoch 799/2000\n",
      "88/88 - 0s - loss: 12.9071 - val_loss: 22.3658\n",
      "Epoch 800/2000\n",
      "88/88 - 0s - loss: 12.6913 - val_loss: 23.0830\n",
      "Epoch 801/2000\n",
      "88/88 - 0s - loss: 12.9754 - val_loss: 22.2462\n",
      "Epoch 802/2000\n",
      "88/88 - 0s - loss: 14.0457 - val_loss: 23.1072\n",
      "Epoch 803/2000\n",
      "88/88 - 0s - loss: 11.9056 - val_loss: 21.7956\n",
      "Epoch 804/2000\n",
      "88/88 - 0s - loss: 11.9086 - val_loss: 23.8639\n",
      "Epoch 805/2000\n",
      "88/88 - 0s - loss: 13.2370 - val_loss: 23.7218\n",
      "Epoch 806/2000\n",
      "88/88 - 0s - loss: 12.4334 - val_loss: 24.0324\n",
      "Epoch 807/2000\n",
      "88/88 - 0s - loss: 11.5863 - val_loss: 22.9526\n",
      "Epoch 808/2000\n",
      "88/88 - 0s - loss: 11.5065 - val_loss: 22.6724\n",
      "Epoch 809/2000\n",
      "88/88 - 0s - loss: 13.0170 - val_loss: 23.0484\n",
      "Epoch 810/2000\n",
      "88/88 - 0s - loss: 11.1775 - val_loss: 22.9998\n",
      "Epoch 811/2000\n",
      "88/88 - 0s - loss: 13.6802 - val_loss: 30.2194\n",
      "Epoch 812/2000\n",
      "88/88 - 0s - loss: 18.8476 - val_loss: 24.4853\n",
      "Epoch 813/2000\n",
      "88/88 - 0s - loss: 14.9851 - val_loss: 24.9258\n",
      "Epoch 814/2000\n",
      "88/88 - 0s - loss: 14.1164 - val_loss: 26.0020\n",
      "Epoch 815/2000\n",
      "88/88 - 0s - loss: 14.4880 - val_loss: 22.0353\n",
      "Epoch 816/2000\n",
      "88/88 - 0s - loss: 13.1950 - val_loss: 23.0941\n",
      "Epoch 817/2000\n",
      "88/88 - 0s - loss: 13.7002 - val_loss: 22.9941\n",
      "Epoch 818/2000\n",
      "88/88 - 0s - loss: 13.1275 - val_loss: 22.4332\n",
      "Epoch 819/2000\n",
      "88/88 - 0s - loss: 13.1358 - val_loss: 21.8790\n",
      "Epoch 820/2000\n",
      "88/88 - 0s - loss: 11.8903 - val_loss: 21.7960\n",
      "Epoch 821/2000\n",
      "88/88 - 0s - loss: 11.6534 - val_loss: 22.0651\n",
      "Epoch 822/2000\n",
      "88/88 - 0s - loss: 11.4616 - val_loss: 21.0985\n",
      "Epoch 823/2000\n",
      "88/88 - 0s - loss: 11.5064 - val_loss: 20.6101\n",
      "Epoch 824/2000\n",
      "88/88 - 0s - loss: 12.1376 - val_loss: 20.9605\n",
      "Epoch 825/2000\n",
      "88/88 - 0s - loss: 11.0882 - val_loss: 21.9738\n",
      "Epoch 826/2000\n",
      "88/88 - 0s - loss: 12.4918 - val_loss: 21.5972\n",
      "Epoch 827/2000\n",
      "88/88 - 0s - loss: 11.6205 - val_loss: 22.7479\n",
      "Epoch 828/2000\n",
      "88/88 - 0s - loss: 11.0676 - val_loss: 20.6313\n",
      "Epoch 829/2000\n",
      "88/88 - 0s - loss: 10.6330 - val_loss: 20.6996\n",
      "Epoch 830/2000\n",
      "88/88 - 0s - loss: 10.1949 - val_loss: 21.1745\n",
      "Epoch 831/2000\n",
      "88/88 - 0s - loss: 10.8361 - val_loss: 21.0476\n",
      "Epoch 832/2000\n",
      "88/88 - 0s - loss: 10.8391 - val_loss: 21.0429\n",
      "Epoch 833/2000\n",
      "88/88 - 0s - loss: 10.8984 - val_loss: 22.3035\n",
      "Epoch 834/2000\n",
      "88/88 - 0s - loss: 10.5044 - val_loss: 21.0196\n",
      "Epoch 835/2000\n",
      "88/88 - 0s - loss: 10.4833 - val_loss: 22.3998\n",
      "Epoch 836/2000\n",
      "88/88 - 0s - loss: 10.8598 - val_loss: 22.8032\n",
      "Epoch 837/2000\n",
      "88/88 - 0s - loss: 11.8775 - val_loss: 22.5432\n",
      "Epoch 838/2000\n",
      "88/88 - 0s - loss: 10.6873 - val_loss: 21.7523\n",
      "Epoch 839/2000\n",
      "88/88 - 0s - loss: 10.7948 - val_loss: 21.5338\n",
      "Epoch 840/2000\n",
      "88/88 - 0s - loss: 11.0901 - val_loss: 22.5478\n",
      "Epoch 841/2000\n",
      "88/88 - 0s - loss: 10.5743 - val_loss: 22.2199\n",
      "Epoch 842/2000\n",
      "88/88 - 0s - loss: 10.7626 - val_loss: 22.2092\n",
      "Epoch 843/2000\n",
      "88/88 - 0s - loss: 10.6542 - val_loss: 22.4404\n",
      "Epoch 844/2000\n",
      "88/88 - 0s - loss: 10.3517 - val_loss: 21.1239\n",
      "Epoch 845/2000\n",
      "88/88 - 0s - loss: 11.1855 - val_loss: 22.6487\n",
      "Epoch 846/2000\n",
      "88/88 - 0s - loss: 10.6195 - val_loss: 21.7170\n",
      "Epoch 847/2000\n",
      "88/88 - 0s - loss: 10.7492 - val_loss: 21.7371\n",
      "Epoch 848/2000\n",
      "88/88 - 0s - loss: 10.8124 - val_loss: 21.8306\n",
      "Epoch 849/2000\n",
      "88/88 - 0s - loss: 11.8358 - val_loss: 23.4816\n",
      "Epoch 850/2000\n",
      "88/88 - 0s - loss: 10.8006 - val_loss: 21.9912\n",
      "Epoch 851/2000\n",
      "88/88 - 0s - loss: 11.0445 - val_loss: 21.8858\n",
      "Epoch 852/2000\n",
      "88/88 - 0s - loss: 11.0253 - val_loss: 22.4623\n",
      "Epoch 853/2000\n",
      "88/88 - 0s - loss: 11.1275 - val_loss: 21.6515\n",
      "Epoch 854/2000\n",
      "88/88 - 0s - loss: 11.0183 - val_loss: 22.4564\n",
      "Epoch 855/2000\n",
      "88/88 - 0s - loss: 11.1624 - val_loss: 21.5501\n",
      "Epoch 856/2000\n",
      "88/88 - 0s - loss: 11.2402 - val_loss: 20.9037\n",
      "Epoch 857/2000\n",
      "88/88 - 0s - loss: 11.5815 - val_loss: 22.2924\n",
      "Epoch 858/2000\n",
      "88/88 - 0s - loss: 13.9416 - val_loss: 24.0678\n",
      "Epoch 859/2000\n",
      "88/88 - 0s - loss: 13.5829 - val_loss: 22.1071\n",
      "Epoch 860/2000\n",
      "88/88 - 0s - loss: 11.5574 - val_loss: 21.8741\n",
      "Epoch 861/2000\n",
      "88/88 - 0s - loss: 11.5283 - val_loss: 22.3915\n",
      "Epoch 862/2000\n",
      "88/88 - 0s - loss: 12.1042 - val_loss: 23.1602\n",
      "Epoch 863/2000\n",
      "88/88 - 0s - loss: 10.7480 - val_loss: 22.0380\n",
      "Epoch 864/2000\n",
      "88/88 - 0s - loss: 11.2720 - val_loss: 21.6972\n",
      "Epoch 865/2000\n",
      "88/88 - 0s - loss: 10.4923 - val_loss: 23.9297\n",
      "Epoch 866/2000\n",
      "88/88 - 0s - loss: 10.7063 - val_loss: 22.5481\n",
      "Epoch 867/2000\n",
      "88/88 - 0s - loss: 10.3332 - val_loss: 21.2121\n",
      "Epoch 868/2000\n",
      "88/88 - 0s - loss: 10.8012 - val_loss: 21.5710\n",
      "Epoch 869/2000\n",
      "88/88 - 0s - loss: 10.2826 - val_loss: 22.3889\n",
      "Epoch 870/2000\n",
      "88/88 - 0s - loss: 10.0943 - val_loss: 22.3416\n",
      "Epoch 871/2000\n",
      "88/88 - 0s - loss: 10.0586 - val_loss: 22.0592\n",
      "Epoch 872/2000\n",
      "88/88 - 0s - loss: 10.6612 - val_loss: 25.0133\n",
      "Epoch 873/2000\n",
      "88/88 - 0s - loss: 11.3422 - val_loss: 22.4588\n",
      "Epoch 874/2000\n",
      "88/88 - 0s - loss: 10.6036 - val_loss: 22.8363\n",
      "Epoch 875/2000\n",
      "88/88 - 0s - loss: 10.5335 - val_loss: 21.2640\n",
      "Epoch 876/2000\n",
      "88/88 - 0s - loss: 10.6874 - val_loss: 21.7599\n",
      "Epoch 877/2000\n",
      "88/88 - 0s - loss: 10.8692 - val_loss: 22.0596\n",
      "Epoch 878/2000\n",
      "88/88 - 0s - loss: 11.1225 - val_loss: 21.2669\n",
      "Epoch 879/2000\n",
      "88/88 - 0s - loss: 9.8037 - val_loss: 21.8420\n",
      "Epoch 880/2000\n",
      "88/88 - 0s - loss: 9.6981 - val_loss: 20.9162\n",
      "Epoch 881/2000\n",
      "88/88 - 0s - loss: 10.0885 - val_loss: 21.9226\n",
      "Epoch 882/2000\n",
      "88/88 - 0s - loss: 10.0960 - val_loss: 22.1470\n",
      "Epoch 883/2000\n",
      "88/88 - 0s - loss: 10.9437 - val_loss: 21.9035\n",
      "Epoch 884/2000\n",
      "88/88 - 0s - loss: 10.6199 - val_loss: 21.5653\n",
      "Epoch 885/2000\n",
      "88/88 - 0s - loss: 15.0994 - val_loss: 24.1182\n",
      "Epoch 886/2000\n",
      "88/88 - 0s - loss: 12.7996 - val_loss: 21.9861\n",
      "Epoch 887/2000\n",
      "88/88 - 0s - loss: 11.6019 - val_loss: 21.5221\n",
      "Epoch 888/2000\n",
      "88/88 - 0s - loss: 10.3640 - val_loss: 20.3992\n",
      "Epoch 889/2000\n",
      "88/88 - 0s - loss: 14.2262 - val_loss: 28.2003\n",
      "Epoch 890/2000\n",
      "88/88 - 0s - loss: 16.8579 - val_loss: 24.1896\n",
      "Epoch 891/2000\n",
      "88/88 - 0s - loss: 14.0306 - val_loss: 23.1234\n",
      "Epoch 892/2000\n",
      "88/88 - 0s - loss: 13.6387 - val_loss: 24.0286\n",
      "Epoch 893/2000\n",
      "88/88 - 0s - loss: 14.7221 - val_loss: 22.9737\n",
      "Epoch 894/2000\n",
      "88/88 - 0s - loss: 14.6116 - val_loss: 22.8682\n",
      "Epoch 895/2000\n",
      "88/88 - 0s - loss: 14.6083 - val_loss: 24.4788\n",
      "Epoch 896/2000\n",
      "88/88 - 0s - loss: 14.2402 - val_loss: 22.4032\n",
      "Epoch 897/2000\n",
      "88/88 - 0s - loss: 13.8005 - val_loss: 21.5189\n",
      "Epoch 898/2000\n",
      "88/88 - 0s - loss: 13.0105 - val_loss: 22.8898\n",
      "Epoch 899/2000\n",
      "88/88 - 0s - loss: 12.5591 - val_loss: 21.4166\n",
      "Epoch 900/2000\n",
      "88/88 - 0s - loss: 13.2107 - val_loss: 21.6156\n",
      "Epoch 901/2000\n",
      "88/88 - 0s - loss: 12.5183 - val_loss: 21.9229\n",
      "Epoch 902/2000\n",
      "88/88 - 0s - loss: 12.0939 - val_loss: 24.9048\n",
      "Epoch 903/2000\n",
      "88/88 - 0s - loss: 15.9831 - val_loss: 23.8190\n",
      "Epoch 904/2000\n",
      "88/88 - 0s - loss: 13.4587 - val_loss: 22.8321\n",
      "Epoch 905/2000\n",
      "88/88 - 0s - loss: 12.7509 - val_loss: 21.6836\n",
      "Epoch 906/2000\n",
      "88/88 - 0s - loss: 11.3882 - val_loss: 21.4979\n",
      "Epoch 907/2000\n",
      "88/88 - 0s - loss: 12.1166 - val_loss: 21.6126\n",
      "Epoch 908/2000\n",
      "88/88 - 1s - loss: 11.2490 - val_loss: 21.3001\n",
      "Epoch 909/2000\n",
      "88/88 - 0s - loss: 11.2684 - val_loss: 21.8553\n",
      "Epoch 910/2000\n",
      "88/88 - 0s - loss: 11.1358 - val_loss: 20.1414\n",
      "Epoch 911/2000\n",
      "88/88 - 0s - loss: 10.6284 - val_loss: 20.5144\n",
      "Epoch 912/2000\n",
      "88/88 - 0s - loss: 11.1125 - val_loss: 19.9764\n",
      "Epoch 913/2000\n",
      "88/88 - 0s - loss: 11.3170 - val_loss: 20.4641\n",
      "Epoch 914/2000\n",
      "88/88 - 0s - loss: 10.4511 - val_loss: 20.4835\n",
      "Epoch 915/2000\n",
      "88/88 - 0s - loss: 9.9343 - val_loss: 20.8325\n",
      "Epoch 916/2000\n",
      "88/88 - 0s - loss: 10.7711 - val_loss: 21.1723\n",
      "Epoch 917/2000\n",
      "88/88 - 0s - loss: 9.8691 - val_loss: 21.4188\n",
      "Epoch 918/2000\n",
      "88/88 - 0s - loss: 10.6710 - val_loss: 20.1450\n",
      "Epoch 919/2000\n",
      "88/88 - 0s - loss: 10.2984 - val_loss: 20.1026\n",
      "Epoch 920/2000\n",
      "88/88 - 0s - loss: 10.4299 - val_loss: 20.1742\n",
      "Epoch 921/2000\n",
      "88/88 - 0s - loss: 11.0506 - val_loss: 20.2480\n",
      "Epoch 922/2000\n",
      "88/88 - 0s - loss: 10.5051 - val_loss: 20.7645\n",
      "Epoch 923/2000\n",
      "88/88 - 0s - loss: 11.0776 - val_loss: 21.1399\n",
      "Epoch 924/2000\n",
      "88/88 - 0s - loss: 10.6076 - val_loss: 21.5807\n",
      "Epoch 925/2000\n",
      "88/88 - 0s - loss: 10.4432 - val_loss: 20.8085\n",
      "Epoch 926/2000\n",
      "88/88 - 0s - loss: 9.7974 - val_loss: 20.8351\n",
      "Epoch 927/2000\n",
      "88/88 - 0s - loss: 9.8513 - val_loss: 20.7221\n",
      "Epoch 928/2000\n",
      "88/88 - 0s - loss: 9.9745 - val_loss: 21.8473\n",
      "Epoch 929/2000\n",
      "88/88 - 0s - loss: 11.0826 - val_loss: 19.9503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 930/2000\n",
      "88/88 - 0s - loss: 9.5577 - val_loss: 19.0993\n",
      "Epoch 931/2000\n",
      "88/88 - 0s - loss: 10.3461 - val_loss: 20.1224\n",
      "Epoch 932/2000\n",
      "88/88 - 0s - loss: 11.9449 - val_loss: 21.6067\n",
      "Epoch 933/2000\n",
      "88/88 - 0s - loss: 12.6918 - val_loss: 20.4060\n",
      "Epoch 934/2000\n",
      "88/88 - 0s - loss: 11.6158 - val_loss: 20.0440\n",
      "Epoch 935/2000\n",
      "88/88 - 0s - loss: 10.3068 - val_loss: 20.2821\n",
      "Epoch 936/2000\n",
      "88/88 - 0s - loss: 10.0921 - val_loss: 19.1228\n",
      "Epoch 937/2000\n",
      "88/88 - 0s - loss: 11.4455 - val_loss: 20.3441\n",
      "Epoch 938/2000\n",
      "88/88 - 0s - loss: 12.2611 - val_loss: 21.5767\n",
      "Epoch 939/2000\n",
      "88/88 - 0s - loss: 11.6621 - val_loss: 20.2643\n",
      "Epoch 940/2000\n",
      "88/88 - 0s - loss: 10.1351 - val_loss: 19.2017\n",
      "Epoch 941/2000\n",
      "88/88 - 0s - loss: 9.9923 - val_loss: 20.7467\n",
      "Epoch 942/2000\n",
      "88/88 - 0s - loss: 10.3741 - val_loss: 19.6781\n",
      "Epoch 943/2000\n",
      "88/88 - 0s - loss: 9.7941 - val_loss: 20.0788\n",
      "Epoch 944/2000\n",
      "88/88 - 0s - loss: 10.3370 - val_loss: 19.6518\n",
      "Epoch 945/2000\n",
      "88/88 - 0s - loss: 10.7526 - val_loss: 20.4164\n",
      "Epoch 946/2000\n",
      "88/88 - 0s - loss: 9.8695 - val_loss: 22.6334\n",
      "Epoch 947/2000\n",
      "88/88 - 0s - loss: 11.0012 - val_loss: 23.0032\n",
      "Epoch 948/2000\n",
      "88/88 - 0s - loss: 11.5603 - val_loss: 21.8708\n",
      "Epoch 949/2000\n",
      "88/88 - 0s - loss: 10.6139 - val_loss: 19.7854\n",
      "Epoch 950/2000\n",
      "88/88 - 0s - loss: 10.7358 - val_loss: 21.8522\n",
      "Epoch 951/2000\n",
      "88/88 - 0s - loss: 10.6915 - val_loss: 21.5013\n",
      "Epoch 952/2000\n",
      "88/88 - 0s - loss: 9.9507 - val_loss: 20.7511\n",
      "Epoch 953/2000\n",
      "88/88 - 0s - loss: 10.2480 - val_loss: 20.6830\n",
      "Epoch 954/2000\n",
      "88/88 - 0s - loss: 12.5513 - val_loss: 21.1728\n",
      "Epoch 955/2000\n",
      "88/88 - 0s - loss: 11.6263 - val_loss: 21.7766\n",
      "Epoch 956/2000\n",
      "88/88 - 0s - loss: 12.3790 - val_loss: 21.1060\n",
      "Epoch 957/2000\n",
      "88/88 - 0s - loss: 11.5833 - val_loss: 21.4405\n",
      "Epoch 958/2000\n",
      "88/88 - 0s - loss: 11.1300 - val_loss: 20.6955\n",
      "Epoch 959/2000\n",
      "88/88 - 0s - loss: 11.4790 - val_loss: 21.2145\n",
      "Epoch 960/2000\n",
      "88/88 - 0s - loss: 11.5704 - val_loss: 21.3889\n",
      "Epoch 961/2000\n",
      "88/88 - 0s - loss: 10.2592 - val_loss: 22.6286\n",
      "Epoch 962/2000\n",
      "88/88 - 0s - loss: 10.0791 - val_loss: 20.9041\n",
      "Epoch 963/2000\n",
      "88/88 - 0s - loss: 11.1461 - val_loss: 20.7385\n",
      "Epoch 964/2000\n",
      "88/88 - 0s - loss: 9.7109 - val_loss: 20.3674\n",
      "Epoch 965/2000\n",
      "88/88 - 0s - loss: 9.3891 - val_loss: 21.7651\n",
      "Epoch 966/2000\n",
      "88/88 - 0s - loss: 10.3005 - val_loss: 23.6696\n",
      "Epoch 967/2000\n",
      "88/88 - 0s - loss: 13.6783 - val_loss: 20.8414\n",
      "Epoch 968/2000\n",
      "88/88 - 0s - loss: 13.8340 - val_loss: 23.3869\n",
      "Epoch 969/2000\n",
      "88/88 - 0s - loss: 12.7419 - val_loss: 22.5163\n",
      "Epoch 970/2000\n",
      "88/88 - 0s - loss: 11.5366 - val_loss: 21.8264\n",
      "Epoch 971/2000\n",
      "88/88 - 0s - loss: 10.4591 - val_loss: 20.9879\n",
      "Epoch 972/2000\n",
      "88/88 - 0s - loss: 9.6370 - val_loss: 21.4620\n",
      "Epoch 973/2000\n",
      "88/88 - 0s - loss: 10.0165 - val_loss: 21.8669\n",
      "Epoch 974/2000\n",
      "88/88 - 0s - loss: 9.7642 - val_loss: 20.7984\n",
      "Epoch 975/2000\n",
      "88/88 - 0s - loss: 10.0020 - val_loss: 21.4125\n",
      "Epoch 976/2000\n",
      "88/88 - 0s - loss: 9.9536 - val_loss: 25.2652\n",
      "Epoch 977/2000\n",
      "88/88 - 0s - loss: 10.3046 - val_loss: 22.7894\n",
      "Epoch 978/2000\n",
      "88/88 - 0s - loss: 10.1793 - val_loss: 21.7978\n",
      "Epoch 979/2000\n",
      "88/88 - 0s - loss: 10.5904 - val_loss: 21.0505\n",
      "Epoch 980/2000\n",
      "88/88 - 0s - loss: 11.9639 - val_loss: 22.0332\n",
      "Epoch 981/2000\n",
      "88/88 - 0s - loss: 10.1228 - val_loss: 20.9333\n",
      "Epoch 982/2000\n",
      "88/88 - 0s - loss: 9.8222 - val_loss: 25.3638\n",
      "Epoch 983/2000\n",
      "88/88 - 0s - loss: 13.3367 - val_loss: 23.1347\n",
      "Epoch 984/2000\n",
      "88/88 - 0s - loss: 12.2365 - val_loss: 23.3425\n",
      "Epoch 985/2000\n",
      "88/88 - 0s - loss: 12.5285 - val_loss: 22.9559\n",
      "Epoch 986/2000\n",
      "88/88 - 0s - loss: 11.0429 - val_loss: 21.6815\n",
      "Epoch 987/2000\n",
      "88/88 - 0s - loss: 10.0862 - val_loss: 20.5505\n",
      "Epoch 988/2000\n",
      "88/88 - 0s - loss: 9.6849 - val_loss: 21.4974\n",
      "Epoch 989/2000\n",
      "88/88 - 0s - loss: 9.5759 - val_loss: 21.4267\n",
      "Epoch 990/2000\n",
      "88/88 - 0s - loss: 8.9602 - val_loss: 24.6939\n",
      "Epoch 991/2000\n",
      "88/88 - 0s - loss: 9.6758 - val_loss: 20.9078\n",
      "Epoch 992/2000\n",
      "88/88 - 0s - loss: 9.8405 - val_loss: 21.2218\n",
      "Epoch 993/2000\n",
      "88/88 - 0s - loss: 9.2053 - val_loss: 20.7032\n",
      "Epoch 994/2000\n",
      "88/88 - 0s - loss: 9.4326 - val_loss: 22.8542\n",
      "Epoch 995/2000\n",
      "88/88 - 0s - loss: 9.3841 - val_loss: 22.7011\n",
      "Epoch 996/2000\n",
      "88/88 - 0s - loss: 8.9248 - val_loss: 21.7400\n",
      "Epoch 997/2000\n",
      "88/88 - 0s - loss: 8.8870 - val_loss: 21.7253\n",
      "Epoch 998/2000\n",
      "88/88 - 0s - loss: 10.4806 - val_loss: 21.5174\n",
      "Epoch 999/2000\n",
      "88/88 - 0s - loss: 10.3853 - val_loss: 21.9942\n",
      "Epoch 1000/2000\n",
      "88/88 - 0s - loss: 9.1911 - val_loss: 21.7120\n",
      "Epoch 1001/2000\n",
      "88/88 - 0s - loss: 9.1374 - val_loss: 21.3942\n",
      "Epoch 1002/2000\n",
      "88/88 - 0s - loss: 9.4788 - val_loss: 21.9695\n",
      "Epoch 1003/2000\n",
      "88/88 - 0s - loss: 9.7483 - val_loss: 21.8652\n",
      "Epoch 1004/2000\n",
      "88/88 - 0s - loss: 10.6373 - val_loss: 20.5256\n",
      "Epoch 1005/2000\n",
      "88/88 - 0s - loss: 9.8582 - val_loss: 21.9172\n",
      "Epoch 1006/2000\n",
      "88/88 - 0s - loss: 10.3391 - val_loss: 20.7576\n",
      "Epoch 1007/2000\n",
      "88/88 - 0s - loss: 9.3488 - val_loss: 21.0170\n",
      "Epoch 1008/2000\n",
      "88/88 - 0s - loss: 9.5001 - val_loss: 20.7431\n",
      "Epoch 1009/2000\n",
      "88/88 - 0s - loss: 10.1930 - val_loss: 23.4201\n",
      "Epoch 1010/2000\n",
      "88/88 - 0s - loss: 9.7594 - val_loss: 20.8738\n",
      "Epoch 1011/2000\n",
      "88/88 - 0s - loss: 9.0916 - val_loss: 20.3302\n",
      "Epoch 1012/2000\n",
      "88/88 - 0s - loss: 9.3825 - val_loss: 20.2433\n",
      "Epoch 1013/2000\n",
      "88/88 - 0s - loss: 10.5081 - val_loss: 20.0866\n",
      "Epoch 1014/2000\n",
      "88/88 - 0s - loss: 10.5968 - val_loss: 21.2066\n",
      "Epoch 1015/2000\n",
      "88/88 - 0s - loss: 11.2771 - val_loss: 22.9701\n",
      "Epoch 1016/2000\n",
      "88/88 - 0s - loss: 12.4436 - val_loss: 21.1995\n",
      "Epoch 1017/2000\n",
      "88/88 - 0s - loss: 11.0954 - val_loss: 21.3734\n",
      "Epoch 1018/2000\n",
      "88/88 - 0s - loss: 9.7843 - val_loss: 21.4089\n",
      "Epoch 1019/2000\n",
      "88/88 - 0s - loss: 9.3983 - val_loss: 19.6852\n",
      "Epoch 1020/2000\n",
      "88/88 - 0s - loss: 11.1171 - val_loss: 22.3505\n",
      "Epoch 1021/2000\n",
      "88/88 - 0s - loss: 12.0939 - val_loss: 21.2545\n",
      "Epoch 1022/2000\n",
      "88/88 - 0s - loss: 10.9559 - val_loss: 22.2658\n",
      "Epoch 1023/2000\n",
      "88/88 - 0s - loss: 10.0545 - val_loss: 20.5716\n",
      "Epoch 1024/2000\n",
      "88/88 - 0s - loss: 10.3571 - val_loss: 21.1953\n",
      "Epoch 1025/2000\n",
      "88/88 - 0s - loss: 10.3579 - val_loss: 21.5232\n",
      "Epoch 1026/2000\n",
      "88/88 - 0s - loss: 10.1285 - val_loss: 20.8238\n",
      "Epoch 1027/2000\n",
      "88/88 - 0s - loss: 10.5635 - val_loss: 21.0121\n",
      "Epoch 1028/2000\n",
      "88/88 - 0s - loss: 9.3363 - val_loss: 20.8388\n",
      "Epoch 1029/2000\n",
      "88/88 - 0s - loss: 9.8590 - val_loss: 22.2433\n",
      "Epoch 1030/2000\n",
      "88/88 - 0s - loss: 10.5167 - val_loss: 21.0300\n",
      "Epoch 1031/2000\n",
      "88/88 - 0s - loss: 10.2336 - val_loss: 23.0690\n",
      "Epoch 1032/2000\n",
      "88/88 - 0s - loss: 10.5278 - val_loss: 20.8800\n",
      "Epoch 1033/2000\n",
      "88/88 - 0s - loss: 9.9628 - val_loss: 21.6596\n",
      "Epoch 1034/2000\n",
      "88/88 - 0s - loss: 10.4022 - val_loss: 21.3306\n",
      "Epoch 1035/2000\n",
      "88/88 - 0s - loss: 9.1378 - val_loss: 21.1282\n",
      "Epoch 1036/2000\n",
      "88/88 - 0s - loss: 9.6924 - val_loss: 21.6759\n",
      "Epoch 1037/2000\n",
      "88/88 - 0s - loss: 9.0283 - val_loss: 20.0932\n",
      "Epoch 1038/2000\n",
      "88/88 - 0s - loss: 9.1155 - val_loss: 20.2715\n",
      "Epoch 1039/2000\n",
      "88/88 - 0s - loss: 8.9104 - val_loss: 21.1533\n",
      "Epoch 1040/2000\n",
      "88/88 - 0s - loss: 9.1908 - val_loss: 20.0706\n",
      "Epoch 1041/2000\n",
      "88/88 - 0s - loss: 8.7168 - val_loss: 21.2474\n",
      "Epoch 1042/2000\n",
      "88/88 - 0s - loss: 9.2923 - val_loss: 21.3295\n",
      "Epoch 1043/2000\n",
      "88/88 - 0s - loss: 15.8479 - val_loss: 21.9931\n",
      "Epoch 1044/2000\n",
      "88/88 - 0s - loss: 13.3007 - val_loss: 21.9949\n",
      "Epoch 1045/2000\n",
      "88/88 - 0s - loss: 11.9749 - val_loss: 22.4043\n",
      "Epoch 1046/2000\n",
      "88/88 - 0s - loss: 10.3490 - val_loss: 22.1106\n",
      "Epoch 1047/2000\n",
      "88/88 - 0s - loss: 10.3867 - val_loss: 21.7360\n",
      "Epoch 1048/2000\n",
      "88/88 - 0s - loss: 9.8709 - val_loss: 21.8402\n",
      "Epoch 1049/2000\n",
      "88/88 - 0s - loss: 9.5957 - val_loss: 20.6512\n",
      "Epoch 1050/2000\n",
      "88/88 - 0s - loss: 9.4757 - val_loss: 21.5367\n",
      "Epoch 1051/2000\n",
      "88/88 - 0s - loss: 8.9123 - val_loss: 20.7475\n",
      "Epoch 1052/2000\n",
      "88/88 - 0s - loss: 9.1700 - val_loss: 21.0983\n",
      "Epoch 1053/2000\n",
      "88/88 - 0s - loss: 12.9435 - val_loss: 23.5870\n",
      "Epoch 1054/2000\n",
      "88/88 - 0s - loss: 12.8506 - val_loss: 21.3282\n",
      "Epoch 1055/2000\n",
      "88/88 - 0s - loss: 9.9736 - val_loss: 23.5552\n",
      "Epoch 1056/2000\n",
      "88/88 - 0s - loss: 12.0844 - val_loss: 21.8450\n",
      "Epoch 1057/2000\n",
      "88/88 - 0s - loss: 11.0941 - val_loss: 21.0780\n",
      "Epoch 1058/2000\n",
      "88/88 - 0s - loss: 9.8281 - val_loss: 20.5661\n",
      "Epoch 1059/2000\n",
      "88/88 - 0s - loss: 9.0144 - val_loss: 20.8751\n",
      "Epoch 1060/2000\n",
      "88/88 - 0s - loss: 9.2982 - val_loss: 21.2526\n",
      "Epoch 1061/2000\n",
      "88/88 - 0s - loss: 9.9187 - val_loss: 20.7889\n",
      "Epoch 1062/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 - 0s - loss: 10.2928 - val_loss: 21.9436\n",
      "Epoch 1063/2000\n",
      "88/88 - 0s - loss: 8.8853 - val_loss: 21.2076\n",
      "Epoch 1064/2000\n",
      "88/88 - 0s - loss: 8.9635 - val_loss: 20.0308\n",
      "Epoch 1065/2000\n",
      "88/88 - 0s - loss: 8.3289 - val_loss: 20.7325\n",
      "Epoch 1066/2000\n",
      "88/88 - 0s - loss: 8.5314 - val_loss: 21.0429\n",
      "Epoch 1067/2000\n",
      "88/88 - 0s - loss: 8.9994 - val_loss: 21.1385\n",
      "Epoch 1068/2000\n",
      "88/88 - 0s - loss: 9.1593 - val_loss: 20.6730\n",
      "Epoch 1069/2000\n",
      "88/88 - 0s - loss: 8.4131 - val_loss: 20.7743\n",
      "Epoch 1070/2000\n",
      "88/88 - 0s - loss: 8.8012 - val_loss: 21.9030\n",
      "Epoch 1071/2000\n",
      "88/88 - 0s - loss: 8.8140 - val_loss: 19.8341\n",
      "Epoch 1072/2000\n",
      "88/88 - 0s - loss: 7.9635 - val_loss: 20.0873\n",
      "Epoch 1073/2000\n",
      "88/88 - 0s - loss: 8.4316 - val_loss: 21.4342\n",
      "Epoch 1074/2000\n",
      "88/88 - 0s - loss: 8.5068 - val_loss: 20.9659\n",
      "Epoch 1075/2000\n",
      "88/88 - 0s - loss: 10.1102 - val_loss: 21.1303\n",
      "Epoch 1076/2000\n",
      "88/88 - 0s - loss: 8.5900 - val_loss: 21.8659\n",
      "Epoch 1077/2000\n",
      "88/88 - 0s - loss: 8.8565 - val_loss: 20.1834\n",
      "Epoch 1078/2000\n",
      "88/88 - 0s - loss: 8.7397 - val_loss: 20.6127\n",
      "Epoch 1079/2000\n",
      "88/88 - 0s - loss: 8.6516 - val_loss: 19.5753\n",
      "Epoch 1080/2000\n",
      "88/88 - 0s - loss: 8.4597 - val_loss: 20.0192\n",
      "Epoch 1081/2000\n",
      "88/88 - 0s - loss: 7.8312 - val_loss: 19.5632\n",
      "Epoch 1082/2000\n",
      "88/88 - 0s - loss: 8.4989 - val_loss: 20.9029\n",
      "Epoch 1083/2000\n",
      "88/88 - 0s - loss: 9.3216 - val_loss: 21.9119\n",
      "Epoch 1084/2000\n",
      "88/88 - 0s - loss: 9.9829 - val_loss: 20.6858\n",
      "Epoch 1085/2000\n",
      "88/88 - 0s - loss: 8.8908 - val_loss: 20.1519\n",
      "Epoch 1086/2000\n",
      "88/88 - 0s - loss: 9.0413 - val_loss: 20.9965\n",
      "Epoch 1087/2000\n",
      "88/88 - 0s - loss: 8.5024 - val_loss: 19.8204\n",
      "Epoch 1088/2000\n",
      "88/88 - 0s - loss: 8.1036 - val_loss: 20.8531\n",
      "Epoch 1089/2000\n",
      "88/88 - 0s - loss: 8.5074 - val_loss: 20.4309\n",
      "Epoch 1090/2000\n",
      "88/88 - 0s - loss: 8.8138 - val_loss: 20.7410\n",
      "Epoch 1091/2000\n",
      "88/88 - 0s - loss: 9.0134 - val_loss: 22.1985\n",
      "Epoch 1092/2000\n",
      "88/88 - 0s - loss: 9.3603 - val_loss: 21.0278\n",
      "Epoch 1093/2000\n",
      "88/88 - 0s - loss: 9.4398 - val_loss: 20.7002\n",
      "Epoch 1094/2000\n",
      "88/88 - 0s - loss: 9.2976 - val_loss: 20.9975\n",
      "Epoch 1095/2000\n",
      "88/88 - 0s - loss: 8.9815 - val_loss: 22.1706\n",
      "Epoch 1096/2000\n",
      "88/88 - 0s - loss: 9.8208 - val_loss: 20.1448\n",
      "Epoch 1097/2000\n",
      "88/88 - 0s - loss: 8.4071 - val_loss: 20.4372\n",
      "Epoch 1098/2000\n",
      "88/88 - 0s - loss: 8.3053 - val_loss: 20.7681\n",
      "Epoch 1099/2000\n",
      "88/88 - 0s - loss: 8.9957 - val_loss: 22.4146\n",
      "Epoch 1100/2000\n",
      "88/88 - 0s - loss: 9.6607 - val_loss: 19.5995\n",
      "Epoch 1101/2000\n",
      "88/88 - 0s - loss: 8.7214 - val_loss: 19.7163\n",
      "Epoch 1102/2000\n",
      "88/88 - 0s - loss: 8.9964 - val_loss: 20.3778\n",
      "Epoch 1103/2000\n",
      "88/88 - 0s - loss: 8.9015 - val_loss: 20.2207\n",
      "Epoch 1104/2000\n",
      "88/88 - 0s - loss: 8.3067 - val_loss: 21.2500\n",
      "Epoch 1105/2000\n",
      "88/88 - 0s - loss: 9.2273 - val_loss: 21.4810\n",
      "Epoch 1106/2000\n",
      "88/88 - 0s - loss: 8.9102 - val_loss: 20.2726\n",
      "Epoch 1107/2000\n",
      "88/88 - 0s - loss: 9.2892 - val_loss: 20.7318\n",
      "Epoch 1108/2000\n",
      "88/88 - 0s - loss: 8.8211 - val_loss: 21.0809\n",
      "Epoch 1109/2000\n",
      "88/88 - 0s - loss: 9.3229 - val_loss: 20.2365\n",
      "Epoch 1110/2000\n",
      "88/88 - 0s - loss: 8.4803 - val_loss: 19.9735\n",
      "Epoch 1111/2000\n",
      "88/88 - 0s - loss: 8.7030 - val_loss: 22.4917\n",
      "Epoch 1112/2000\n",
      "88/88 - 0s - loss: 9.0383 - val_loss: 20.3529\n",
      "Epoch 1113/2000\n",
      "88/88 - 0s - loss: 8.6915 - val_loss: 20.3811\n",
      "Epoch 1114/2000\n",
      "88/88 - 0s - loss: 9.5721 - val_loss: 20.7286\n",
      "Epoch 1115/2000\n",
      "88/88 - 0s - loss: 10.1013 - val_loss: 23.0028\n",
      "Epoch 1116/2000\n",
      "88/88 - 0s - loss: 10.4250 - val_loss: 21.0162\n",
      "Epoch 1117/2000\n",
      "88/88 - 0s - loss: 8.8139 - val_loss: 20.8156\n",
      "Epoch 1118/2000\n",
      "88/88 - 0s - loss: 8.1777 - val_loss: 21.3585\n",
      "Epoch 1119/2000\n",
      "88/88 - 0s - loss: 8.3158 - val_loss: 20.5261\n",
      "Epoch 1120/2000\n",
      "88/88 - 0s - loss: 8.5115 - val_loss: 20.1779\n",
      "Epoch 1121/2000\n",
      "88/88 - 0s - loss: 8.2629 - val_loss: 20.2321\n",
      "Epoch 1122/2000\n",
      "88/88 - 0s - loss: 8.3532 - val_loss: 21.7774\n",
      "Epoch 1123/2000\n",
      "88/88 - 0s - loss: 8.8181 - val_loss: 21.2077\n",
      "Epoch 1124/2000\n",
      "88/88 - 0s - loss: 8.4845 - val_loss: 20.1911\n",
      "Epoch 1125/2000\n",
      "88/88 - 0s - loss: 9.2431 - val_loss: 22.9035\n",
      "Epoch 1126/2000\n",
      "88/88 - 0s - loss: 8.6166 - val_loss: 20.7729\n",
      "Epoch 1127/2000\n",
      "88/88 - 0s - loss: 8.5019 - val_loss: 20.5166\n",
      "Epoch 1128/2000\n",
      "88/88 - 0s - loss: 8.5118 - val_loss: 20.4551\n",
      "Epoch 1129/2000\n",
      "88/88 - 0s - loss: 9.3670 - val_loss: 20.8075\n",
      "Epoch 1130/2000\n",
      "88/88 - 0s - loss: 8.7286 - val_loss: 21.2851\n",
      "Epoch 1131/2000\n",
      "88/88 - 0s - loss: 8.6243 - val_loss: 21.7249\n",
      "Epoch 1132/2000\n",
      "88/88 - 0s - loss: 8.0695 - val_loss: 21.2597\n",
      "Epoch 1133/2000\n",
      "88/88 - 0s - loss: 9.0853 - val_loss: 20.5438\n",
      "Epoch 1134/2000\n",
      "88/88 - 0s - loss: 8.5045 - val_loss: 20.1714\n",
      "Epoch 1135/2000\n",
      "88/88 - 0s - loss: 8.7130 - val_loss: 22.1655\n",
      "Epoch 1136/2000\n",
      "88/88 - 0s - loss: 8.9954 - val_loss: 24.1288\n",
      "Epoch 1137/2000\n",
      "88/88 - 0s - loss: 11.5066 - val_loss: 21.7483\n",
      "Epoch 1138/2000\n",
      "88/88 - 0s - loss: 9.4376 - val_loss: 21.8104\n",
      "Epoch 1139/2000\n",
      "88/88 - 0s - loss: 9.5479 - val_loss: 22.1475\n",
      "Epoch 1140/2000\n",
      "88/88 - 0s - loss: 10.0025 - val_loss: 22.6921\n",
      "Epoch 1141/2000\n",
      "88/88 - 0s - loss: 9.2912 - val_loss: 20.8031\n",
      "Epoch 1142/2000\n",
      "88/88 - 0s - loss: 8.6369 - val_loss: 21.8605\n",
      "Epoch 1143/2000\n",
      "88/88 - 0s - loss: 10.3545 - val_loss: 22.1499\n",
      "Epoch 1144/2000\n",
      "88/88 - 0s - loss: 9.9709 - val_loss: 22.7799\n",
      "Epoch 1145/2000\n",
      "88/88 - 0s - loss: 10.4733 - val_loss: 20.9772\n",
      "Epoch 1146/2000\n",
      "88/88 - 0s - loss: 9.0656 - val_loss: 21.3107\n",
      "Epoch 1147/2000\n",
      "88/88 - 0s - loss: 9.9636 - val_loss: 21.9252\n",
      "Epoch 1148/2000\n",
      "88/88 - 0s - loss: 10.8556 - val_loss: 20.6219\n",
      "Epoch 1149/2000\n",
      "88/88 - 0s - loss: 9.2932 - val_loss: 20.9313\n",
      "Epoch 1150/2000\n",
      "88/88 - 0s - loss: 10.0522 - val_loss: 21.1985\n",
      "Epoch 1151/2000\n",
      "88/88 - 0s - loss: 9.6725 - val_loss: 22.6403\n",
      "Epoch 1152/2000\n",
      "88/88 - 0s - loss: 9.8466 - val_loss: 21.5409\n",
      "Epoch 1153/2000\n",
      "88/88 - 0s - loss: 9.4239 - val_loss: 21.4977\n",
      "Epoch 1154/2000\n",
      "88/88 - 0s - loss: 9.4229 - val_loss: 21.0910\n",
      "Epoch 1155/2000\n",
      "88/88 - 0s - loss: 9.1829 - val_loss: 21.2934\n",
      "Epoch 1156/2000\n",
      "88/88 - 0s - loss: 9.3472 - val_loss: 21.6702\n",
      "Epoch 1157/2000\n",
      "88/88 - 0s - loss: 9.2318 - val_loss: 20.8364\n",
      "Epoch 1158/2000\n",
      "88/88 - 0s - loss: 9.5099 - val_loss: 20.8108\n",
      "Epoch 1159/2000\n",
      "88/88 - 0s - loss: 8.4040 - val_loss: 20.6991\n",
      "Epoch 1160/2000\n",
      "88/88 - 0s - loss: 8.6915 - val_loss: 20.2403\n",
      "Epoch 1161/2000\n",
      "88/88 - 0s - loss: 8.5927 - val_loss: 19.6928\n",
      "Epoch 1162/2000\n",
      "88/88 - 0s - loss: 9.1434 - val_loss: 21.7447\n",
      "Epoch 1163/2000\n",
      "88/88 - 0s - loss: 9.3345 - val_loss: 21.3407\n",
      "Epoch 1164/2000\n",
      "88/88 - 0s - loss: 8.4514 - val_loss: 20.9312\n",
      "Epoch 1165/2000\n",
      "88/88 - 0s - loss: 8.8035 - val_loss: 21.6977\n",
      "Epoch 1166/2000\n",
      "88/88 - 0s - loss: 9.2363 - val_loss: 21.3993\n",
      "Epoch 1167/2000\n",
      "88/88 - 0s - loss: 9.2435 - val_loss: 20.9678\n",
      "Epoch 1168/2000\n",
      "88/88 - 0s - loss: 9.7197 - val_loss: 23.2800\n",
      "Epoch 1169/2000\n",
      "88/88 - 0s - loss: 9.4973 - val_loss: 21.0538\n",
      "Epoch 1170/2000\n",
      "88/88 - 0s - loss: 9.5931 - val_loss: 20.9209\n",
      "Epoch 1171/2000\n",
      "88/88 - 0s - loss: 8.2631 - val_loss: 20.3111\n",
      "Epoch 1172/2000\n",
      "88/88 - 0s - loss: 10.7142 - val_loss: 21.7324\n",
      "Epoch 1173/2000\n",
      "88/88 - 0s - loss: 9.0055 - val_loss: 21.2839\n",
      "Epoch 1174/2000\n",
      "88/88 - 0s - loss: 8.6839 - val_loss: 20.4483\n",
      "Epoch 1175/2000\n",
      "88/88 - 0s - loss: 8.8019 - val_loss: 20.2420\n",
      "Epoch 1176/2000\n",
      "88/88 - 0s - loss: 8.6617 - val_loss: 20.9422\n",
      "Epoch 1177/2000\n",
      "88/88 - 0s - loss: 9.1697 - val_loss: 20.9328\n",
      "Epoch 1178/2000\n",
      "88/88 - 0s - loss: 8.3219 - val_loss: 20.0712\n",
      "Epoch 1179/2000\n",
      "88/88 - 0s - loss: 9.3112 - val_loss: 20.1488\n",
      "Epoch 1180/2000\n",
      "88/88 - 0s - loss: 9.7091 - val_loss: 20.5140\n",
      "Epoch 1181/2000\n",
      "88/88 - 0s - loss: 8.9772 - val_loss: 20.4944\n",
      "Epoch 1182/2000\n",
      "88/88 - 0s - loss: 10.1472 - val_loss: 23.9793\n",
      "Epoch 1183/2000\n",
      "88/88 - 0s - loss: 12.3095 - val_loss: 22.6058\n",
      "Epoch 1184/2000\n",
      "88/88 - 0s - loss: 10.4320 - val_loss: 22.0831\n",
      "Epoch 1185/2000\n",
      "88/88 - 0s - loss: 9.7896 - val_loss: 21.0064\n",
      "Epoch 1186/2000\n",
      "88/88 - 0s - loss: 9.5926 - val_loss: 22.8843\n",
      "Epoch 1187/2000\n",
      "88/88 - 0s - loss: 9.8136 - val_loss: 20.3686\n",
      "Epoch 1188/2000\n",
      "88/88 - 0s - loss: 9.6117 - val_loss: 22.8441\n",
      "Epoch 1189/2000\n",
      "88/88 - 0s - loss: 8.5353 - val_loss: 20.5464\n",
      "Epoch 1190/2000\n",
      "88/88 - 0s - loss: 9.4311 - val_loss: 20.8642\n",
      "Epoch 1191/2000\n",
      "88/88 - 0s - loss: 8.8730 - val_loss: 22.0336\n",
      "Epoch 1192/2000\n",
      "88/88 - 0s - loss: 9.0243 - val_loss: 21.7894\n",
      "Epoch 1193/2000\n",
      "88/88 - 0s - loss: 10.7769 - val_loss: 22.1353\n",
      "Epoch 1194/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 - 0s - loss: 10.3525 - val_loss: 19.9315\n",
      "Epoch 1195/2000\n",
      "88/88 - 0s - loss: 9.1377 - val_loss: 20.7339\n",
      "Epoch 1196/2000\n",
      "88/88 - 0s - loss: 8.7614 - val_loss: 20.3191\n",
      "Epoch 1197/2000\n",
      "88/88 - 0s - loss: 9.0770 - val_loss: 20.2807\n",
      "Epoch 1198/2000\n",
      "88/88 - 0s - loss: 8.4524 - val_loss: 19.7102\n",
      "Epoch 1199/2000\n",
      "88/88 - 0s - loss: 8.4555 - val_loss: 19.9026\n",
      "Epoch 1200/2000\n",
      "88/88 - 0s - loss: 8.3683 - val_loss: 19.9766\n",
      "Epoch 1201/2000\n",
      "88/88 - 0s - loss: 8.5737 - val_loss: 21.2463\n",
      "Epoch 1202/2000\n",
      "88/88 - 0s - loss: 8.5552 - val_loss: 22.3320\n",
      "Epoch 1203/2000\n",
      "88/88 - 0s - loss: 9.2333 - val_loss: 21.9557\n",
      "Epoch 1204/2000\n",
      "88/88 - 0s - loss: 8.8280 - val_loss: 20.2196\n",
      "Epoch 1205/2000\n",
      "88/88 - 0s - loss: 8.3210 - val_loss: 22.1579\n",
      "Epoch 1206/2000\n",
      "88/88 - 0s - loss: 8.9970 - val_loss: 21.0998\n",
      "Epoch 1207/2000\n",
      "88/88 - 0s - loss: 9.2270 - val_loss: 20.4827\n",
      "Epoch 1208/2000\n",
      "88/88 - 0s - loss: 9.2162 - val_loss: 21.8460\n",
      "Epoch 1209/2000\n",
      "88/88 - 0s - loss: 8.5444 - val_loss: 20.1629\n",
      "Epoch 1210/2000\n",
      "88/88 - 0s - loss: 7.8152 - val_loss: 20.3330\n",
      "Epoch 1211/2000\n",
      "88/88 - 0s - loss: 8.4693 - val_loss: 20.8780\n",
      "Epoch 1212/2000\n",
      "88/88 - 0s - loss: 14.4654 - val_loss: 21.3974\n",
      "Epoch 1213/2000\n",
      "88/88 - 0s - loss: 13.4346 - val_loss: 21.0418\n",
      "Epoch 1214/2000\n",
      "88/88 - 0s - loss: 11.3962 - val_loss: 20.0431\n",
      "Epoch 1215/2000\n",
      "88/88 - 0s - loss: 11.3547 - val_loss: 20.0799\n",
      "Epoch 1216/2000\n",
      "88/88 - 0s - loss: 10.1351 - val_loss: 21.6878\n",
      "Epoch 1217/2000\n",
      "88/88 - 0s - loss: 11.1609 - val_loss: 21.2927\n",
      "Epoch 1218/2000\n",
      "88/88 - 0s - loss: 10.4940 - val_loss: 20.8112\n",
      "Epoch 1219/2000\n",
      "88/88 - 0s - loss: 9.9042 - val_loss: 19.7811\n",
      "Epoch 1220/2000\n",
      "88/88 - 0s - loss: 8.6846 - val_loss: 20.7339\n",
      "Epoch 1221/2000\n",
      "88/88 - 0s - loss: 8.7787 - val_loss: 20.2057\n",
      "Epoch 1222/2000\n",
      "88/88 - 0s - loss: 8.5263 - val_loss: 20.1918\n",
      "Epoch 1223/2000\n",
      "88/88 - 0s - loss: 8.5943 - val_loss: 20.3762\n",
      "Epoch 1224/2000\n",
      "88/88 - 0s - loss: 9.6487 - val_loss: 20.7845\n",
      "Epoch 1225/2000\n",
      "88/88 - 0s - loss: 9.1782 - val_loss: 19.9879\n",
      "Epoch 1226/2000\n",
      "88/88 - 0s - loss: 8.2797 - val_loss: 19.8578\n",
      "Epoch 1227/2000\n",
      "88/88 - 0s - loss: 9.2244 - val_loss: 20.2032\n",
      "Epoch 1228/2000\n",
      "88/88 - 0s - loss: 8.9522 - val_loss: 19.6166\n",
      "Epoch 1229/2000\n",
      "88/88 - 0s - loss: 8.9004 - val_loss: 23.1027\n",
      "Epoch 1230/2000\n",
      "88/88 - 0s - loss: 9.3230 - val_loss: 20.1084\n",
      "Epoch 1231/2000\n",
      "88/88 - 0s - loss: 8.6643 - val_loss: 20.7052\n",
      "Epoch 1232/2000\n",
      "88/88 - 0s - loss: 9.2637 - val_loss: 22.1972\n",
      "Epoch 1233/2000\n",
      "88/88 - 0s - loss: 12.2770 - val_loss: 22.7187\n",
      "Epoch 1234/2000\n",
      "88/88 - 0s - loss: 12.1355 - val_loss: 22.0334\n",
      "Epoch 1235/2000\n",
      "88/88 - 0s - loss: 10.1206 - val_loss: 21.6834\n",
      "Epoch 1236/2000\n",
      "88/88 - 0s - loss: 9.3096 - val_loss: 20.9231\n",
      "Epoch 1237/2000\n",
      "88/88 - 0s - loss: 8.7808 - val_loss: 21.5309\n",
      "Epoch 1238/2000\n",
      "88/88 - 0s - loss: 9.2243 - val_loss: 22.9618\n",
      "Epoch 1239/2000\n",
      "88/88 - 0s - loss: 8.8567 - val_loss: 22.3842\n",
      "Epoch 1240/2000\n",
      "88/88 - 0s - loss: 10.3216 - val_loss: 21.6492\n",
      "Epoch 1241/2000\n",
      "88/88 - 0s - loss: 8.9260 - val_loss: 20.4509\n",
      "Epoch 1242/2000\n",
      "88/88 - 0s - loss: 9.1351 - val_loss: 20.5640\n",
      "Epoch 1243/2000\n",
      "88/88 - 0s - loss: 8.6991 - val_loss: 20.1485\n",
      "Epoch 1244/2000\n",
      "88/88 - 0s - loss: 9.1728 - val_loss: 20.4748\n",
      "Epoch 1245/2000\n",
      "88/88 - 0s - loss: 10.5297 - val_loss: 21.1854\n",
      "Epoch 1246/2000\n",
      "88/88 - 0s - loss: 9.4254 - val_loss: 20.4503\n",
      "Epoch 1247/2000\n",
      "88/88 - 0s - loss: 9.0053 - val_loss: 21.2504\n",
      "Epoch 1248/2000\n",
      "88/88 - 0s - loss: 9.3219 - val_loss: 20.0423\n",
      "Epoch 1249/2000\n",
      "88/88 - 0s - loss: 9.4946 - val_loss: 21.1382\n",
      "Epoch 1250/2000\n",
      "88/88 - 0s - loss: 9.1378 - val_loss: 19.9201\n",
      "Epoch 1251/2000\n",
      "88/88 - 0s - loss: 8.6027 - val_loss: 19.7767\n",
      "Epoch 1252/2000\n",
      "88/88 - 0s - loss: 8.1805 - val_loss: 20.7182\n",
      "Epoch 1253/2000\n",
      "88/88 - 0s - loss: 8.2135 - val_loss: 19.9308\n",
      "Epoch 1254/2000\n",
      "88/88 - 0s - loss: 7.7306 - val_loss: 20.3339\n",
      "Epoch 1255/2000\n",
      "88/88 - 0s - loss: 8.4354 - val_loss: 19.9902\n",
      "Epoch 1256/2000\n",
      "88/88 - 0s - loss: 7.7921 - val_loss: 20.3348\n",
      "Epoch 1257/2000\n",
      "88/88 - 0s - loss: 8.3617 - val_loss: 22.4832\n",
      "Epoch 1258/2000\n",
      "88/88 - 0s - loss: 9.0486 - val_loss: 22.1343\n",
      "Epoch 1259/2000\n",
      "88/88 - 0s - loss: 9.0249 - val_loss: 20.1192\n",
      "Epoch 1260/2000\n",
      "88/88 - 0s - loss: 7.9618 - val_loss: 20.2051\n",
      "Epoch 1261/2000\n",
      "88/88 - 0s - loss: 7.5904 - val_loss: 20.1157\n",
      "Epoch 1262/2000\n",
      "88/88 - 0s - loss: 7.4678 - val_loss: 20.9036\n",
      "Epoch 1263/2000\n",
      "88/88 - 0s - loss: 8.1817 - val_loss: 19.6422\n",
      "Epoch 1264/2000\n",
      "88/88 - 0s - loss: 7.8922 - val_loss: 20.9794\n",
      "Epoch 1265/2000\n",
      "88/88 - 0s - loss: 7.9766 - val_loss: 20.4291\n",
      "Epoch 1266/2000\n",
      "88/88 - 0s - loss: 8.2755 - val_loss: 20.3032\n",
      "Epoch 1267/2000\n",
      "88/88 - 0s - loss: 7.5632 - val_loss: 19.3393\n",
      "Epoch 1268/2000\n",
      "88/88 - 0s - loss: 7.5569 - val_loss: 20.6975\n",
      "Epoch 1269/2000\n",
      "88/88 - 0s - loss: 8.0903 - val_loss: 19.8805\n",
      "Epoch 1270/2000\n",
      "88/88 - 0s - loss: 7.4222 - val_loss: 20.1655\n",
      "Epoch 1271/2000\n",
      "88/88 - 0s - loss: 9.2722 - val_loss: 20.8971\n",
      "Epoch 1272/2000\n",
      "88/88 - 0s - loss: 9.4248 - val_loss: 20.1116\n",
      "Epoch 1273/2000\n",
      "88/88 - 0s - loss: 8.7332 - val_loss: 20.4906\n",
      "Epoch 1274/2000\n",
      "88/88 - 0s - loss: 10.4598 - val_loss: 21.5150\n",
      "Epoch 1275/2000\n",
      "88/88 - 0s - loss: 10.6500 - val_loss: 21.4520\n",
      "Epoch 1276/2000\n",
      "88/88 - 0s - loss: 10.9843 - val_loss: 21.1914\n",
      "Epoch 1277/2000\n",
      "88/88 - 0s - loss: 9.9540 - val_loss: 20.7618\n",
      "Epoch 1278/2000\n",
      "88/88 - 0s - loss: 9.0093 - val_loss: 21.5015\n",
      "Epoch 1279/2000\n",
      "88/88 - 0s - loss: 9.4402 - val_loss: 22.1560\n",
      "Epoch 1280/2000\n",
      "88/88 - 0s - loss: 9.5410 - val_loss: 20.9477\n",
      "Epoch 1281/2000\n",
      "88/88 - 0s - loss: 9.5885 - val_loss: 20.3971\n",
      "Epoch 1282/2000\n",
      "88/88 - 0s - loss: 10.0512 - val_loss: 21.2358\n",
      "Epoch 1283/2000\n",
      "88/88 - 0s - loss: 9.3783 - val_loss: 21.1227\n",
      "Epoch 1284/2000\n",
      "88/88 - 0s - loss: 8.5015 - val_loss: 20.4328\n",
      "Epoch 1285/2000\n",
      "88/88 - 0s - loss: 8.1779 - val_loss: 20.1254\n",
      "Epoch 1286/2000\n",
      "88/88 - 0s - loss: 8.4229 - val_loss: 20.8217\n",
      "Epoch 1287/2000\n",
      "88/88 - 0s - loss: 8.3953 - val_loss: 20.0761\n",
      "Epoch 1288/2000\n",
      "88/88 - 0s - loss: 8.3334 - val_loss: 20.4893\n",
      "Epoch 1289/2000\n",
      "88/88 - 0s - loss: 9.0835 - val_loss: 20.6272\n",
      "Epoch 1290/2000\n",
      "88/88 - 0s - loss: 8.8420 - val_loss: 19.5631\n",
      "Epoch 1291/2000\n",
      "88/88 - 0s - loss: 8.6824 - val_loss: 21.2564\n",
      "Epoch 1292/2000\n",
      "88/88 - 0s - loss: 8.1481 - val_loss: 19.4660\n",
      "Epoch 1293/2000\n",
      "88/88 - 0s - loss: 8.0688 - val_loss: 19.4171\n",
      "Epoch 1294/2000\n",
      "88/88 - 0s - loss: 8.0148 - val_loss: 19.3597\n",
      "Epoch 1295/2000\n",
      "88/88 - 0s - loss: 7.5646 - val_loss: 20.6871\n",
      "Epoch 1296/2000\n",
      "88/88 - 0s - loss: 7.9159 - val_loss: 19.4725\n",
      "Epoch 1297/2000\n",
      "88/88 - 0s - loss: 7.4908 - val_loss: 21.7855\n",
      "Epoch 1298/2000\n",
      "88/88 - 0s - loss: 8.3225 - val_loss: 19.3806\n",
      "Epoch 1299/2000\n",
      "88/88 - 0s - loss: 9.1215 - val_loss: 19.4592\n",
      "Epoch 1300/2000\n",
      "88/88 - 0s - loss: 9.4654 - val_loss: 21.0294\n",
      "Epoch 1301/2000\n",
      "88/88 - 0s - loss: 8.6403 - val_loss: 21.2057\n",
      "Epoch 1302/2000\n",
      "88/88 - 0s - loss: 8.3191 - val_loss: 19.4434\n",
      "Epoch 1303/2000\n",
      "88/88 - 0s - loss: 12.5265 - val_loss: 24.7614\n",
      "Epoch 1304/2000\n",
      "88/88 - 0s - loss: 10.9094 - val_loss: 23.1348\n",
      "Epoch 1305/2000\n",
      "88/88 - 0s - loss: 9.8608 - val_loss: 22.0168\n",
      "Epoch 1306/2000\n",
      "88/88 - 0s - loss: 10.2894 - val_loss: 21.1778\n",
      "Epoch 1307/2000\n",
      "88/88 - 0s - loss: 10.0084 - val_loss: 20.7399\n",
      "Epoch 1308/2000\n",
      "88/88 - 0s - loss: 8.4461 - val_loss: 22.3491\n",
      "Epoch 1309/2000\n",
      "88/88 - 0s - loss: 8.4049 - val_loss: 21.5778\n",
      "Epoch 1310/2000\n",
      "88/88 - 0s - loss: 8.2382 - val_loss: 20.6133\n",
      "Epoch 1311/2000\n",
      "88/88 - 0s - loss: 7.3487 - val_loss: 20.7027\n",
      "Epoch 1312/2000\n",
      "88/88 - 0s - loss: 10.1839 - val_loss: 21.1667\n",
      "Epoch 1313/2000\n",
      "88/88 - 0s - loss: 9.5124 - val_loss: 19.9514\n",
      "Epoch 1314/2000\n",
      "88/88 - 0s - loss: 9.2739 - val_loss: 20.9066\n",
      "Epoch 1315/2000\n",
      "88/88 - 0s - loss: 9.3474 - val_loss: 22.5855\n",
      "Epoch 1316/2000\n",
      "88/88 - 0s - loss: 9.2236 - val_loss: 19.6595\n",
      "Epoch 1317/2000\n",
      "88/88 - 0s - loss: 8.3062 - val_loss: 21.1247\n",
      "Epoch 1318/2000\n",
      "88/88 - 0s - loss: 8.2328 - val_loss: 19.1880\n",
      "Epoch 1319/2000\n",
      "88/88 - 0s - loss: 8.8685 - val_loss: 20.1488\n",
      "Epoch 1320/2000\n",
      "88/88 - 0s - loss: 8.2398 - val_loss: 19.1949\n",
      "Epoch 1321/2000\n",
      "88/88 - 0s - loss: 8.2983 - val_loss: 20.1700\n",
      "Epoch 1322/2000\n",
      "88/88 - 0s - loss: 8.1483 - val_loss: 19.5039\n",
      "Epoch 1323/2000\n",
      "88/88 - 0s - loss: 7.8932 - val_loss: 20.0219\n",
      "Epoch 1324/2000\n",
      "88/88 - 0s - loss: 8.3055 - val_loss: 19.9720\n",
      "Epoch 1325/2000\n",
      "88/88 - 0s - loss: 7.9663 - val_loss: 21.0281\n",
      "Epoch 1326/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 - 0s - loss: 9.0880 - val_loss: 18.9533\n",
      "Epoch 1327/2000\n",
      "88/88 - 0s - loss: 7.1649 - val_loss: 18.5252\n",
      "Epoch 1328/2000\n",
      "88/88 - 0s - loss: 7.1410 - val_loss: 19.9931\n",
      "Epoch 1329/2000\n",
      "88/88 - 0s - loss: 8.6593 - val_loss: 19.4164\n",
      "Epoch 1330/2000\n",
      "88/88 - 0s - loss: 7.8242 - val_loss: 20.1871\n",
      "Epoch 1331/2000\n",
      "88/88 - 0s - loss: 8.2771 - val_loss: 20.8779\n",
      "Epoch 1332/2000\n",
      "88/88 - 0s - loss: 7.9698 - val_loss: 20.4842\n",
      "Epoch 1333/2000\n",
      "88/88 - 0s - loss: 8.5935 - val_loss: 20.3556\n",
      "Epoch 1334/2000\n",
      "88/88 - 0s - loss: 7.6656 - val_loss: 18.8752\n",
      "Epoch 1335/2000\n",
      "88/88 - 0s - loss: 7.9781 - val_loss: 20.2713\n",
      "Epoch 1336/2000\n",
      "88/88 - 0s - loss: 7.7039 - val_loss: 19.6343\n",
      "Epoch 1337/2000\n",
      "88/88 - 0s - loss: 7.8889 - val_loss: 21.1035\n",
      "Epoch 1338/2000\n",
      "88/88 - 0s - loss: 7.5010 - val_loss: 21.3060\n",
      "Epoch 1339/2000\n",
      "88/88 - 0s - loss: 8.4726 - val_loss: 22.5921\n",
      "Epoch 1340/2000\n",
      "88/88 - 0s - loss: 11.4826 - val_loss: 20.1624\n",
      "Epoch 1341/2000\n",
      "88/88 - 0s - loss: 9.5530 - val_loss: 21.1237\n",
      "Epoch 1342/2000\n",
      "88/88 - 0s - loss: 9.5722 - val_loss: 21.4125\n",
      "Epoch 1343/2000\n",
      "88/88 - 0s - loss: 9.2001 - val_loss: 20.3705\n",
      "Epoch 1344/2000\n",
      "88/88 - 0s - loss: 8.0462 - val_loss: 20.4730\n",
      "Epoch 1345/2000\n",
      "88/88 - 0s - loss: 9.0318 - val_loss: 19.6940\n",
      "Epoch 1346/2000\n",
      "88/88 - 0s - loss: 8.9160 - val_loss: 20.1178\n",
      "Epoch 1347/2000\n",
      "88/88 - 0s - loss: 8.9777 - val_loss: 20.5584\n",
      "Epoch 1348/2000\n",
      "88/88 - 0s - loss: 9.1530 - val_loss: 20.0069\n",
      "Epoch 1349/2000\n",
      "88/88 - 0s - loss: 8.0905 - val_loss: 20.1201\n",
      "Epoch 1350/2000\n",
      "88/88 - 0s - loss: 7.8558 - val_loss: 19.3762\n",
      "Epoch 1351/2000\n",
      "88/88 - 0s - loss: 8.7190 - val_loss: 19.8672\n",
      "Epoch 1352/2000\n",
      "88/88 - 0s - loss: 9.1004 - val_loss: 20.3941\n",
      "Epoch 1353/2000\n",
      "88/88 - 0s - loss: 8.1317 - val_loss: 19.5289\n",
      "Epoch 1354/2000\n",
      "88/88 - 0s - loss: 8.2479 - val_loss: 21.2404\n",
      "Epoch 1355/2000\n",
      "88/88 - 0s - loss: 8.6620 - val_loss: 19.2055\n",
      "Epoch 1356/2000\n",
      "88/88 - 0s - loss: 7.2301 - val_loss: 19.5406\n",
      "Epoch 1357/2000\n",
      "88/88 - 0s - loss: 7.7510 - val_loss: 18.8382\n",
      "Epoch 1358/2000\n",
      "88/88 - 0s - loss: 9.0360 - val_loss: 19.9414\n",
      "Epoch 1359/2000\n",
      "88/88 - 0s - loss: 9.0989 - val_loss: 20.2129\n",
      "Epoch 1360/2000\n",
      "88/88 - 0s - loss: 9.1840 - val_loss: 20.0017\n",
      "Epoch 1361/2000\n",
      "88/88 - 0s - loss: 8.2203 - val_loss: 20.9393\n",
      "Epoch 1362/2000\n",
      "88/88 - 0s - loss: 10.1705 - val_loss: 20.1838\n",
      "Epoch 1363/2000\n",
      "88/88 - 0s - loss: 9.1002 - val_loss: 20.5516\n",
      "Epoch 1364/2000\n",
      "88/88 - 0s - loss: 8.6873 - val_loss: 20.3306\n",
      "Epoch 1365/2000\n",
      "88/88 - 0s - loss: 9.1931 - val_loss: 20.8438\n",
      "Epoch 1366/2000\n",
      "88/88 - 0s - loss: 8.5578 - val_loss: 20.8292\n",
      "Epoch 1367/2000\n",
      "88/88 - 0s - loss: 8.4365 - val_loss: 21.0971\n",
      "Epoch 1368/2000\n",
      "88/88 - 0s - loss: 7.9160 - val_loss: 21.0774\n",
      "Epoch 1369/2000\n",
      "88/88 - 0s - loss: 9.0660 - val_loss: 22.3382\n",
      "Epoch 1370/2000\n",
      "88/88 - 0s - loss: 8.6988 - val_loss: 20.5641\n",
      "Epoch 1371/2000\n",
      "88/88 - 0s - loss: 8.3434 - val_loss: 21.0318\n",
      "Epoch 1372/2000\n",
      "88/88 - 0s - loss: 7.6455 - val_loss: 20.7819\n",
      "Epoch 1373/2000\n",
      "88/88 - 0s - loss: 7.7343 - val_loss: 21.7677\n",
      "Epoch 1374/2000\n",
      "88/88 - 0s - loss: 8.0576 - val_loss: 19.4976\n",
      "Epoch 1375/2000\n",
      "88/88 - 0s - loss: 7.8284 - val_loss: 19.5440\n",
      "Epoch 1376/2000\n",
      "88/88 - 0s - loss: 7.3426 - val_loss: 20.0395\n",
      "Epoch 1377/2000\n",
      "88/88 - 0s - loss: 7.5742 - val_loss: 20.2120\n",
      "Epoch 1378/2000\n",
      "88/88 - 0s - loss: 8.3974 - val_loss: 20.7190\n",
      "Epoch 1379/2000\n",
      "88/88 - 0s - loss: 7.8731 - val_loss: 19.9281\n",
      "Epoch 1380/2000\n",
      "88/88 - 0s - loss: 8.1337 - val_loss: 20.0905\n",
      "Epoch 1381/2000\n",
      "88/88 - 0s - loss: 7.8215 - val_loss: 18.6815\n",
      "Epoch 1382/2000\n",
      "88/88 - 0s - loss: 7.8799 - val_loss: 20.8276\n",
      "Epoch 1383/2000\n",
      "88/88 - 0s - loss: 8.5955 - val_loss: 19.6895\n",
      "Epoch 1384/2000\n",
      "88/88 - 0s - loss: 7.4045 - val_loss: 19.9577\n",
      "Epoch 1385/2000\n",
      "88/88 - 0s - loss: 8.1774 - val_loss: 19.8345\n",
      "Epoch 1386/2000\n",
      "88/88 - 0s - loss: 7.5790 - val_loss: 19.7801\n",
      "Epoch 1387/2000\n",
      "88/88 - 0s - loss: 7.0512 - val_loss: 19.3646\n",
      "Epoch 1388/2000\n",
      "88/88 - 0s - loss: 7.1148 - val_loss: 21.1738\n",
      "Epoch 1389/2000\n",
      "88/88 - 0s - loss: 8.7342 - val_loss: 19.8502\n",
      "Epoch 1390/2000\n",
      "88/88 - 0s - loss: 8.6050 - val_loss: 20.1213\n",
      "Epoch 1391/2000\n",
      "88/88 - 0s - loss: 7.2941 - val_loss: 20.3472\n",
      "Epoch 1392/2000\n",
      "88/88 - 0s - loss: 7.1722 - val_loss: 19.5547\n",
      "Epoch 1393/2000\n",
      "88/88 - 0s - loss: 7.1697 - val_loss: 19.2830\n",
      "Epoch 1394/2000\n",
      "88/88 - 0s - loss: 7.1235 - val_loss: 20.0258\n",
      "Epoch 1395/2000\n",
      "88/88 - 0s - loss: 7.1668 - val_loss: 20.0373\n",
      "Epoch 1396/2000\n",
      "88/88 - 0s - loss: 8.1616 - val_loss: 19.2416\n",
      "Epoch 1397/2000\n",
      "88/88 - 0s - loss: 7.5009 - val_loss: 19.7128\n",
      "Epoch 1398/2000\n",
      "88/88 - 0s - loss: 8.1065 - val_loss: 19.6987\n",
      "Epoch 1399/2000\n",
      "88/88 - 0s - loss: 7.5677 - val_loss: 18.7864\n",
      "Epoch 1400/2000\n",
      "88/88 - 0s - loss: 6.8160 - val_loss: 19.7560\n",
      "Epoch 1401/2000\n",
      "88/88 - 0s - loss: 7.2800 - val_loss: 18.8749\n",
      "Epoch 1402/2000\n",
      "88/88 - 0s - loss: 8.1432 - val_loss: 20.3090\n",
      "Epoch 1403/2000\n",
      "88/88 - 0s - loss: 7.7466 - val_loss: 20.5421\n",
      "Epoch 1404/2000\n",
      "88/88 - 0s - loss: 7.0908 - val_loss: 18.7894\n",
      "Epoch 1405/2000\n",
      "88/88 - 0s - loss: 8.2572 - val_loss: 19.2883\n",
      "Epoch 1406/2000\n",
      "88/88 - 0s - loss: 7.4051 - val_loss: 19.1985\n",
      "Epoch 1407/2000\n",
      "88/88 - 0s - loss: 7.2454 - val_loss: 22.4612\n",
      "Epoch 1408/2000\n",
      "88/88 - 0s - loss: 8.3820 - val_loss: 20.2189\n",
      "Epoch 1409/2000\n",
      "88/88 - 0s - loss: 8.0356 - val_loss: 20.2855\n",
      "Epoch 1410/2000\n",
      "88/88 - 0s - loss: 7.9675 - val_loss: 22.7557\n",
      "Epoch 1411/2000\n",
      "88/88 - 0s - loss: 13.1000 - val_loss: 24.3038\n",
      "Epoch 1412/2000\n",
      "88/88 - 0s - loss: 10.4657 - val_loss: 21.4360\n",
      "Epoch 1413/2000\n",
      "88/88 - 0s - loss: 10.2981 - val_loss: 24.7747\n",
      "Epoch 1414/2000\n",
      "88/88 - 0s - loss: 10.3076 - val_loss: 20.9119\n",
      "Epoch 1415/2000\n",
      "88/88 - 0s - loss: 8.4041 - val_loss: 20.7834\n",
      "Epoch 1416/2000\n",
      "88/88 - 0s - loss: 9.0281 - val_loss: 19.6716\n",
      "Epoch 1417/2000\n",
      "88/88 - 0s - loss: 8.4335 - val_loss: 20.3829\n",
      "Epoch 1418/2000\n",
      "88/88 - 0s - loss: 7.7825 - val_loss: 20.5489\n",
      "Epoch 1419/2000\n",
      "88/88 - 0s - loss: 8.0676 - val_loss: 20.4382\n",
      "Epoch 1420/2000\n",
      "88/88 - 0s - loss: 7.8432 - val_loss: 21.3699\n",
      "Epoch 1421/2000\n",
      "88/88 - 0s - loss: 8.6010 - val_loss: 19.9751\n",
      "Epoch 1422/2000\n",
      "88/88 - 0s - loss: 7.7359 - val_loss: 19.7480\n",
      "Epoch 1423/2000\n",
      "88/88 - 0s - loss: 7.5156 - val_loss: 19.9939\n",
      "Epoch 1424/2000\n",
      "88/88 - 0s - loss: 8.7093 - val_loss: 20.9235\n",
      "Epoch 1425/2000\n",
      "88/88 - 0s - loss: 10.5461 - val_loss: 21.1457\n",
      "Epoch 1426/2000\n",
      "88/88 - 0s - loss: 9.9392 - val_loss: 20.2818\n",
      "Epoch 1427/2000\n",
      "88/88 - 0s - loss: 10.0424 - val_loss: 19.1743\n",
      "Epoch 1428/2000\n",
      "88/88 - 0s - loss: 8.7232 - val_loss: 20.1164\n",
      "Epoch 1429/2000\n",
      "88/88 - 0s - loss: 8.5373 - val_loss: 20.1246\n",
      "Epoch 1430/2000\n",
      "88/88 - 0s - loss: 8.7815 - val_loss: 20.1856\n",
      "Epoch 1431/2000\n",
      "88/88 - 0s - loss: 9.8537 - val_loss: 22.7647\n",
      "Epoch 1432/2000\n",
      "88/88 - 0s - loss: 10.9169 - val_loss: 21.1342\n",
      "Epoch 1433/2000\n",
      "88/88 - 0s - loss: 9.8151 - val_loss: 22.2291\n",
      "Epoch 1434/2000\n",
      "88/88 - 0s - loss: 11.7286 - val_loss: 22.0188\n",
      "Epoch 1435/2000\n",
      "88/88 - 0s - loss: 10.4707 - val_loss: 21.9645\n",
      "Epoch 1436/2000\n",
      "88/88 - 0s - loss: 11.8747 - val_loss: 22.5224\n",
      "Epoch 1437/2000\n",
      "88/88 - 0s - loss: 11.5075 - val_loss: 23.3307\n",
      "Epoch 1438/2000\n",
      "88/88 - 0s - loss: 11.7031 - val_loss: 22.6190\n",
      "Epoch 1439/2000\n",
      "88/88 - 0s - loss: 11.9166 - val_loss: 22.4456\n",
      "Epoch 1440/2000\n",
      "88/88 - 0s - loss: 10.4775 - val_loss: 21.6560\n",
      "Epoch 1441/2000\n",
      "88/88 - 0s - loss: 10.3133 - val_loss: 20.8454\n",
      "Epoch 1442/2000\n",
      "88/88 - 0s - loss: 9.5377 - val_loss: 21.1961\n",
      "Epoch 1443/2000\n",
      "88/88 - 0s - loss: 9.2260 - val_loss: 20.9540\n",
      "Epoch 1444/2000\n",
      "88/88 - 0s - loss: 8.6356 - val_loss: 21.0472\n",
      "Epoch 1445/2000\n",
      "88/88 - 0s - loss: 8.6481 - val_loss: 20.4630\n",
      "Epoch 1446/2000\n",
      "88/88 - 0s - loss: 8.8055 - val_loss: 21.2428\n",
      "Epoch 1447/2000\n",
      "88/88 - 0s - loss: 10.7430 - val_loss: 22.3916\n",
      "Epoch 1448/2000\n",
      "88/88 - 0s - loss: 9.9482 - val_loss: 20.7533\n",
      "Epoch 1449/2000\n",
      "88/88 - 0s - loss: 9.9222 - val_loss: 19.9798\n",
      "Epoch 1450/2000\n",
      "88/88 - 0s - loss: 8.2260 - val_loss: 22.0677\n",
      "Epoch 1451/2000\n",
      "88/88 - 0s - loss: 9.1484 - val_loss: 22.1364\n",
      "Epoch 1452/2000\n",
      "88/88 - 0s - loss: 8.5150 - val_loss: 20.4848\n",
      "Epoch 1453/2000\n",
      "88/88 - 0s - loss: 8.4660 - val_loss: 21.1165\n",
      "Epoch 1454/2000\n",
      "88/88 - 0s - loss: 8.2842 - val_loss: 20.1221\n",
      "Epoch 1455/2000\n",
      "88/88 - 0s - loss: 8.4014 - val_loss: 20.1580\n",
      "Epoch 1456/2000\n",
      "88/88 - 0s - loss: 8.1590 - val_loss: 20.8668\n",
      "Epoch 1457/2000\n",
      "88/88 - 0s - loss: 7.9806 - val_loss: 20.7239\n",
      "Epoch 1458/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 - 0s - loss: 8.7648 - val_loss: 20.2978\n",
      "Epoch 1459/2000\n",
      "88/88 - 0s - loss: 7.6813 - val_loss: 20.5951\n",
      "Epoch 1460/2000\n",
      "88/88 - 0s - loss: 7.9361 - val_loss: 19.4545\n",
      "Epoch 1461/2000\n",
      "88/88 - 0s - loss: 7.4691 - val_loss: 20.1883\n",
      "Epoch 1462/2000\n",
      "88/88 - 0s - loss: 8.9439 - val_loss: 20.9603\n",
      "Epoch 1463/2000\n",
      "88/88 - 0s - loss: 7.9593 - val_loss: 21.3916\n",
      "Epoch 1464/2000\n",
      "88/88 - 0s - loss: 8.1992 - val_loss: 19.5721\n",
      "Epoch 1465/2000\n",
      "88/88 - 0s - loss: 8.5060 - val_loss: 20.2122\n",
      "Epoch 1466/2000\n",
      "88/88 - 0s - loss: 8.4819 - val_loss: 19.6453\n",
      "Epoch 1467/2000\n",
      "88/88 - 0s - loss: 7.6257 - val_loss: 21.3091\n",
      "Epoch 1468/2000\n",
      "88/88 - 0s - loss: 7.9869 - val_loss: 19.6371\n",
      "Epoch 1469/2000\n",
      "88/88 - 0s - loss: 7.6214 - val_loss: 20.7666\n",
      "Epoch 1470/2000\n",
      "88/88 - 0s - loss: 7.9726 - val_loss: 21.0019\n",
      "Epoch 1471/2000\n",
      "88/88 - 0s - loss: 8.5002 - val_loss: 20.0272\n",
      "Epoch 1472/2000\n",
      "88/88 - 0s - loss: 8.1831 - val_loss: 20.2681\n",
      "Epoch 1473/2000\n",
      "88/88 - 0s - loss: 7.9392 - val_loss: 20.1759\n",
      "Epoch 1474/2000\n",
      "88/88 - 0s - loss: 7.7448 - val_loss: 19.8554\n",
      "Epoch 1475/2000\n",
      "88/88 - 0s - loss: 7.6430 - val_loss: 21.4931\n",
      "Epoch 1476/2000\n",
      "88/88 - 0s - loss: 7.7612 - val_loss: 20.5840\n",
      "Epoch 1477/2000\n",
      "88/88 - 0s - loss: 8.1547 - val_loss: 19.6285\n",
      "Epoch 1478/2000\n",
      "88/88 - 0s - loss: 7.9447 - val_loss: 20.6044\n",
      "Epoch 1479/2000\n",
      "88/88 - 0s - loss: 8.2696 - val_loss: 21.6952\n",
      "Epoch 1480/2000\n",
      "88/88 - 0s - loss: 8.1692 - val_loss: 20.0965\n",
      "Epoch 1481/2000\n",
      "88/88 - 0s - loss: 7.9062 - val_loss: 19.6010\n",
      "Epoch 1482/2000\n",
      "88/88 - 0s - loss: 8.0883 - val_loss: 19.9740\n",
      "Epoch 1483/2000\n",
      "88/88 - 0s - loss: 7.9911 - val_loss: 20.1633\n",
      "Epoch 1484/2000\n",
      "88/88 - 0s - loss: 7.6176 - val_loss: 21.9622\n",
      "Epoch 1485/2000\n",
      "88/88 - 0s - loss: 7.5915 - val_loss: 20.6703\n",
      "Epoch 1486/2000\n",
      "88/88 - 0s - loss: 7.5814 - val_loss: 20.0638\n",
      "Epoch 1487/2000\n",
      "88/88 - 0s - loss: 7.4345 - val_loss: 20.4382\n",
      "Epoch 1488/2000\n",
      "88/88 - 0s - loss: 7.8288 - val_loss: 19.7193\n",
      "Epoch 1489/2000\n",
      "88/88 - 0s - loss: 7.9833 - val_loss: 21.3261\n",
      "Epoch 1490/2000\n",
      "88/88 - 0s - loss: 7.8090 - val_loss: 21.1994\n",
      "Epoch 1491/2000\n",
      "88/88 - 0s - loss: 7.8925 - val_loss: 19.9656\n",
      "Epoch 1492/2000\n",
      "88/88 - 0s - loss: 7.5255 - val_loss: 20.3245\n",
      "Epoch 1493/2000\n",
      "88/88 - 0s - loss: 7.7094 - val_loss: 21.0254\n",
      "Epoch 1494/2000\n",
      "88/88 - 0s - loss: 7.3370 - val_loss: 20.7868\n",
      "Epoch 1495/2000\n",
      "88/88 - 0s - loss: 7.6932 - val_loss: 19.9364\n",
      "Epoch 1496/2000\n",
      "88/88 - 0s - loss: 8.2201 - val_loss: 21.6769\n",
      "Epoch 1497/2000\n",
      "88/88 - 0s - loss: 12.5307 - val_loss: 22.0407\n",
      "Epoch 1498/2000\n",
      "88/88 - 0s - loss: 10.9659 - val_loss: 21.3099\n",
      "Epoch 1499/2000\n",
      "88/88 - 0s - loss: 10.7310 - val_loss: 21.6959\n",
      "Epoch 1500/2000\n",
      "88/88 - 0s - loss: 11.4617 - val_loss: 24.6608\n",
      "Epoch 1501/2000\n",
      "88/88 - 0s - loss: 10.1616 - val_loss: 21.2779\n",
      "Epoch 1502/2000\n",
      "88/88 - 0s - loss: 10.1693 - val_loss: 21.7458\n",
      "Epoch 1503/2000\n",
      "88/88 - 0s - loss: 8.9519 - val_loss: 21.0511\n",
      "Epoch 1504/2000\n",
      "88/88 - 0s - loss: 9.2139 - val_loss: 21.4684\n",
      "Epoch 1505/2000\n",
      "88/88 - 0s - loss: 8.6892 - val_loss: 20.2605\n",
      "Epoch 1506/2000\n",
      "88/88 - 0s - loss: 8.6411 - val_loss: 20.9531\n",
      "Epoch 1507/2000\n",
      "88/88 - 0s - loss: 9.6690 - val_loss: 21.3216\n",
      "Epoch 1508/2000\n",
      "88/88 - 0s - loss: 9.7558 - val_loss: 21.8359\n",
      "Epoch 1509/2000\n",
      "88/88 - 0s - loss: 11.9958 - val_loss: 24.4370\n",
      "Epoch 1510/2000\n",
      "88/88 - 0s - loss: 13.8135 - val_loss: 21.4659\n",
      "Epoch 1511/2000\n",
      "88/88 - 0s - loss: 10.6828 - val_loss: 22.5748\n",
      "Epoch 1512/2000\n",
      "88/88 - 0s - loss: 12.2413 - val_loss: 21.8983\n",
      "Epoch 1513/2000\n",
      "88/88 - 0s - loss: 11.4964 - val_loss: 21.2902\n",
      "Epoch 1514/2000\n",
      "88/88 - 0s - loss: 11.6890 - val_loss: 22.6440\n",
      "Epoch 1515/2000\n",
      "88/88 - 0s - loss: 10.3129 - val_loss: 20.7626\n",
      "Epoch 1516/2000\n",
      "88/88 - 0s - loss: 10.1160 - val_loss: 22.0264\n",
      "Epoch 1517/2000\n",
      "88/88 - 0s - loss: 13.2889 - val_loss: 27.1449\n",
      "Epoch 1518/2000\n",
      "88/88 - 0s - loss: 15.4839 - val_loss: 23.9764\n",
      "Epoch 1519/2000\n",
      "88/88 - 0s - loss: 13.9432 - val_loss: 23.5119\n",
      "Epoch 1520/2000\n",
      "88/88 - 0s - loss: 12.4704 - val_loss: 23.7272\n",
      "Epoch 1521/2000\n",
      "88/88 - 0s - loss: 15.1938 - val_loss: 24.7941\n",
      "Epoch 1522/2000\n",
      "88/88 - 0s - loss: 12.7872 - val_loss: 22.9741\n",
      "Epoch 1523/2000\n",
      "88/88 - 0s - loss: 11.8450 - val_loss: 21.4215\n",
      "Epoch 1524/2000\n",
      "88/88 - 0s - loss: 12.0651 - val_loss: 21.5353\n",
      "Epoch 1525/2000\n",
      "88/88 - 0s - loss: 11.3543 - val_loss: 21.0263\n",
      "Epoch 1526/2000\n",
      "88/88 - 0s - loss: 10.1337 - val_loss: 20.1874\n",
      "Epoch 1527/2000\n",
      "88/88 - 0s - loss: 10.3114 - val_loss: 19.8430\n",
      "Epoch 1528/2000\n",
      "88/88 - 0s - loss: 9.6406 - val_loss: 19.3685\n",
      "Epoch 1529/2000\n",
      "88/88 - 0s - loss: 9.8779 - val_loss: 20.8488\n",
      "Epoch 1530/2000\n",
      "88/88 - 0s - loss: 9.7736 - val_loss: 20.0611\n",
      "Epoch 1531/2000\n",
      "88/88 - 0s - loss: 8.8571 - val_loss: 19.4970\n",
      "Epoch 1532/2000\n",
      "88/88 - 0s - loss: 9.2081 - val_loss: 20.9383\n",
      "Epoch 1533/2000\n",
      "88/88 - 0s - loss: 9.4296 - val_loss: 20.1976\n",
      "Epoch 1534/2000\n",
      "88/88 - 0s - loss: 8.5212 - val_loss: 21.1939\n",
      "Epoch 1535/2000\n",
      "88/88 - 0s - loss: 8.8984 - val_loss: 19.9298\n",
      "Epoch 1536/2000\n",
      "88/88 - 0s - loss: 9.8164 - val_loss: 21.6382\n",
      "Epoch 1537/2000\n",
      "88/88 - 0s - loss: 10.1736 - val_loss: 20.9696\n",
      "Epoch 1538/2000\n",
      "88/88 - 0s - loss: 8.9357 - val_loss: 20.7389\n",
      "Epoch 1539/2000\n",
      "88/88 - 0s - loss: 8.2148 - val_loss: 20.1992\n",
      "Epoch 1540/2000\n",
      "88/88 - 0s - loss: 11.0218 - val_loss: 23.5173\n",
      "Epoch 1541/2000\n",
      "88/88 - 0s - loss: 11.8242 - val_loss: 21.8803\n",
      "Epoch 1542/2000\n",
      "88/88 - 0s - loss: 9.8278 - val_loss: 21.2531\n",
      "Epoch 1543/2000\n",
      "88/88 - 0s - loss: 10.7033 - val_loss: 20.5945\n",
      "Epoch 1544/2000\n",
      "88/88 - 0s - loss: 11.5750 - val_loss: 21.4997\n",
      "Epoch 1545/2000\n",
      "88/88 - 0s - loss: 10.9678 - val_loss: 21.5244\n",
      "Epoch 1546/2000\n",
      "88/88 - 0s - loss: 11.1025 - val_loss: 19.4165\n",
      "Epoch 1547/2000\n",
      "88/88 - 0s - loss: 10.5245 - val_loss: 20.5933\n",
      "Epoch 1548/2000\n",
      "88/88 - 0s - loss: 10.1379 - val_loss: 20.4544\n",
      "Epoch 1549/2000\n",
      "88/88 - 0s - loss: 9.9948 - val_loss: 19.9318\n",
      "Epoch 1550/2000\n",
      "88/88 - 0s - loss: 9.1753 - val_loss: 19.9656\n",
      "Epoch 1551/2000\n",
      "88/88 - 0s - loss: 9.9725 - val_loss: 20.6802\n",
      "Epoch 1552/2000\n",
      "88/88 - 0s - loss: 8.9758 - val_loss: 19.6620\n",
      "Epoch 1553/2000\n",
      "88/88 - 0s - loss: 8.0673 - val_loss: 19.8369\n",
      "Epoch 1554/2000\n",
      "88/88 - 0s - loss: 9.4353 - val_loss: 20.8604\n",
      "Epoch 1555/2000\n",
      "88/88 - 0s - loss: 8.9033 - val_loss: 21.0015\n",
      "Epoch 1556/2000\n",
      "88/88 - 0s - loss: 9.1362 - val_loss: 21.4711\n",
      "Epoch 1557/2000\n",
      "88/88 - 0s - loss: 10.2607 - val_loss: 19.6178\n",
      "Epoch 1558/2000\n",
      "88/88 - 0s - loss: 9.2604 - val_loss: 21.1960\n",
      "Epoch 1559/2000\n",
      "88/88 - 0s - loss: 11.1706 - val_loss: 21.4855\n",
      "Epoch 1560/2000\n",
      "88/88 - 0s - loss: 9.0355 - val_loss: 21.7353\n",
      "Epoch 1561/2000\n",
      "88/88 - 0s - loss: 8.3867 - val_loss: 19.8385\n",
      "Epoch 1562/2000\n",
      "88/88 - 0s - loss: 9.5393 - val_loss: 21.0539\n",
      "Epoch 1563/2000\n",
      "88/88 - 0s - loss: 9.0193 - val_loss: 21.8613\n",
      "Epoch 1564/2000\n",
      "88/88 - 0s - loss: 9.2896 - val_loss: 20.1250\n",
      "Epoch 1565/2000\n",
      "88/88 - 0s - loss: 8.2344 - val_loss: 20.2285\n",
      "Epoch 1566/2000\n",
      "88/88 - 0s - loss: 8.2946 - val_loss: 22.8987\n",
      "Epoch 1567/2000\n",
      "88/88 - 0s - loss: 9.3827 - val_loss: 20.9487\n",
      "Epoch 1568/2000\n",
      "88/88 - 0s - loss: 8.6046 - val_loss: 22.0967\n",
      "Epoch 1569/2000\n",
      "88/88 - 0s - loss: 8.2507 - val_loss: 19.2928\n",
      "Epoch 1570/2000\n",
      "88/88 - 0s - loss: 7.7311 - val_loss: 19.8157\n",
      "Epoch 1571/2000\n",
      "88/88 - 0s - loss: 8.7519 - val_loss: 19.7057\n",
      "Epoch 1572/2000\n",
      "88/88 - 0s - loss: 7.9025 - val_loss: 19.4109\n",
      "Epoch 1573/2000\n",
      "88/88 - 0s - loss: 7.5216 - val_loss: 20.2847\n",
      "Epoch 1574/2000\n",
      "88/88 - 0s - loss: 8.3644 - val_loss: 21.4757\n",
      "Epoch 1575/2000\n",
      "88/88 - 0s - loss: 8.7814 - val_loss: 19.7566\n",
      "Epoch 1576/2000\n",
      "88/88 - 0s - loss: 7.5735 - val_loss: 19.7320\n",
      "Epoch 1577/2000\n",
      "88/88 - 0s - loss: 7.3531 - val_loss: 19.3408\n",
      "Epoch 1578/2000\n",
      "88/88 - 0s - loss: 8.5610 - val_loss: 20.6548\n",
      "Epoch 1579/2000\n",
      "88/88 - 0s - loss: 8.0306 - val_loss: 19.5543\n",
      "Epoch 1580/2000\n",
      "88/88 - 0s - loss: 7.8017 - val_loss: 20.5563\n",
      "Epoch 1581/2000\n",
      "88/88 - 0s - loss: 8.8604 - val_loss: 20.4525\n",
      "Epoch 1582/2000\n",
      "88/88 - 0s - loss: 8.4885 - val_loss: 20.3514\n",
      "Epoch 1583/2000\n",
      "88/88 - 0s - loss: 8.3129 - val_loss: 21.6830\n",
      "Epoch 1584/2000\n",
      "88/88 - 0s - loss: 12.2054 - val_loss: 23.0996\n",
      "Epoch 1585/2000\n",
      "88/88 - 0s - loss: 10.9526 - val_loss: 21.0736\n",
      "Epoch 1586/2000\n",
      "88/88 - 0s - loss: 9.5691 - val_loss: 20.2130\n",
      "Epoch 1587/2000\n",
      "88/88 - 0s - loss: 9.2096 - val_loss: 20.1978\n",
      "Epoch 1588/2000\n",
      "88/88 - 0s - loss: 9.9010 - val_loss: 20.7997\n",
      "Epoch 1589/2000\n",
      "88/88 - 0s - loss: 10.7468 - val_loss: 23.0533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1590/2000\n",
      "88/88 - 0s - loss: 11.4593 - val_loss: 20.7306\n",
      "Epoch 1591/2000\n",
      "88/88 - 0s - loss: 9.3807 - val_loss: 19.9339\n",
      "Epoch 1592/2000\n",
      "88/88 - 0s - loss: 9.5429 - val_loss: 19.6010\n",
      "Epoch 1593/2000\n",
      "88/88 - 0s - loss: 8.6165 - val_loss: 18.6894\n",
      "Epoch 1594/2000\n",
      "88/88 - 0s - loss: 8.8003 - val_loss: 20.8838\n",
      "Epoch 1595/2000\n",
      "88/88 - 0s - loss: 9.4509 - val_loss: 20.6424\n",
      "Epoch 1596/2000\n",
      "88/88 - 0s - loss: 9.8728 - val_loss: 20.7014\n",
      "Epoch 1597/2000\n",
      "88/88 - 0s - loss: 11.3322 - val_loss: 22.0492\n",
      "Epoch 1598/2000\n",
      "88/88 - 0s - loss: 10.7502 - val_loss: 20.2825\n",
      "Epoch 1599/2000\n",
      "88/88 - 0s - loss: 10.0653 - val_loss: 20.3891\n",
      "Epoch 1600/2000\n",
      "88/88 - 0s - loss: 9.5712 - val_loss: 21.8687\n",
      "Epoch 1601/2000\n",
      "88/88 - 0s - loss: 9.5540 - val_loss: 19.7246\n",
      "Epoch 1602/2000\n",
      "88/88 - 0s - loss: 9.3006 - val_loss: 20.6139\n",
      "Epoch 1603/2000\n",
      "88/88 - 0s - loss: 9.4673 - val_loss: 19.6959\n",
      "Epoch 1604/2000\n",
      "88/88 - 0s - loss: 8.6443 - val_loss: 19.5603\n",
      "Epoch 1605/2000\n",
      "88/88 - 0s - loss: 7.9313 - val_loss: 19.6957\n",
      "Epoch 1606/2000\n",
      "88/88 - 0s - loss: 8.9849 - val_loss: 19.6580\n",
      "Epoch 1607/2000\n",
      "88/88 - 0s - loss: 8.3272 - val_loss: 19.9392\n",
      "Epoch 1608/2000\n",
      "88/88 - 0s - loss: 9.0826 - val_loss: 20.5439\n",
      "Epoch 1609/2000\n",
      "88/88 - 0s - loss: 8.6297 - val_loss: 20.6717\n",
      "Epoch 1610/2000\n",
      "88/88 - 0s - loss: 8.5991 - val_loss: 20.5316\n",
      "Epoch 1611/2000\n",
      "88/88 - 0s - loss: 7.9927 - val_loss: 20.5999\n",
      "Epoch 1612/2000\n",
      "88/88 - 0s - loss: 7.7028 - val_loss: 19.8028\n",
      "Epoch 1613/2000\n",
      "88/88 - 0s - loss: 7.3856 - val_loss: 19.1542\n",
      "Epoch 1614/2000\n",
      "88/88 - 0s - loss: 7.3486 - val_loss: 18.9595\n",
      "Epoch 1615/2000\n",
      "88/88 - 0s - loss: 8.0641 - val_loss: 19.8278\n",
      "Epoch 1616/2000\n",
      "88/88 - 0s - loss: 8.1333 - val_loss: 20.3378\n",
      "Epoch 1617/2000\n",
      "88/88 - 0s - loss: 7.6257 - val_loss: 20.8281\n",
      "Epoch 1618/2000\n",
      "88/88 - 0s - loss: 7.2289 - val_loss: 20.0928\n",
      "Epoch 1619/2000\n",
      "88/88 - 0s - loss: 8.0691 - val_loss: 19.3882\n",
      "Epoch 1620/2000\n",
      "88/88 - 0s - loss: 8.5434 - val_loss: 19.0975\n",
      "Epoch 1621/2000\n",
      "88/88 - 0s - loss: 9.1114 - val_loss: 19.3881\n",
      "Epoch 1622/2000\n",
      "88/88 - 0s - loss: 8.5009 - val_loss: 19.6296\n",
      "Epoch 1623/2000\n",
      "88/88 - 0s - loss: 8.1580 - val_loss: 19.2523\n",
      "Epoch 1624/2000\n",
      "88/88 - 0s - loss: 7.8810 - val_loss: 19.2207\n",
      "Epoch 1625/2000\n",
      "88/88 - 0s - loss: 8.8001 - val_loss: 20.1193\n",
      "Epoch 1626/2000\n",
      "88/88 - 0s - loss: 8.1288 - val_loss: 19.7654\n",
      "Epoch 1627/2000\n",
      "88/88 - 0s - loss: 7.2011 - val_loss: 19.2827\n",
      "Epoch 1628/2000\n",
      "88/88 - 0s - loss: 7.4123 - val_loss: 19.4041\n",
      "Epoch 1629/2000\n",
      "88/88 - 0s - loss: 7.7940 - val_loss: 21.0386\n",
      "Epoch 1630/2000\n",
      "88/88 - 0s - loss: 8.6575 - val_loss: 19.8077\n",
      "Epoch 1631/2000\n",
      "88/88 - 0s - loss: 7.7201 - val_loss: 20.1179\n",
      "Epoch 1632/2000\n",
      "88/88 - 0s - loss: 7.1321 - val_loss: 19.3755\n",
      "Epoch 1633/2000\n",
      "88/88 - 0s - loss: 7.5067 - val_loss: 19.3223\n",
      "Epoch 1634/2000\n",
      "88/88 - 0s - loss: 7.4711 - val_loss: 21.3619\n",
      "Epoch 1635/2000\n",
      "88/88 - 0s - loss: 8.4157 - val_loss: 20.8267\n",
      "Epoch 1636/2000\n",
      "88/88 - 0s - loss: 7.6146 - val_loss: 22.0239\n",
      "Epoch 1637/2000\n",
      "88/88 - 0s - loss: 8.2256 - val_loss: 20.7523\n",
      "Epoch 1638/2000\n",
      "88/88 - 0s - loss: 7.9117 - val_loss: 19.7718\n",
      "Epoch 1639/2000\n",
      "88/88 - 0s - loss: 7.6157 - val_loss: 20.8883\n",
      "Epoch 1640/2000\n",
      "88/88 - 0s - loss: 10.3989 - val_loss: 20.9954\n",
      "Epoch 1641/2000\n",
      "88/88 - 0s - loss: 11.4475 - val_loss: 28.0470\n",
      "Epoch 1642/2000\n",
      "88/88 - 0s - loss: 14.6122 - val_loss: 23.9578\n",
      "Epoch 1643/2000\n",
      "88/88 - 0s - loss: 10.3365 - val_loss: 21.7836\n",
      "Epoch 1644/2000\n",
      "88/88 - 0s - loss: 11.0225 - val_loss: 23.7328\n",
      "Epoch 1645/2000\n",
      "88/88 - 0s - loss: 10.6325 - val_loss: 22.7070\n",
      "Epoch 1646/2000\n",
      "88/88 - 0s - loss: 9.5761 - val_loss: 21.9372\n",
      "Epoch 1647/2000\n",
      "88/88 - 0s - loss: 11.3135 - val_loss: 22.3222\n",
      "Epoch 1648/2000\n",
      "88/88 - 0s - loss: 9.5949 - val_loss: 20.7295\n",
      "Epoch 1649/2000\n",
      "88/88 - 0s - loss: 9.2008 - val_loss: 21.9792\n",
      "Epoch 1650/2000\n",
      "88/88 - 0s - loss: 9.1585 - val_loss: 21.7121\n",
      "Epoch 1651/2000\n",
      "88/88 - 0s - loss: 9.3262 - val_loss: 20.6956\n",
      "Epoch 1652/2000\n",
      "88/88 - 0s - loss: 10.4444 - val_loss: 21.4119\n",
      "Epoch 1653/2000\n",
      "88/88 - 0s - loss: 9.7216 - val_loss: 21.6176\n",
      "Epoch 1654/2000\n",
      "88/88 - 0s - loss: 8.9052 - val_loss: 20.2644\n",
      "Epoch 1655/2000\n",
      "88/88 - 0s - loss: 8.4008 - val_loss: 20.0358\n",
      "Epoch 1656/2000\n",
      "88/88 - 0s - loss: 7.7311 - val_loss: 18.4806\n",
      "Epoch 1657/2000\n",
      "88/88 - 0s - loss: 9.0560 - val_loss: 21.5684\n",
      "Epoch 1658/2000\n",
      "88/88 - 0s - loss: 9.2691 - val_loss: 19.4193\n",
      "Epoch 1659/2000\n",
      "88/88 - 0s - loss: 7.9623 - val_loss: 20.0903\n",
      "Epoch 1660/2000\n",
      "88/88 - 0s - loss: 9.3566 - val_loss: 21.0524\n",
      "Epoch 1661/2000\n",
      "88/88 - 0s - loss: 9.7365 - val_loss: 20.7725\n",
      "Epoch 1662/2000\n",
      "88/88 - 0s - loss: 8.3563 - val_loss: 19.9070\n",
      "Epoch 1663/2000\n",
      "88/88 - 0s - loss: 7.6521 - val_loss: 21.1627\n",
      "Epoch 1664/2000\n",
      "88/88 - 0s - loss: 8.2532 - val_loss: 19.7367\n",
      "Epoch 1665/2000\n",
      "88/88 - 0s - loss: 7.4411 - val_loss: 20.6747\n",
      "Epoch 1666/2000\n",
      "88/88 - 0s - loss: 7.6738 - val_loss: 21.1092\n",
      "Epoch 1667/2000\n",
      "88/88 - 0s - loss: 8.3684 - val_loss: 21.3421\n",
      "Epoch 1668/2000\n",
      "88/88 - 0s - loss: 8.4623 - val_loss: 20.8466\n",
      "Epoch 1669/2000\n",
      "88/88 - 0s - loss: 8.5103 - val_loss: 19.9276\n",
      "Epoch 1670/2000\n",
      "88/88 - 0s - loss: 7.5923 - val_loss: 20.3983\n",
      "Epoch 1671/2000\n",
      "88/88 - 0s - loss: 9.4630 - val_loss: 20.2921\n",
      "Epoch 1672/2000\n",
      "88/88 - 0s - loss: 7.3569 - val_loss: 21.2131\n",
      "Epoch 1673/2000\n",
      "88/88 - 0s - loss: 8.3795 - val_loss: 19.5615\n",
      "Epoch 1674/2000\n",
      "88/88 - 0s - loss: 7.5303 - val_loss: 19.6544\n",
      "Epoch 1675/2000\n",
      "88/88 - 0s - loss: 7.7778 - val_loss: 22.0278\n",
      "Epoch 1676/2000\n",
      "88/88 - 0s - loss: 7.9915 - val_loss: 20.1659\n",
      "Epoch 1677/2000\n",
      "88/88 - 0s - loss: 7.8733 - val_loss: 23.0279\n",
      "Epoch 1678/2000\n",
      "88/88 - 0s - loss: 7.4144 - val_loss: 20.2177\n",
      "Epoch 1679/2000\n",
      "88/88 - 0s - loss: 7.7880 - val_loss: 20.7777\n",
      "Epoch 1680/2000\n",
      "88/88 - 0s - loss: 8.1660 - val_loss: 21.4596\n",
      "Epoch 1681/2000\n",
      "88/88 - 0s - loss: 7.1667 - val_loss: 19.7472\n",
      "Epoch 1682/2000\n",
      "88/88 - 0s - loss: 6.4609 - val_loss: 20.1661\n",
      "Epoch 1683/2000\n",
      "88/88 - 0s - loss: 7.5321 - val_loss: 20.4026\n",
      "Epoch 1684/2000\n",
      "88/88 - 0s - loss: 8.3874 - val_loss: 19.3728\n",
      "Epoch 1685/2000\n",
      "88/88 - 0s - loss: 7.9716 - val_loss: 19.8470\n",
      "Epoch 1686/2000\n",
      "88/88 - 0s - loss: 8.3855 - val_loss: 20.5882\n",
      "Epoch 1687/2000\n",
      "88/88 - 0s - loss: 7.9972 - val_loss: 20.4873\n",
      "Epoch 1688/2000\n",
      "88/88 - 0s - loss: 7.6973 - val_loss: 22.0321\n",
      "Epoch 1689/2000\n",
      "88/88 - 0s - loss: 8.1643 - val_loss: 22.0847\n",
      "Epoch 1690/2000\n",
      "88/88 - 0s - loss: 11.1500 - val_loss: 22.8088\n",
      "Epoch 1691/2000\n",
      "88/88 - 0s - loss: 10.0241 - val_loss: 20.8648\n",
      "Epoch 1692/2000\n",
      "88/88 - 0s - loss: 9.5234 - val_loss: 21.2089\n",
      "Epoch 1693/2000\n",
      "88/88 - 0s - loss: 8.9423 - val_loss: 20.8840\n",
      "Epoch 1694/2000\n",
      "88/88 - 0s - loss: 9.9438 - val_loss: 21.2262\n",
      "Epoch 1695/2000\n",
      "88/88 - 0s - loss: 9.2257 - val_loss: 24.4745\n",
      "Epoch 1696/2000\n",
      "88/88 - 0s - loss: 10.4143 - val_loss: 23.4749\n",
      "Epoch 1697/2000\n",
      "88/88 - 0s - loss: 10.1969 - val_loss: 20.9963\n",
      "Epoch 1698/2000\n",
      "88/88 - 0s - loss: 8.7157 - val_loss: 22.1577\n",
      "Epoch 1699/2000\n",
      "88/88 - 0s - loss: 9.1673 - val_loss: 21.9193\n",
      "Epoch 1700/2000\n",
      "88/88 - 0s - loss: 10.0692 - val_loss: 21.7508\n",
      "Epoch 1701/2000\n",
      "88/88 - 0s - loss: 9.1992 - val_loss: 19.8842\n",
      "Epoch 1702/2000\n",
      "88/88 - 0s - loss: 8.2518 - val_loss: 19.8187\n",
      "Epoch 1703/2000\n",
      "88/88 - 0s - loss: 8.4382 - val_loss: 20.5901\n",
      "Epoch 1704/2000\n",
      "88/88 - 0s - loss: 8.2586 - val_loss: 19.4757\n",
      "Epoch 1705/2000\n",
      "88/88 - 0s - loss: 9.0591 - val_loss: 19.8474\n",
      "Epoch 1706/2000\n",
      "88/88 - 0s - loss: 8.7362 - val_loss: 19.8620\n",
      "Epoch 1707/2000\n",
      "88/88 - 0s - loss: 8.4754 - val_loss: 19.9070\n",
      "Epoch 1708/2000\n",
      "88/88 - 0s - loss: 8.9054 - val_loss: 20.8626\n",
      "Epoch 1709/2000\n",
      "88/88 - 0s - loss: 9.3467 - val_loss: 21.0357\n",
      "Epoch 1710/2000\n",
      "88/88 - 0s - loss: 8.8993 - val_loss: 19.7808\n",
      "Epoch 1711/2000\n",
      "88/88 - 0s - loss: 8.0497 - val_loss: 21.9397\n",
      "Epoch 1712/2000\n",
      "88/88 - 0s - loss: 8.2021 - val_loss: 21.0391\n",
      "Epoch 1713/2000\n",
      "88/88 - 0s - loss: 8.0504 - val_loss: 21.0893\n",
      "Epoch 1714/2000\n",
      "88/88 - 0s - loss: 8.5586 - val_loss: 21.4853\n",
      "Epoch 1715/2000\n",
      "88/88 - 0s - loss: 8.3968 - val_loss: 21.6446\n",
      "Epoch 1716/2000\n",
      "88/88 - 0s - loss: 8.5686 - val_loss: 21.6722\n",
      "Epoch 1717/2000\n",
      "88/88 - 0s - loss: 8.7644 - val_loss: 19.5274\n",
      "Epoch 1718/2000\n",
      "88/88 - 0s - loss: 8.3861 - val_loss: 20.0968\n",
      "Epoch 1719/2000\n",
      "88/88 - 0s - loss: 7.5355 - val_loss: 19.3692\n",
      "Epoch 1720/2000\n",
      "88/88 - 0s - loss: 7.2542 - val_loss: 19.4761\n",
      "Epoch 1721/2000\n",
      "88/88 - 0s - loss: 7.4563 - val_loss: 19.4681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1722/2000\n",
      "88/88 - 0s - loss: 8.9066 - val_loss: 20.4999\n",
      "Epoch 1723/2000\n",
      "88/88 - 0s - loss: 7.9962 - val_loss: 19.5728\n",
      "Epoch 1724/2000\n",
      "88/88 - 0s - loss: 7.7685 - val_loss: 20.3432\n",
      "Epoch 1725/2000\n",
      "88/88 - 0s - loss: 8.4359 - val_loss: 20.7409\n",
      "Epoch 1726/2000\n",
      "88/88 - 0s - loss: 8.3512 - val_loss: 20.6134\n",
      "Epoch 1727/2000\n",
      "88/88 - 0s - loss: 7.4494 - val_loss: 20.1532\n",
      "Epoch 1728/2000\n",
      "88/88 - 0s - loss: 6.9614 - val_loss: 20.5651\n",
      "Epoch 1729/2000\n",
      "88/88 - 0s - loss: 6.7988 - val_loss: 21.1379\n",
      "Epoch 1730/2000\n",
      "88/88 - 0s - loss: 7.6455 - val_loss: 19.6471\n",
      "Epoch 1731/2000\n",
      "88/88 - 0s - loss: 8.0640 - val_loss: 19.7680\n",
      "Epoch 1732/2000\n",
      "88/88 - 0s - loss: 8.1360 - val_loss: 19.0046\n",
      "Epoch 1733/2000\n",
      "88/88 - 0s - loss: 6.9301 - val_loss: 19.4806\n",
      "Epoch 1734/2000\n",
      "88/88 - 0s - loss: 7.3416 - val_loss: 19.6852\n",
      "Epoch 1735/2000\n",
      "88/88 - 0s - loss: 7.8371 - val_loss: 19.8553\n",
      "Epoch 1736/2000\n",
      "88/88 - 0s - loss: 6.9627 - val_loss: 20.6937\n",
      "Epoch 1737/2000\n",
      "88/88 - 0s - loss: 7.3835 - val_loss: 20.2974\n",
      "Epoch 1738/2000\n",
      "88/88 - 0s - loss: 6.8515 - val_loss: 20.3688\n",
      "Epoch 1739/2000\n",
      "88/88 - 0s - loss: 7.6236 - val_loss: 21.0158\n",
      "Epoch 1740/2000\n",
      "88/88 - 0s - loss: 8.4195 - val_loss: 21.0720\n",
      "Epoch 1741/2000\n",
      "88/88 - 0s - loss: 7.4524 - val_loss: 20.3051\n",
      "Epoch 1742/2000\n",
      "88/88 - 0s - loss: 8.3211 - val_loss: 19.9388\n",
      "Epoch 1743/2000\n",
      "88/88 - 0s - loss: 7.0323 - val_loss: 19.8640\n",
      "Epoch 1744/2000\n",
      "88/88 - 0s - loss: 7.4413 - val_loss: 19.9972\n",
      "Epoch 1745/2000\n",
      "88/88 - 0s - loss: 7.4471 - val_loss: 21.2513\n",
      "Epoch 1746/2000\n",
      "88/88 - 0s - loss: 8.2635 - val_loss: 21.4754\n",
      "Epoch 1747/2000\n",
      "88/88 - 0s - loss: 7.0814 - val_loss: 20.1691\n",
      "Epoch 1748/2000\n",
      "88/88 - 0s - loss: 7.3434 - val_loss: 20.3301\n",
      "Epoch 1749/2000\n",
      "88/88 - 0s - loss: 8.2902 - val_loss: 21.0923\n",
      "Epoch 1750/2000\n",
      "88/88 - 0s - loss: 7.1060 - val_loss: 19.3442\n",
      "Epoch 1751/2000\n",
      "88/88 - 0s - loss: 7.9089 - val_loss: 20.2578\n",
      "Epoch 1752/2000\n",
      "88/88 - 0s - loss: 6.7216 - val_loss: 20.2977\n",
      "Epoch 1753/2000\n",
      "88/88 - 0s - loss: 8.0337 - val_loss: 20.2044\n",
      "Epoch 1754/2000\n",
      "88/88 - 0s - loss: 7.9125 - val_loss: 20.3125\n",
      "Epoch 1755/2000\n",
      "88/88 - 0s - loss: 8.7592 - val_loss: 20.6655\n",
      "Epoch 1756/2000\n",
      "88/88 - 0s - loss: 9.3793 - val_loss: 21.2484\n",
      "Epoch 1757/2000\n",
      "88/88 - 0s - loss: 7.4068 - val_loss: 19.7096\n",
      "Epoch 1758/2000\n",
      "88/88 - 0s - loss: 8.5920 - val_loss: 20.3070\n",
      "Epoch 1759/2000\n",
      "88/88 - 0s - loss: 7.8180 - val_loss: 21.0899\n",
      "Epoch 1760/2000\n",
      "88/88 - 0s - loss: 7.9989 - val_loss: 20.0907\n",
      "Epoch 1761/2000\n",
      "88/88 - 0s - loss: 8.4095 - val_loss: 21.1369\n",
      "Epoch 1762/2000\n",
      "88/88 - 0s - loss: 7.9207 - val_loss: 20.5434\n",
      "Epoch 1763/2000\n",
      "88/88 - 0s - loss: 7.9520 - val_loss: 20.0587\n",
      "Epoch 1764/2000\n",
      "88/88 - 0s - loss: 8.1037 - val_loss: 20.3091\n",
      "Epoch 1765/2000\n",
      "88/88 - 0s - loss: 8.1401 - val_loss: 19.9060\n",
      "Epoch 1766/2000\n",
      "88/88 - 0s - loss: 8.9455 - val_loss: 19.9981\n",
      "Epoch 1767/2000\n",
      "88/88 - 0s - loss: 9.1277 - val_loss: 21.0732\n",
      "Epoch 1768/2000\n",
      "88/88 - 0s - loss: 8.9710 - val_loss: 20.9243\n",
      "Epoch 1769/2000\n",
      "88/88 - 0s - loss: 8.2297 - val_loss: 20.5219\n",
      "Epoch 1770/2000\n",
      "88/88 - 0s - loss: 7.8170 - val_loss: 20.0324\n",
      "Epoch 1771/2000\n",
      "88/88 - 0s - loss: 8.1622 - val_loss: 21.5055\n",
      "Epoch 1772/2000\n",
      "88/88 - 0s - loss: 10.2382 - val_loss: 22.9977\n",
      "Epoch 1773/2000\n",
      "88/88 - 0s - loss: 10.3330 - val_loss: 20.5839\n",
      "Epoch 1774/2000\n",
      "88/88 - 0s - loss: 9.2640 - val_loss: 23.0922\n",
      "Epoch 1775/2000\n",
      "88/88 - 0s - loss: 8.9408 - val_loss: 20.2830\n",
      "Epoch 1776/2000\n",
      "88/88 - 0s - loss: 8.7623 - val_loss: 22.9993\n",
      "Epoch 1777/2000\n",
      "88/88 - 0s - loss: 9.4442 - val_loss: 21.3025\n",
      "Epoch 1778/2000\n",
      "88/88 - 0s - loss: 9.5378 - val_loss: 21.9805\n",
      "Epoch 1779/2000\n",
      "88/88 - 0s - loss: 9.4216 - val_loss: 21.6304\n",
      "Epoch 1780/2000\n",
      "88/88 - 0s - loss: 8.5784 - val_loss: 20.1897\n",
      "Epoch 1781/2000\n",
      "88/88 - 0s - loss: 8.4104 - val_loss: 20.3161\n",
      "Epoch 1782/2000\n",
      "88/88 - 0s - loss: 8.3282 - val_loss: 19.8944\n",
      "Epoch 1783/2000\n",
      "88/88 - 0s - loss: 7.5412 - val_loss: 20.0317\n",
      "Epoch 1784/2000\n",
      "88/88 - 0s - loss: 9.6846 - val_loss: 22.1962\n",
      "Epoch 1785/2000\n",
      "88/88 - 0s - loss: 10.8174 - val_loss: 20.7370\n",
      "Epoch 1786/2000\n",
      "88/88 - 0s - loss: 9.6871 - val_loss: 21.0198\n",
      "Epoch 1787/2000\n",
      "88/88 - 0s - loss: 8.7812 - val_loss: 22.3661\n",
      "Epoch 1788/2000\n",
      "88/88 - 0s - loss: 11.1097 - val_loss: 22.2348\n",
      "Epoch 1789/2000\n",
      "88/88 - 0s - loss: 10.9998 - val_loss: 21.5966\n",
      "Epoch 1790/2000\n",
      "88/88 - 0s - loss: 9.2070 - val_loss: 21.9209\n",
      "Epoch 1791/2000\n",
      "88/88 - 0s - loss: 9.0313 - val_loss: 20.6174\n",
      "Epoch 1792/2000\n",
      "88/88 - 0s - loss: 12.2434 - val_loss: 22.1435\n",
      "Epoch 1793/2000\n",
      "88/88 - 0s - loss: 10.7581 - val_loss: 23.1132\n",
      "Epoch 1794/2000\n",
      "88/88 - 0s - loss: 10.2635 - val_loss: 20.9130\n",
      "Epoch 1795/2000\n",
      "88/88 - 0s - loss: 9.1665 - val_loss: 20.7448\n",
      "Epoch 1796/2000\n",
      "88/88 - 0s - loss: 9.6852 - val_loss: 20.4842\n",
      "Epoch 1797/2000\n",
      "88/88 - 0s - loss: 9.4555 - val_loss: 21.4890\n",
      "Epoch 1798/2000\n",
      "88/88 - 0s - loss: 8.9111 - val_loss: 21.2913\n",
      "Epoch 1799/2000\n",
      "88/88 - 0s - loss: 9.1852 - val_loss: 20.0402\n",
      "Epoch 1800/2000\n",
      "88/88 - 0s - loss: 8.3896 - val_loss: 21.0051\n",
      "Epoch 1801/2000\n",
      "88/88 - 0s - loss: 11.6504 - val_loss: 22.0887\n",
      "Epoch 1802/2000\n",
      "88/88 - 0s - loss: 12.1654 - val_loss: 22.2240\n",
      "Epoch 1803/2000\n",
      "88/88 - 0s - loss: 11.6937 - val_loss: 22.0471\n",
      "Epoch 1804/2000\n",
      "88/88 - 0s - loss: 9.9629 - val_loss: 21.6061\n",
      "Epoch 1805/2000\n",
      "88/88 - 0s - loss: 10.0196 - val_loss: 20.9890\n",
      "Epoch 1806/2000\n",
      "88/88 - 0s - loss: 9.5197 - val_loss: 21.1844\n",
      "Epoch 1807/2000\n",
      "88/88 - 0s - loss: 9.9651 - val_loss: 21.8375\n",
      "Epoch 1808/2000\n",
      "88/88 - 0s - loss: 9.2517 - val_loss: 21.9820\n",
      "Epoch 1809/2000\n",
      "88/88 - 0s - loss: 8.9507 - val_loss: 21.5559\n",
      "Epoch 1810/2000\n",
      "88/88 - 0s - loss: 8.5038 - val_loss: 23.5665\n",
      "Epoch 1811/2000\n",
      "88/88 - 0s - loss: 9.1476 - val_loss: 21.5302\n",
      "Epoch 1812/2000\n",
      "88/88 - 0s - loss: 8.2713 - val_loss: 22.4123\n",
      "Epoch 1813/2000\n",
      "88/88 - 0s - loss: 8.1235 - val_loss: 21.1899\n",
      "Epoch 1814/2000\n",
      "88/88 - 0s - loss: 9.0488 - val_loss: 22.3216\n",
      "Epoch 1815/2000\n",
      "88/88 - 0s - loss: 7.9077 - val_loss: 21.0169\n",
      "Epoch 1816/2000\n",
      "88/88 - 0s - loss: 7.6381 - val_loss: 20.7335\n",
      "Epoch 1817/2000\n",
      "88/88 - 0s - loss: 7.7452 - val_loss: 20.9099\n",
      "Epoch 1818/2000\n",
      "88/88 - 0s - loss: 7.7587 - val_loss: 20.9483\n",
      "Epoch 1819/2000\n",
      "88/88 - 0s - loss: 8.5047 - val_loss: 20.3132\n",
      "Epoch 1820/2000\n",
      "88/88 - 0s - loss: 8.2883 - val_loss: 20.9714\n",
      "Epoch 1821/2000\n",
      "88/88 - 0s - loss: 8.3442 - val_loss: 22.2144\n",
      "Epoch 1822/2000\n",
      "88/88 - 0s - loss: 8.1944 - val_loss: 20.6091\n",
      "Epoch 1823/2000\n",
      "88/88 - 0s - loss: 9.1156 - val_loss: 21.2179\n",
      "Epoch 1824/2000\n",
      "88/88 - 0s - loss: 8.3464 - val_loss: 21.2199\n",
      "Epoch 1825/2000\n",
      "88/88 - 0s - loss: 8.3380 - val_loss: 21.5485\n",
      "Epoch 1826/2000\n",
      "88/88 - 0s - loss: 8.9781 - val_loss: 20.8542\n",
      "Epoch 1827/2000\n",
      "88/88 - 0s - loss: 7.6645 - val_loss: 19.9866\n",
      "Epoch 1828/2000\n",
      "88/88 - 0s - loss: 7.4558 - val_loss: 21.6060\n",
      "Epoch 1829/2000\n",
      "88/88 - 0s - loss: 7.4285 - val_loss: 22.5742\n",
      "Epoch 1830/2000\n",
      "88/88 - 0s - loss: 8.6107 - val_loss: 21.4441\n",
      "Epoch 1831/2000\n",
      "88/88 - 0s - loss: 9.1622 - val_loss: 21.7435\n",
      "Epoch 1832/2000\n",
      "88/88 - 0s - loss: 9.2184 - val_loss: 27.4164\n",
      "Epoch 1833/2000\n",
      "88/88 - 0s - loss: 14.3090 - val_loss: 23.2653\n",
      "Epoch 1834/2000\n",
      "88/88 - 0s - loss: 12.1874 - val_loss: 23.3696\n",
      "Epoch 1835/2000\n",
      "88/88 - 0s - loss: 11.3127 - val_loss: 21.7213\n",
      "Epoch 1836/2000\n",
      "88/88 - 0s - loss: 10.3781 - val_loss: 23.5480\n",
      "Epoch 1837/2000\n",
      "88/88 - 0s - loss: 10.1136 - val_loss: 22.9571\n",
      "Epoch 1838/2000\n",
      "88/88 - 0s - loss: 9.6276 - val_loss: 20.6189\n",
      "Epoch 1839/2000\n",
      "88/88 - 0s - loss: 9.3358 - val_loss: 21.5163\n",
      "Epoch 1840/2000\n",
      "88/88 - 0s - loss: 8.9514 - val_loss: 22.0612\n",
      "Epoch 1841/2000\n",
      "88/88 - 0s - loss: 10.8144 - val_loss: 21.5226\n",
      "Epoch 1842/2000\n",
      "88/88 - 0s - loss: 10.4113 - val_loss: 21.1040\n",
      "Epoch 1843/2000\n",
      "88/88 - 0s - loss: 9.7025 - val_loss: 20.3567\n",
      "Epoch 1844/2000\n",
      "88/88 - 0s - loss: 8.6124 - val_loss: 20.2174\n",
      "Epoch 1845/2000\n",
      "88/88 - 0s - loss: 8.7432 - val_loss: 20.1547\n",
      "Epoch 1846/2000\n",
      "88/88 - 0s - loss: 8.9025 - val_loss: 20.7384\n",
      "Epoch 1847/2000\n",
      "88/88 - 0s - loss: 8.2285 - val_loss: 20.2200\n",
      "Epoch 1848/2000\n",
      "88/88 - 0s - loss: 8.8823 - val_loss: 25.8569\n",
      "Epoch 1849/2000\n",
      "88/88 - 0s - loss: 15.3263 - val_loss: 24.6279\n",
      "Epoch 1850/2000\n",
      "88/88 - 0s - loss: 13.0067 - val_loss: 23.7720\n",
      "Epoch 1851/2000\n",
      "88/88 - 0s - loss: 11.7577 - val_loss: 23.2291\n",
      "Epoch 1852/2000\n",
      "88/88 - 0s - loss: 12.6139 - val_loss: 23.5311\n",
      "Epoch 1853/2000\n",
      "88/88 - 0s - loss: 12.0226 - val_loss: 23.0799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1854/2000\n",
      "88/88 - 0s - loss: 11.3125 - val_loss: 21.7657\n",
      "Epoch 1855/2000\n",
      "88/88 - 0s - loss: 10.2044 - val_loss: 23.8376\n",
      "Epoch 1856/2000\n",
      "88/88 - 0s - loss: 10.4586 - val_loss: 21.8760\n",
      "Epoch 1857/2000\n",
      "88/88 - 0s - loss: 9.5269 - val_loss: 22.4703\n",
      "Epoch 1858/2000\n",
      "88/88 - 0s - loss: 9.5930 - val_loss: 21.4645\n",
      "Epoch 1859/2000\n",
      "88/88 - 0s - loss: 9.1208 - val_loss: 20.8995\n",
      "Epoch 1860/2000\n",
      "88/88 - 0s - loss: 9.1439 - val_loss: 23.1323\n",
      "Epoch 1861/2000\n",
      "88/88 - 0s - loss: 11.0832 - val_loss: 23.8160\n",
      "Epoch 1862/2000\n",
      "88/88 - 0s - loss: 10.8839 - val_loss: 22.3100\n",
      "Epoch 1863/2000\n",
      "88/88 - 0s - loss: 10.0004 - val_loss: 20.9933\n",
      "Epoch 1864/2000\n",
      "88/88 - 0s - loss: 9.6609 - val_loss: 20.7848\n",
      "Epoch 1865/2000\n",
      "88/88 - 0s - loss: 8.8868 - val_loss: 20.3571\n",
      "Epoch 1866/2000\n",
      "88/88 - 0s - loss: 9.3302 - val_loss: 21.6734\n",
      "Epoch 1867/2000\n",
      "88/88 - 0s - loss: 11.3000 - val_loss: 22.6254\n",
      "Epoch 1868/2000\n",
      "88/88 - 0s - loss: 10.8853 - val_loss: 22.7650\n",
      "Epoch 1869/2000\n",
      "88/88 - 0s - loss: 10.5184 - val_loss: 21.5007\n",
      "Epoch 1870/2000\n",
      "88/88 - 0s - loss: 10.1716 - val_loss: 20.4008\n",
      "Epoch 1871/2000\n",
      "88/88 - 0s - loss: 10.4089 - val_loss: 22.2730\n",
      "Epoch 1872/2000\n",
      "88/88 - 0s - loss: 10.6856 - val_loss: 20.8308\n",
      "Epoch 1873/2000\n",
      "88/88 - 0s - loss: 9.4770 - val_loss: 22.3332\n",
      "Epoch 1874/2000\n",
      "88/88 - 0s - loss: 10.1851 - val_loss: 21.2101\n",
      "Epoch 1875/2000\n",
      "88/88 - 0s - loss: 10.0410 - val_loss: 24.0756\n",
      "Epoch 1876/2000\n",
      "88/88 - 0s - loss: 9.7868 - val_loss: 20.8401\n",
      "Epoch 1877/2000\n",
      "88/88 - 0s - loss: 8.9394 - val_loss: 20.3619\n",
      "Epoch 1878/2000\n",
      "88/88 - 0s - loss: 9.5071 - val_loss: 22.6389\n",
      "Epoch 1879/2000\n",
      "88/88 - 0s - loss: 9.8702 - val_loss: 20.3564\n",
      "Epoch 1880/2000\n",
      "88/88 - 0s - loss: 8.9661 - val_loss: 20.0135\n",
      "Epoch 1881/2000\n",
      "88/88 - 0s - loss: 8.7060 - val_loss: 20.5571\n",
      "Epoch 1882/2000\n",
      "88/88 - 0s - loss: 9.2071 - val_loss: 19.6599\n",
      "Epoch 1883/2000\n",
      "88/88 - 0s - loss: 9.0030 - val_loss: 20.8903\n",
      "Epoch 1884/2000\n",
      "88/88 - 0s - loss: 9.4731 - val_loss: 20.8572\n",
      "Epoch 1885/2000\n",
      "88/88 - 0s - loss: 9.2626 - val_loss: 21.5020\n",
      "Epoch 1886/2000\n",
      "88/88 - 0s - loss: 9.9047 - val_loss: 21.1367\n",
      "Epoch 1887/2000\n",
      "88/88 - 0s - loss: 9.5886 - val_loss: 20.7719\n",
      "Epoch 1888/2000\n",
      "88/88 - 0s - loss: 9.1769 - val_loss: 21.0241\n",
      "Epoch 1889/2000\n",
      "88/88 - 0s - loss: 9.5411 - val_loss: 20.6701\n",
      "Epoch 1890/2000\n",
      "88/88 - 0s - loss: 9.4927 - val_loss: 21.3599\n",
      "Epoch 1891/2000\n",
      "88/88 - 0s - loss: 9.7650 - val_loss: 21.8233\n",
      "Epoch 1892/2000\n",
      "88/88 - 0s - loss: 9.7658 - val_loss: 20.8426\n",
      "Epoch 1893/2000\n",
      "88/88 - 0s - loss: 9.4970 - val_loss: 19.3912\n",
      "Epoch 1894/2000\n",
      "88/88 - 0s - loss: 8.7937 - val_loss: 19.6161\n",
      "Epoch 1895/2000\n",
      "88/88 - 0s - loss: 9.8952 - val_loss: 20.0584\n",
      "Epoch 1896/2000\n",
      "88/88 - 0s - loss: 11.3135 - val_loss: 25.4685\n",
      "Epoch 1897/2000\n",
      "88/88 - 0s - loss: 15.6306 - val_loss: 23.4544\n",
      "Epoch 1898/2000\n",
      "88/88 - 0s - loss: 15.4047 - val_loss: 23.5092\n",
      "Epoch 1899/2000\n",
      "88/88 - 0s - loss: 14.2440 - val_loss: 23.5873\n",
      "Epoch 1900/2000\n",
      "88/88 - 0s - loss: 13.7036 - val_loss: 23.1007\n",
      "Epoch 1901/2000\n",
      "88/88 - 0s - loss: 13.5820 - val_loss: 22.8846\n",
      "Epoch 1902/2000\n",
      "88/88 - 0s - loss: 12.9511 - val_loss: 23.6496\n",
      "Epoch 1903/2000\n",
      "88/88 - 0s - loss: 12.3588 - val_loss: 21.9391\n",
      "Epoch 1904/2000\n",
      "88/88 - 0s - loss: 11.9283 - val_loss: 21.4902\n",
      "Epoch 1905/2000\n",
      "88/88 - 0s - loss: 11.3391 - val_loss: 21.7637\n",
      "Epoch 1906/2000\n",
      "88/88 - 0s - loss: 11.5423 - val_loss: 21.3096\n",
      "Epoch 1907/2000\n",
      "88/88 - 0s - loss: 11.7117 - val_loss: 22.5868\n",
      "Epoch 1908/2000\n",
      "88/88 - 0s - loss: 12.8509 - val_loss: 21.2463\n",
      "Epoch 1909/2000\n",
      "88/88 - 0s - loss: 10.7190 - val_loss: 22.2991\n",
      "Epoch 1910/2000\n",
      "88/88 - 0s - loss: 10.7092 - val_loss: 20.9890\n",
      "Epoch 1911/2000\n",
      "88/88 - 0s - loss: 11.2404 - val_loss: 22.1430\n",
      "Epoch 1912/2000\n",
      "88/88 - 0s - loss: 10.4160 - val_loss: 20.5852\n",
      "Epoch 1913/2000\n",
      "88/88 - 0s - loss: 11.0621 - val_loss: 22.1469\n",
      "Epoch 1914/2000\n",
      "88/88 - 0s - loss: 11.2493 - val_loss: 22.2476\n",
      "Epoch 1915/2000\n",
      "88/88 - 0s - loss: 10.6378 - val_loss: 20.8787\n",
      "Epoch 1916/2000\n",
      "88/88 - 0s - loss: 9.7004 - val_loss: 21.8909\n",
      "Epoch 1917/2000\n",
      "88/88 - 0s - loss: 10.5086 - val_loss: 24.4548\n",
      "Epoch 1918/2000\n",
      "88/88 - 0s - loss: 15.2593 - val_loss: 22.7937\n",
      "Epoch 1919/2000\n",
      "88/88 - 0s - loss: 13.1167 - val_loss: 21.3717\n",
      "Epoch 1920/2000\n",
      "88/88 - 0s - loss: 13.9116 - val_loss: 23.3150\n",
      "Epoch 1921/2000\n",
      "88/88 - 0s - loss: 14.3487 - val_loss: 23.5727\n",
      "Epoch 1922/2000\n",
      "88/88 - 0s - loss: 12.7871 - val_loss: 27.7411\n",
      "Epoch 1923/2000\n",
      "88/88 - 0s - loss: 12.0380 - val_loss: 21.9024\n",
      "Epoch 1924/2000\n",
      "88/88 - 0s - loss: 10.6328 - val_loss: 21.4283\n",
      "Epoch 1925/2000\n",
      "88/88 - 0s - loss: 10.9817 - val_loss: 21.1950\n",
      "Epoch 1926/2000\n",
      "88/88 - 0s - loss: 11.2060 - val_loss: 21.8973\n",
      "Epoch 1927/2000\n",
      "88/88 - 0s - loss: 10.4075 - val_loss: 21.2703\n",
      "Epoch 1928/2000\n",
      "88/88 - 0s - loss: 10.4363 - val_loss: 20.4227\n",
      "Epoch 1929/2000\n",
      "88/88 - 0s - loss: 9.8930 - val_loss: 21.0152\n",
      "Epoch 1930/2000\n",
      "88/88 - 0s - loss: 10.2525 - val_loss: 24.0084\n",
      "Epoch 1931/2000\n",
      "88/88 - 0s - loss: 12.8148 - val_loss: 22.4949\n",
      "Epoch 1932/2000\n",
      "88/88 - 0s - loss: 11.9728 - val_loss: 21.2420\n",
      "Epoch 1933/2000\n",
      "88/88 - 0s - loss: 10.5613 - val_loss: 20.3299\n",
      "Epoch 1934/2000\n",
      "88/88 - 0s - loss: 9.7828 - val_loss: 20.2987\n",
      "Epoch 1935/2000\n",
      "88/88 - 0s - loss: 10.7296 - val_loss: 20.6557\n",
      "Epoch 1936/2000\n",
      "88/88 - 0s - loss: 11.1364 - val_loss: 23.3156\n",
      "Epoch 1937/2000\n",
      "88/88 - 0s - loss: 11.4079 - val_loss: 21.8041\n",
      "Epoch 1938/2000\n",
      "88/88 - 0s - loss: 9.7240 - val_loss: 21.2518\n",
      "Epoch 1939/2000\n",
      "88/88 - 0s - loss: 9.7268 - val_loss: 21.5257\n",
      "Epoch 1940/2000\n",
      "88/88 - 0s - loss: 10.9818 - val_loss: 21.4417\n",
      "Epoch 1941/2000\n",
      "88/88 - 0s - loss: 9.8215 - val_loss: 23.0358\n",
      "Epoch 1942/2000\n",
      "88/88 - 0s - loss: 10.3827 - val_loss: 22.7574\n",
      "Epoch 1943/2000\n",
      "88/88 - 0s - loss: 10.0359 - val_loss: 20.9151\n",
      "Epoch 1944/2000\n",
      "88/88 - 0s - loss: 9.4297 - val_loss: 20.8644\n",
      "Epoch 1945/2000\n",
      "88/88 - 0s - loss: 9.5275 - val_loss: 24.0217\n",
      "Epoch 1946/2000\n",
      "88/88 - 0s - loss: 12.1890 - val_loss: 21.8911\n",
      "Epoch 1947/2000\n",
      "88/88 - 0s - loss: 10.3303 - val_loss: 21.7691\n",
      "Epoch 1948/2000\n",
      "88/88 - 0s - loss: 10.4859 - val_loss: 21.2009\n",
      "Epoch 1949/2000\n",
      "88/88 - 0s - loss: 9.7203 - val_loss: 21.1096\n",
      "Epoch 1950/2000\n",
      "88/88 - 0s - loss: 9.8584 - val_loss: 20.6377\n",
      "Epoch 1951/2000\n",
      "88/88 - 0s - loss: 9.2946 - val_loss: 19.7325\n",
      "Epoch 1952/2000\n",
      "88/88 - 0s - loss: 9.3453 - val_loss: 20.7559\n",
      "Epoch 1953/2000\n",
      "88/88 - 0s - loss: 9.7311 - val_loss: 20.4093\n",
      "Epoch 1954/2000\n",
      "88/88 - 0s - loss: 9.6304 - val_loss: 20.4181\n",
      "Epoch 1955/2000\n",
      "88/88 - 0s - loss: 9.4340 - val_loss: 19.9849\n",
      "Epoch 1956/2000\n",
      "88/88 - 0s - loss: 8.9614 - val_loss: 20.2345\n",
      "Epoch 1957/2000\n",
      "88/88 - 0s - loss: 9.2031 - val_loss: 20.1045\n",
      "Epoch 1958/2000\n",
      "88/88 - 0s - loss: 9.3374 - val_loss: 20.2898\n",
      "Epoch 1959/2000\n",
      "88/88 - 0s - loss: 8.9139 - val_loss: 20.5575\n",
      "Epoch 1960/2000\n",
      "88/88 - 0s - loss: 9.0339 - val_loss: 21.5498\n",
      "Epoch 1961/2000\n",
      "88/88 - 0s - loss: 11.8155 - val_loss: 24.6511\n",
      "Epoch 1962/2000\n",
      "88/88 - 0s - loss: 12.1745 - val_loss: 22.9221\n",
      "Epoch 1963/2000\n",
      "88/88 - 0s - loss: 11.1131 - val_loss: 22.3950\n",
      "Epoch 1964/2000\n",
      "88/88 - 0s - loss: 11.9847 - val_loss: 26.9133\n",
      "Epoch 1965/2000\n",
      "88/88 - 0s - loss: 15.6201 - val_loss: 25.9550\n",
      "Epoch 1966/2000\n",
      "88/88 - 0s - loss: 13.0980 - val_loss: 24.2040\n",
      "Epoch 1967/2000\n",
      "88/88 - 0s - loss: 11.2480 - val_loss: 23.3312\n",
      "Epoch 1968/2000\n",
      "88/88 - 0s - loss: 10.7977 - val_loss: 23.5593\n",
      "Epoch 1969/2000\n",
      "88/88 - 0s - loss: 11.4256 - val_loss: 22.7274\n",
      "Epoch 1970/2000\n",
      "88/88 - 0s - loss: 10.6027 - val_loss: 22.6235\n",
      "Epoch 1971/2000\n",
      "88/88 - 0s - loss: 10.6226 - val_loss: 22.7229\n",
      "Epoch 1972/2000\n",
      "88/88 - 0s - loss: 10.2749 - val_loss: 23.8924\n",
      "Epoch 1973/2000\n",
      "88/88 - 0s - loss: 10.8375 - val_loss: 22.4677\n",
      "Epoch 1974/2000\n",
      "88/88 - 0s - loss: 11.0225 - val_loss: 22.6147\n",
      "Epoch 1975/2000\n",
      "88/88 - 0s - loss: 10.6548 - val_loss: 23.0878\n",
      "Epoch 1976/2000\n",
      "88/88 - 0s - loss: 11.9359 - val_loss: 25.0370\n",
      "Epoch 1977/2000\n",
      "88/88 - 0s - loss: 13.8064 - val_loss: 23.2484\n",
      "Epoch 1978/2000\n",
      "88/88 - 0s - loss: 10.8867 - val_loss: 22.3560\n",
      "Epoch 1979/2000\n",
      "88/88 - 0s - loss: 11.1231 - val_loss: 23.2012\n",
      "Epoch 1980/2000\n",
      "88/88 - 0s - loss: 11.0473 - val_loss: 23.0356\n",
      "Epoch 1981/2000\n",
      "88/88 - 0s - loss: 10.9951 - val_loss: 23.3185\n",
      "Epoch 1982/2000\n",
      "88/88 - 0s - loss: 10.8008 - val_loss: 22.1447\n",
      "Epoch 1983/2000\n",
      "88/88 - 0s - loss: 10.2240 - val_loss: 24.1343\n",
      "Epoch 1984/2000\n",
      "88/88 - 0s - loss: 11.6296 - val_loss: 23.6416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1985/2000\n",
      "88/88 - 0s - loss: 10.4640 - val_loss: 22.3299\n",
      "Epoch 1986/2000\n",
      "88/88 - 0s - loss: 10.4346 - val_loss: 22.7256\n",
      "Epoch 1987/2000\n",
      "88/88 - 0s - loss: 10.2585 - val_loss: 24.3667\n",
      "Epoch 1988/2000\n",
      "88/88 - 0s - loss: 10.6169 - val_loss: 22.2753\n",
      "Epoch 1989/2000\n",
      "88/88 - 0s - loss: 10.6670 - val_loss: 24.1983\n",
      "Epoch 1990/2000\n",
      "88/88 - 0s - loss: 9.6127 - val_loss: 21.8441\n",
      "Epoch 1991/2000\n",
      "88/88 - 0s - loss: 9.4648 - val_loss: 22.7996\n",
      "Epoch 1992/2000\n",
      "88/88 - 0s - loss: 9.8195 - val_loss: 22.5394\n",
      "Epoch 1993/2000\n",
      "88/88 - 0s - loss: 9.3472 - val_loss: 21.7527\n",
      "Epoch 1994/2000\n",
      "88/88 - 0s - loss: 9.7130 - val_loss: 22.3592\n",
      "Epoch 1995/2000\n",
      "88/88 - 0s - loss: 10.2642 - val_loss: 22.3180\n",
      "Epoch 1996/2000\n",
      "88/88 - 0s - loss: 9.2162 - val_loss: 23.2719\n",
      "Epoch 1997/2000\n",
      "88/88 - 0s - loss: 9.7671 - val_loss: 22.1799\n",
      "Epoch 1998/2000\n",
      "88/88 - 0s - loss: 9.4147 - val_loss: 21.9639\n",
      "Epoch 1999/2000\n",
      "88/88 - 0s - loss: 10.0787 - val_loss: 22.0180\n",
      "Epoch 2000/2000\n",
      "88/88 - 0s - loss: 9.8199 - val_loss: 24.3402\n",
      "Wall time: 10min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = hot3_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test,y_test),\n",
    "    batch_size=10,\n",
    "    verbose=2, epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLoss(loss_type, loss):\n",
    "  MEAN = np.mean(loss)\n",
    "  STD_DEV = np.std(loss)\n",
    "  MIN = np.min(loss)\n",
    "  MAX = np.max(loss)\n",
    "  print(str(loss_type))\n",
    "  print(\"\\t Max: =\", MAX)\n",
    "  print(\"\\t Min: =\", MIN)\n",
    "  print(\"\\t Mean: =\", MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:\n",
      "\t Max: = 57.07482147216797\n",
      "\t Min: = 6.460926532745361\n",
      "\t Mean: = 12.472197850942612\n"
     ]
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "training_loss = history.history['loss']\n",
    "printLoss(\"Training Loss:\", training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.ylim([0, 1000])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error')\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 24.3402\n",
      "{'hot3_model': 24.340234756469727}\n"
     ]
    }
   ],
   "source": [
    "test_results = {}\n",
    "test_results['hot3_model'] = hot3_model.evaluate(X_test, y_test, verbose=1)\n",
    "print (test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =hot3_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = pd.DataFrame(X_test['T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_pred = pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalCSV = pd.concat([T,air_quality_pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalCSV.columns = ['T', 'air_quality_pm2.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalCSV.to_csv('./ltfc/PM2.5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
